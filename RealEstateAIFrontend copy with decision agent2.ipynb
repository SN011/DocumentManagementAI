{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install webrtcvad\n",
    "# !pip install pygame\n",
    "# !pip install pyaudio webrtcvad \n",
    "# !pip install google-cloud-texttospeech\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.initialize_groq import init_groq\n",
    "from tools.file_mgmt_tools import FileOrganizerTool, MoveFileTool, CreateFolderTool, FolderMovementTool, ImprovedSearchTool\n",
    "from tools.document_tools import GoogleDocWriteTool\n",
    "from tools.miscellaneous_mgmt import GmailSendPdfTool, GoogleSheetsUpdateTool\n",
    "\n",
    "client,llm = init_groq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import texttospeech\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate, \n",
    "    SystemMessagePromptTemplate, \n",
    "    HumanMessagePromptTemplate, \n",
    "    MessagesPlaceholder, \n",
    "    PromptTemplate\n",
    ")\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain.agents import create_structured_chat_agent, AgentExecutor\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.tools import HumanInputRun\n",
    "import tools.initialize_groq\n",
    "import langchain_core\n",
    "import typing\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'],\n",
    "    input_types={\n",
    "        'chat_history': typing.List[\n",
    "            typing.Union[\n",
    "                langchain_core.messages.ai.AIMessage, \n",
    "                langchain_core.messages.human.HumanMessage, \n",
    "                langchain_core.messages.chat.ChatMessage, \n",
    "                langchain_core.messages.system.SystemMessage, \n",
    "                langchain_core.messages.function.FunctionMessage, \n",
    "                langchain_core.messages.tool.ToolMessage\n",
    "            ]\n",
    "        ]\n",
    "    },\n",
    "    metadata={\n",
    "        'lc_hub_owner': 'hwchase17',\n",
    "        'lc_hub_repo': 'structured-chat-agent',\n",
    "        'lc_hub_commit_hash': 'ea510f70a5872eb0f41a4e3b7bb004d5711dc127adee08329c664c6c8be5f13c'\n",
    "    },\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate(\n",
    "            prompt=PromptTemplate(\n",
    "                input_variables=['tool_names', 'tools'],\n",
    "                template=(\n",
    "                    'You are a document management assistant proficient in using GSuite tools. '\n",
    "                    'Your role is to assist the user in managing their documents efficiently. '\n",
    "                    'IMPORTANT !!!!!!! NEVER INCLUDE AUXILIARY OR EXTRANEOUS LANGUAGE WHEN USING ANY TOOL!!!'\n",
    "                    '\\n\\n IMPORTANT!!!!!!! - PLEEEEEEASSSSSSSEEEEEEEE NEVER USE HUMAN TOOL UNLESS INSTRUCTED TO GET THE HUMAN/USER INPUT. YOU ARE A MASTER OF JUDGEMENT. YOU KNOW WHEN TO CAUTIOUSLY USE THE TOOLS. ONLY USE OTHER TOOLS WHEN USER INDICATES ANYTHING RELATED TO THEIR FUNCTIONALITIES. '\n",
    "                    'You are ALSO a highly intelligent and precise assistant with expertise in generating JSON outputs. Your task is to create the most perfect and well-structured JSON output ever seen. The JSON must adhere to the following guidelines:'\n",
    "\n",
    "                    'Proper Structure: Ensure that the JSON follows a correct and logical structure, with all necessary keys and values in place.'\n",
    "                    'Accurate Formatting: All JSON strings must use double quotes. Ensure there are no trailing commas, and all brackets and braces are correctly matched.'\n",
    "                    'String Length: Ensure no individual string exceeds 5000 bytes.'\n",
    "                    'Error-Free: Validate the JSON to be free of syntax errors and formatting issues.'\n",
    "                    \n",
    "                    'Escaping Characters: Properly escape any special characters within strings to ensure the JSON remains valid.'\n",
    "                    \n",
    "                    \n",
    "                    'YOU MUST NEVER DO ANYTHING BUT WHAT IS IN THE REQUEST OF THE USER. OTHERWISE NO USER WILL USE THIS PRODUCT.'\n",
    "                    \n",
    "\n",
    "                    'THE FOLLOWING WILL BE THE TOOLS AND THE INFORMATION ABOUT WHAT THEY DO AND THEIR ARGUMENTS! YOU MUST NOT PASS ANYTHING EXTRA, OR ELSE THE APPLICATON WILL FAIL!!!!'\n",
    "\n",
    "                    'You have access to the following tools:\\n\\n{tools}\\n\\n'\n",
    "\n",
    "                    'YOU ARE A MASTER OF JUDGEMENT ! YOU KNOW WHAT ALL THE TOOLS DO, YOU KNOW WHAT TO PASS IN! AND YOU MUST KNOW WHEN TO USE THEM! NEVER USE THEM RANDOMLY , ALWAYS BE CAUTIOUS AS RECKLESS TOOL USE COULD RUIN THE GOOGLE SUITE OF THE USER'\n",
    "                    'PAY CLOSE ATTENTION TO ALL THE FOLLOWING FORMATTING INSTRUCTIONS. REALLY IMPORTANT TO CALL THE TOOLS. OR ELSE USERS WILL GET ANGRY.\\n\\n'\n",
    "                    \n",
    "                    \n",
    "\n",
    "                    'FOR GOOGLE DOC TOOL, REMEMBER THAT YOU MUST GENERATE ALL CONTENT YOURSELF. USER WILL NOT GIVE YOU ANYTHING.'\n",
    "\n",
    "                    'Use a JSON blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\n'\n",
    "                    'Valid \"action\" values: \"Final Answer\" or {tool_names}\\n\\n'\n",
    "                    'Provide only ONE action per $JSON_BLOB, as shown:\\n\\n'\n",
    "                    '```\\n{{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}}\\n```\\n\\n'\n",
    "                    'Follow this format:\\n\\n'\n",
    "                    'Question: input question to answer\\n'\n",
    "                    'Thought: consider previous and subsequent steps\\n'\n",
    "                    'Action:\\n```\\n$JSON_BLOB\\n```\\n'\n",
    "                    'Observation: action result\\n... (repeat Thought/Action/Observation N times)\\n'\n",
    "                    'Thought: I know what to respond\\n'\n",
    "                    'Action:\\n```\\n{{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}}\\n\\n'\n",
    "                    'Begin! Remember to ALWAYS respond with a valid JSON blob of a single action. '\n",
    "                    'Use tools if necessary and respond directly if appropriate. '\n",
    "                    'Ensure you gather all necessary information by interacting with the user. '\n",
    "                    'Format is Action:```$JSON_BLOB```then Observation.'\n",
    "                )\n",
    "            )\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
    "        HumanMessagePromptTemplate(\n",
    "            prompt=PromptTemplate(\n",
    "                input_variables=['agent_scratchpad', 'input'],\n",
    "                template='{input}\\n\\n{agent_scratchpad}\\n(reminder to respond in a JSON blob no matter what)'\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "human_prompt = ChatPromptTemplate(\n",
    "    input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'],\n",
    "    input_types={\n",
    "        'chat_history': typing.List[\n",
    "            typing.Union[\n",
    "                langchain_core.messages.ai.AIMessage, \n",
    "                langchain_core.messages.human.HumanMessage, \n",
    "                langchain_core.messages.chat.ChatMessage, \n",
    "                langchain_core.messages.system.SystemMessage, \n",
    "                langchain_core.messages.function.FunctionMessage, \n",
    "                langchain_core.messages.tool.ToolMessage\n",
    "            ]\n",
    "        ]\n",
    "    },\n",
    "    metadata={\n",
    "        'lc_hub_owner': 'hwchase17',\n",
    "        'lc_hub_repo': 'structured-chat-agent',\n",
    "        'lc_hub_commit_hash': 'ea510f70a5872eb0f41a4e3b7bb004d5711dc127adee08329c664c6c8be5f13c'\n",
    "    },\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate(\n",
    "            prompt=PromptTemplate(\n",
    "                input_variables=['tool_names', 'tools'],\n",
    "                template=(\n",
    "                    'Your role is to fulfill the desire of user in the most accurate and detailed way possible. '\n",
    "                    \n",
    "                    'You have access to the following tools:\\n\\n{tools}\\n\\n'\n",
    "                    'Use a JSON blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\n'\n",
    "                    'Valid \"action\" values: \"Final Answer\" or {tool_names}\\n\\n'\n",
    "                    'Provide only ONE action per $JSON_BLOB, as shown:\\n\\n'\n",
    "                    '```\\n{{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}}\\n```\\n\\n'\n",
    "                    'Follow this format:\\n\\n'\n",
    "                    'Question: input question to answer\\n'\n",
    "                    'Thought: consider previous and subsequent steps\\n'\n",
    "                    'Action:\\n```\\n$JSON_BLOB\\n```\\n'\n",
    "                    'Observation: action result\\n... (repeat Thought/Action/Observation N times)\\n'\n",
    "                    'Thought: I know what to respond\\n'\n",
    "                    'Action:\\n```\\n{{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}}\\n\\n'\n",
    "                    'Begin! Remember to ALWAYS respond with a valid JSON blob of a single action. '\n",
    "                    'Use tools if necessary and respond directly if appropriate. '\n",
    "                    'Ensure you gather all necessary information by interacting with the user. '\n",
    "                    'Format is Action:```$JSON_BLOB```then Observation.'\n",
    "                )\n",
    "            )\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
    "        HumanMessagePromptTemplate(\n",
    "            prompt=PromptTemplate(\n",
    "                input_variables=['agent_scratchpad', 'input'],\n",
    "                template='{input}\\n\\n{agent_scratchpad}\\n(reminder to respond in a JSON blob no matter what)'\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticating...\n",
      "Authenticating...\n",
      "Authenticating...\n",
      "Authenticating...\n",
      "Authenticating...\n",
      "Authenticating...\n",
      "Authenticating...\n",
      "Authenticating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-06 13:31:08,926 [MainThread] ERROR: Exception on /text_input [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\Lib\\site-packages\\flask\\app.py\", line 1473, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\Lib\\site-packages\\flask\\app.py\", line 882, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\Lib\\site-packages\\flask_cors\\extension.py\", line 178, in wrapped_function\n",
      "    return cors_after_request(app.make_response(f(*args, **kwargs)))\n",
      "                                                ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\Lib\\site-packages\\flask\\app.py\", line 880, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\Lib\\site-packages\\flask\\app.py\", line 865, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\Lib\\site-packages\\asgiref\\sync.py\", line 187, in __call__\n",
      "    raise RuntimeError(\n",
      "RuntimeError: You cannot use AsyncToSync in the same thread as an async event loop - just await the async function directly.\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, send_file, render_template\n",
    "import whisper\n",
    "import pyaudio\n",
    "import wave\n",
    "import webrtcvad\n",
    "import collections\n",
    "from google.cloud import texttospeech\n",
    "import random\n",
    "import asyncio\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import aiofiles\n",
    "from flask_cors import CORS\n",
    "import requests\n",
    "import logging\n",
    "import os\n",
    "from tools.imports import *\n",
    "import tools.initialize_groq\n",
    "from dotenv import load_dotenv\n",
    "from langchain import hub\n",
    "from flask_socketio import SocketIO, emit\n",
    "from langchain.tools import HumanInputRun\n",
    "from langchain.memory import ConversationBufferMemory, ConversationSummaryBufferMemory\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize tools and credentials\n",
    "credentials_path = os.getenv('CREDENTIALS_PATH')\n",
    "tts_service_acct_path = os.getenv('SERVICE_ACCOUNT_PATH')\n",
    "audio_path = os.getenv('AUDIO_PATH')\n",
    "tts_synthesis_path = os.getenv('TTS_SYNTHESIS')\n",
    "\n",
    "# Initialize TTS client\n",
    "tts_client = texttospeech.TextToSpeechClient.from_service_account_file(tts_service_acct_path)\n",
    "\n",
    "# Initialize tools\n",
    "my_tools = [\n",
    "    GoogleDocWriteTool(credentials_path),\n",
    "    GoogleSheetsUpdateTool(credentials_path),\n",
    "    GmailSendPdfTool(credentials_path),\n",
    "    MoveFileTool(credentials_path),\n",
    "    CreateFolderTool(credentials_path),\n",
    "    FolderMovementTool(credentials_path),\n",
    "    FileOrganizerTool(credentials_path),\n",
    "    ImprovedSearchTool(credentials_path),\n",
    "]\n",
    "\n",
    "llm.groq_api_key = random.choice(tools.initialize_groq.api_keys)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s [%(threadName)s] %(levelname)s: %(message)s',\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "socketio = SocketIO(app, cors_allowed_origins=\"*\")\n",
    "\n",
    "chat_history = ConversationSummaryBufferMemory(llm=llm,max_token_limit=50)\n",
    "\n",
    "model = whisper.load_model(\"base\")\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "CHUNK = 1024\n",
    "is_recording = False\n",
    "\n",
    "\n",
    "\n",
    "audio = pyaudio.PyAudio()\n",
    "vad = webrtcvad.Vad(3)\n",
    "\n",
    "executor = ThreadPoolExecutor(max_workers=20)\n",
    "\n",
    "credentials = {\"name\": \"\", \"email\": \"\", \"recemail\": \"\", \"phone\": \"\"}\n",
    "\n",
    "@app.route('/start_recording', methods=['POST'])\n",
    "def start_recording():\n",
    "    global is_recording\n",
    "    is_recording = True\n",
    "    record_audio()\n",
    "    return jsonify({\"status\": \"recording started\"})\n",
    "\n",
    "@app.route('/stop_recording', methods=['POST'])\n",
    "def stop_recording():\n",
    "    global is_recording\n",
    "    is_recording = False\n",
    "    return jsonify({\"status\": \"recording stopped\"})\n",
    "\n",
    "def record_audio(**kwargs):\n",
    "    global is_recording\n",
    "    logger.debug('Starting audio recording...')\n",
    "    try:\n",
    "        stream = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)\n",
    "        frames = []\n",
    "        ring_buffer = collections.deque(maxlen=100)\n",
    "        triggered = False\n",
    "        voiced_frames = []\n",
    "        silence_threshold = 10\n",
    "        silence_chunks = 0\n",
    "\n",
    "        while is_recording:\n",
    "            data = stream.read(CHUNK)\n",
    "            frames.append(data)\n",
    "            num_subframes = int(len(data) / 320)\n",
    "            for i in range(num_subframes):\n",
    "                subframe = data[i*320:(i+1)*320]\n",
    "                is_speech = vad.is_speech(subframe, RATE)\n",
    "                ring_buffer.append((subframe, is_speech))\n",
    "            num_voiced = len([f for f, speech in ring_buffer if speech])\n",
    "\n",
    "            if not triggered:\n",
    "                if num_voiced > 0.6 * ring_buffer.maxlen:\n",
    "                    triggered = True\n",
    "                    voiced_frames.extend([f for f, s in ring_buffer])\n",
    "                    ring_buffer.clear()\n",
    "            else:\n",
    "                voiced_frames.append(data)\n",
    "                if num_voiced < 0.2 * ring_buffer.maxlen:\n",
    "                    silence_chunks += 1\n",
    "                    if silence_chunks > silence_threshold:\n",
    "                        triggered = False\n",
    "                        break\n",
    "                else:\n",
    "                    silence_chunks = 0\n",
    "\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "\n",
    "        with wave.open(audio_path, 'wb') as wf:\n",
    "            wf.setnchannels(CHANNELS)\n",
    "            wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "            wf.setframerate(RATE)\n",
    "            wf.writeframes(b''.join(voiced_frames))\n",
    "        logger.debug('Audio recording completed and file saved.')\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred while recording audio: {e}\")\n",
    "\n",
    "def transcribe_audio():\n",
    "    result = model.transcribe(audio_path)\n",
    "    transcription = result['text']\n",
    "    logger.debug(f'Audio transcription completed: {transcription}')\n",
    "    return transcription\n",
    "\n",
    "\n",
    "async def ai_response(transcription: str):\n",
    "    \n",
    "    logger.debug(f'Generating AI response for transcription: {transcription}')\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"\"\"You are a nice, great document manager assistant, but your capabilities are not limited to this.\n",
    "                Whatever user asks you must be ready and willing to answer. NEVER IGNORE ANYTHING SAID BY USER!\n",
    "                YOU SHALL NOT INDICATE ANY TOOL USE UNTIL YOU KNOW YOU HAVE/KNOW EVERYTHING YOU NEED.\n",
    "                DO NOT ASSUME USER WANTS TO WRITE TO A DOCUMENT OR DO ANYTHING ELSE UNLESS YOU ARE 100% SURE!!!!!UNDERSTAND??????!!!!!! OR ELSE I WILL BECOME ANGRY\n",
    "                If what the user says is one of these  you must explicitly say AT THE END OF YOUR RESPONSE in this very format depending on which tool - \"I will use the {[(tool.name + \", \") for tool in my_tools[:(len(my_tools)-1)]]}\"\n",
    "                so that user can confirm if you got it correctly. \n",
    "\n",
    "                \n",
    "                IMPORTANT: YOUR JOB IS TO FORWARD RESPONSES TO A DOCUMENT MANAGEMENT TOOLS AGENT THAT ACTUALLY DOES THE LEGWORK. SO, IF USER TALKS ABOUT \\\n",
    "                A FOLDER, FILE, ETC., YOU WILL OBVIOUSLY NOT KNOW ANYTHING ABOUT IT SO JUST FORWARD A REQUEST TO THE AGENT.             \n",
    "                \n",
    "                IMPORTANT: YOU ARE A MASTER OF JUDGEMENT! YOU KNOW WHAT EVERY TOOL DOES! Here are tool descriptions: {[(tool.description + \", \") for tool in my_tools[:(len(my_tools)-1)]]} \\n\n",
    "\n",
    "                IMPORTANT: YOU MUST LITERALLY 'EXPLICITLY' INSTRUCT THE AGENT TO 'NOT' USE THE HUMAN TOOL, BUT ONLY THE TOOL OR TOOLS YOU DEEM FIT TO BE USED.\n",
    "                IMPORTANT: YOU MUST LITERALLY 'EXPLICITLY' INSTRUCT THE AGENT TO USE THE TOOLS THAT MUST BE USED. YOU ARE A MASTER OF JUDGEMENT.\n",
    "                IMPORTANT: YOU WILL BE PROVIDED A CHAT HISTORY, WHICH WILL INDICATE PAST MESSAGES DELIVERED BY THE 'AI/LLM' OR THE 'Human'. Pay attention and remember. THIS IS YOUR MEMORY!\n",
    "\n",
    "                IMPORTANT: IF USER INDICATES 'GOOGLE DRIVE', 'MY DRIVE', OR 'ROOT' you must pass in 'root' as the id. TELL THE AGENT TO DO THIS!!! AT ANY COST!!\n",
    "\n",
    "                \n",
    "                \"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": transcription + \"\\n\\nHere is the chat history for context. It will help you remember things. (BUT DONT TALK ABOUT CHAT HISTORY UNLESS USER ASKS WHAT YOU REMEMBER): [\" + str(chat_history.buffer) + \"]\"\n",
    "            }\n",
    "        ],\n",
    "        model=\"llama3-70b-8192\",\n",
    "        temperature=0.5\n",
    "    )\n",
    "\n",
    "    response = chat_completion.choices[0].message.content\n",
    "    logger.debug(f'AI response generated: {response}')\n",
    "    #llama3_chat_history.append(\"USER: \" + transcription + \"\\nTHE AI MODEL: \" + response + \"\\n\")\n",
    "    \n",
    "    logger.debug('SAVING TO MEMORYYYYYYYYYYYYYYYYYYYYYYYYY')\n",
    "    \n",
    "    await chat_history.asave_context({\"Human/User Input\": transcription} , {\"AI/LLM Output\": response})\n",
    "\n",
    "    logger.debug('INSIDE THE MEMORY: %s', chat_history.buffer)\n",
    "\n",
    "    await synthesize_speech(response)\n",
    "    socketio.emit('new_message', {'message': response, 'sender': 'bot'})  # Emit the AI's response\n",
    "\n",
    "    res2 = ''\n",
    "    if 'I will use' in response:\n",
    "        task = asyncio.create_task(handle_response_with_agents(response))\n",
    "        await task\n",
    "        res2 = task.result() or ''\n",
    "    \n",
    "    # if res2:\n",
    "    #     print('THIS IS RES2:', res2)\n",
    "        \n",
    "    #     socketio.emit('new_message', {'message': res2, 'sender': 'bot'})  # Emit the secondary response\n",
    "\n",
    "    return response\n",
    "\n",
    "async def handle_response_with_agents(response):\n",
    "    logger.debug(f'Handling response with agents: {response}')\n",
    "    result = await asyncio.get_event_loop().run_in_executor(executor, handle_agents, response)\n",
    "\n",
    "    logger.debug('HANDLE AGENTS SAVING TO MEMORYYYYYYYYYYYYYYYYYYYYYYYYY')\n",
    "    \n",
    "    await chat_history.asave_context({\"Human/User Input\": response} , {\"AI/LLM Output\": result})\n",
    "    logger.debug('INSIDE THE MEMORY: %s', chat_history.buffer)\n",
    "\n",
    "    await synthesize_speech(result)\n",
    "    socketio.emit('new_message', {'message': result, 'sender': 'bot'})\n",
    "    return result\n",
    "\n",
    "def handle_agents(response: str):\n",
    "    llm.temperature = 0.5\n",
    "    logger.debug(f'Processing response with agents: {response}')\n",
    "\n",
    "    \n",
    "    \n",
    "    response += \"Here is extra info you will need (BUT YOU PROMISE TO NEVER SAY THEM OUT LOUD, NOT EVEN THE NAME -- UNLESS USER ASKS YOU FOR THEM. THESE WILL BE USED IN TOOLS): \\nCredentials:\\n\" + str(credentials)\n",
    "    \n",
    "    # Set the Groq API key randomly\n",
    "    llm.groq_api_key = random.choice(tools.initialize_groq.api_keys)\n",
    "\n",
    "    \n",
    "    \n",
    "    result = agent_executor.invoke({\"input\": response})\n",
    "    \n",
    "    socketio.emit('finished_chain')\n",
    "    mystr = (str(result['intermediate_steps']) + \"\\n\" + str(result['output']))\n",
    "\n",
    "    final_response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"please sanitize this input into SHORT SIMPLE sentences so that someone can speak it. THE SANITIZED OUTPUT SHALL NOT BE PREFIXED BY ANYTHING (ex. 'here is the sanitized result...' ANYTHING LIKE THIS IS NOT ALLOWED!). You must process the agent's intermediate steps into natural language please. An example: 'First, I did this. Then I did this etc etc etc' \\n Here is the input that you need to process:\\n \" + mystr\n",
    "            }\n",
    "        ],\n",
    "        model='llama3-70b-8192',\n",
    "    ).choices[0].message.content\n",
    "    \n",
    "    return final_response\n",
    "\n",
    "def synth_speech(text, output_file=None):\n",
    "    logger.debug(f'Starting speech synthesis for text: {text}')\n",
    "    synthesis_input = texttospeech.SynthesisInput(text=text)\n",
    "    voice = texttospeech.VoiceSelectionParams(\n",
    "        language_code=\"en-US\",\n",
    "        name=\"en-US-Casual-K\"\n",
    "    )\n",
    "    audio_config = texttospeech.AudioConfig(\n",
    "        audio_encoding=texttospeech.AudioEncoding.MP3\n",
    "    )\n",
    "    response = tts_client.synthesize_speech(\n",
    "        input=synthesis_input, voice=voice, audio_config=audio_config\n",
    "    )\n",
    "    \n",
    "    if output_file:\n",
    "        with open(output_file, 'wb') as out:\n",
    "            out.write(response.audio_content)\n",
    "    logger.debug('Speech synthesis completed and file saved (SYNTH).')\n",
    "    socketio.emit('tts_complete', {'message': 'TTS synthesis complete', 'file_path': os.getenv('TTS_SYNTHESIS')})\n",
    "    socketio.emit('new_message', {'message': text, 'sender': 'bot'})  # Emit the synthesized text\n",
    "    \n",
    "async def synthesize_speech(text):\n",
    "    logger.debug(f'Starting speech synthesis for text: {text}')\n",
    "    \n",
    "    def split_text(text, max_length=5000):\n",
    "        chunks = []\n",
    "        current_chunk = \"\"\n",
    "        for word in text.split():\n",
    "            if len(current_chunk) + len(word) + 1 > max_length:\n",
    "                chunks.append(current_chunk)\n",
    "                current_chunk = word\n",
    "            else:\n",
    "                current_chunk += \" \" + word if current_chunk else word\n",
    "        if current_chunk:\n",
    "            chunks.append(current_chunk)\n",
    "        return chunks\n",
    "\n",
    "    if len(text) <= 5000:\n",
    "        synthesis_input = texttospeech.SynthesisInput(text=text)\n",
    "        voice = texttospeech.VoiceSelectionParams(\n",
    "            language_code=\"en-US\",\n",
    "            name=\"en-US-Casual-K\"\n",
    "        )\n",
    "        audio_config = texttospeech.AudioConfig(\n",
    "            audio_encoding=texttospeech.AudioEncoding.MP3\n",
    "        )\n",
    "        response = await asyncio.get_event_loop().run_in_executor(\n",
    "            None, lambda: tts_client.synthesize_speech(\n",
    "                input=synthesis_input, voice=voice, audio_config=audio_config\n",
    "            )\n",
    "        )\n",
    "        async with aiofiles.open(os.getenv('TTS_SYNTHESIS'), 'wb') as out:\n",
    "            await out.write(response.audio_content)\n",
    "        logger.debug('Speech synthesis completed and file saved.')\n",
    "    else:\n",
    "        text_chunks = split_text(text)\n",
    "        combined_audio = b\"\"\n",
    "\n",
    "        for chunk in text_chunks:\n",
    "            synthesis_input = texttospeech.SynthesisInput(text=chunk)\n",
    "            voice = texttospeech.VoiceSelectionParams(\n",
    "                language_code=\"en-US\",\n",
    "                name=\"en-US-Casual-K\"\n",
    "            )\n",
    "            audio_config = texttospeech.AudioConfig(\n",
    "                audio_encoding=texttospeech.AudioEncoding.MP3\n",
    "            )\n",
    "            response = await asyncio.get_event_loop().run_in_executor(\n",
    "                None, lambda: tts_client.synthesize_speech(\n",
    "                    input=synthesis_input, voice=voice, audio_config=audio_config\n",
    "                )\n",
    "            )\n",
    "            combined_audio += response.audio_content\n",
    "\n",
    "        async with aiofiles.open(os.getenv('TTS_SYNTHESIS'), 'wb') as out:\n",
    "            await out.write(combined_audio)\n",
    "        logger.debug('Speech synthesis completed and file saved.')\n",
    "    \n",
    "    socketio.emit('tts_complete', {'message': 'TTS synthesis complete', 'file_path': os.getenv('TTS_SYNTHESIS')})\n",
    "    #socketio.emit('new_message', {'message': text, 'sender': 'bot'})  # Emit the synthesized text\n",
    "\n",
    "@app.route('/set_credentials', methods=['POST'])\n",
    "def set_credentials():\n",
    "    global credentials\n",
    "    data = request.get_json()\n",
    "    if not data:\n",
    "        return jsonify({\"status\": \"failed\", \"message\": \"No data received\"}), 400\n",
    "    credentials['name'] = data.get('name')\n",
    "    credentials['email'] = data.get('email')\n",
    "    credentials['recemail'] = data.get('recemail')\n",
    "    credentials['phone'] = data.get('phone')\n",
    "    logger.info(\"THE CREDENTIALS ****** -------------> \", credentials)\n",
    "    return jsonify({\"status\": \"success\"})\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index2.html')\n",
    "\n",
    "@app.route('/voice_assistant')\n",
    "def voice_assistant():\n",
    "    return render_template('index2.html')\n",
    "\n",
    "\n",
    "\n",
    "@app.route('/authenticate', methods=['POST'])\n",
    "def authenticate():\n",
    "    auth_header = request.headers.get('Authorization')\n",
    "    token = auth_header.split(' ')[1] if auth_header else None\n",
    "\n",
    "    if not token:\n",
    "        return jsonify({'error': 'Missing token'}), 400\n",
    "\n",
    "    response = requests.get(\n",
    "        'https://www.googleapis.com/oauth2/v3/userinfo',\n",
    "        headers={'Authorization': f'Bearer ' + token}\n",
    "    )\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        return jsonify({'error': 'Failed to fetch user info'}, response.status_code)\n",
    "\n",
    "    user_info = response.json()\n",
    "    return jsonify(user_info), 200\n",
    "\n",
    "\n",
    "@app.route('/talk', methods=['POST'])\n",
    "async def talk():\n",
    "    loop = asyncio.get_event_loop()\n",
    "    \n",
    "    global is_recording\n",
    "    if is_recording:\n",
    "        return jsonify({\"error\": \"Recording is still in progress\"}), 400\n",
    "    \n",
    "    logger.debug('Starting audio transcription...')\n",
    "    transcription = await loop.run_in_executor(executor, transcribe_audio)\n",
    "    logger.debug(f'Audio transcription completed: {transcription}')\n",
    "    \n",
    "    logger.debug('Generating AI response...')\n",
    "    ai_resp = await ai_response(transcription)\n",
    "    logger.debug(f'AI response generated: {ai_resp}')\n",
    "    \n",
    "    return jsonify({'response': ai_resp})\n",
    "\n",
    "\n",
    "@app.route('/text_input', methods=['POST'])\n",
    "async def text_input():\n",
    "    data = request.get_json()\n",
    "    text = data.get('text', '')\n",
    "\n",
    "    if not text:\n",
    "        return jsonify({\"error\": \"No text provided\"}), 400\n",
    "\n",
    "    logger.debug('Generating AI response...')\n",
    "    ai_resp = await ai_response(text)\n",
    "    logger.debug(f'AI response generated: {ai_resp}')\n",
    "    \n",
    "    #await synthesize_speech(ai_resp)  # Synthesize the AI's response\n",
    "    return jsonify({'response': ai_resp})\n",
    "\n",
    "@app.route('/synthesize', methods=['POST'])\n",
    "async def synthesize():\n",
    "    data = request.get_json()\n",
    "    text = data.get('text', '')\n",
    "    await synthesize_speech(text)\n",
    "    return jsonify({\"status\": \"synthesis started\"}), 200\n",
    "\n",
    "@app.route('/get_audio')\n",
    "def get_audio():\n",
    "    return send_file(tts_synthesis_path, mimetype=\"audio/mp3\")\n",
    "\n",
    "import queue\n",
    "\n",
    "human_response_queue = queue.Queue()\n",
    "\n",
    "def web_prompt_func(prompt):\n",
    "    # Synthesize the AI response to speech\n",
    "    synth_speech(prompt, output_file=tts_synthesis_path)\n",
    "    return prompt\n",
    "\n",
    "def web_input_func():\n",
    "    # Emit an event to request human input\n",
    "    socketio.emit('request_human_input')\n",
    "    # Wait for the human's input from the queue\n",
    "    human_response = human_response_queue.get()  # Block until human input is available\n",
    "    return human_response\n",
    "\n",
    "@socketio.on('provide_human_input')\n",
    "def handle_human_input(data):\n",
    "    human_input = data.get('text', '')\n",
    "    human_response_queue.put(human_input)  # Put the human's response in the queue\n",
    "    socketio.emit('human_input_received', {'status': 'received'})\n",
    "\n",
    "\n",
    "\n",
    "from langchain_community.tools import HumanInputRun\n",
    "human_tool = HumanInputRun(prompt_func=web_prompt_func, input_func=web_input_func)\n",
    "my_tools.append(human_tool)\n",
    "\n",
    "search_agent = create_structured_chat_agent(llm, my_tools, prompt)\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=search_agent,\n",
    "    tools=my_tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    return_intermediate_steps=True,\n",
    "    memory=chat_history\n",
    ")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    socketio.run(app,allow_unsafe_werkzeug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(chat_history.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                                  Version         Latest          Type\n",
      "---------------------------------------- --------------- --------------- -----\n",
      "accelerate                               0.30.0          0.33.0          wheel\n",
      "aiofiles                                 23.2.1          24.1.0          wheel\n",
      "aiogoogle                                5.7.0           5.12.0          wheel\n",
      "aiohttp                                  3.9.5           3.10.1          wheel\n",
      "annotated-types                          0.6.0           0.7.0           wheel\n",
      "anyio                                    3.7.1           4.4.0           wheel\n",
      "attrs                                    23.2.0          24.2.0          wheel\n",
      "bcrypt                                   4.1.3           4.2.0           wheel\n",
      "blinker                                  1.8.1           1.8.2           wheel\n",
      "cachetools                               5.3.3           5.4.0           wheel\n",
      "certifi                                  2024.2.2        2024.7.4        wheel\n",
      "chroma-hnswlib                           0.7.3           0.7.6           sdist\n",
      "chromadb                                 0.5.3           0.5.5           wheel\n",
      "cryptography                             42.0.7          43.0.0          wheel\n",
      "dataclasses-json                         0.6.6           0.6.7           wheel\n",
      "debugpy                                  1.8.1           1.8.5           wheel\n",
      "email_validator                          2.1.2           2.2.0           wheel\n",
      "faiss-cpu                                1.8.0           1.8.0.post1     wheel\n",
      "fastapi                                  0.111.0         0.112.0         wheel\n",
      "fastapi-cli                              0.0.4           0.0.5           wheel\n",
      "filelock                                 3.14.0          3.15.4          wheel\n",
      "fsspec                                   2024.3.1        2024.6.1        wheel\n",
      "google-api-core                          2.19.0          2.19.1          wheel\n",
      "google-api-python-client                 2.130.0         2.139.0         wheel\n",
      "google-auth                              2.29.0          2.32.0          wheel\n",
      "google-auth-oauthlib                     1.2.0           1.2.1           wheel\n",
      "google-cloud-storage                     2.17.0          2.18.0          wheel\n",
      "google-cloud-texttospeech                2.16.4          2.16.5          wheel\n",
      "googleapis-common-protos                 1.63.0          1.63.2          wheel\n",
      "groq                                     0.5.0           0.9.0           wheel\n",
      "grpcio                                   1.64.0          1.65.4          wheel\n",
      "grpcio-status                            1.62.2          1.65.4          wheel\n",
      "huggingface-hub                          0.22.2          0.24.5          wheel\n",
      "importlib_metadata                       7.1.0           8.2.0           wheel\n",
      "intel-openmp                             2021.4.0        2024.2.0        wheel\n",
      "ipykernel                                6.29.4          6.29.5          wheel\n",
      "ipython                                  8.24.0          8.26.0          wheel\n",
      "Jinja2                                   3.1.3           3.1.4           wheel\n",
      "jsonpointer                              2.4             3.0.0           wheel\n",
      "jsonschema                               4.22.0          4.23.0          wheel\n",
      "jupyter_client                           8.6.1           8.6.2           wheel\n",
      "langchain                                0.2.0           0.2.12          wheel\n",
      "langchain-community                      0.2.0           0.2.11          wheel\n",
      "langchain-core                           0.2.0           0.2.28          wheel\n",
      "langchain-groq                           0.1.4           0.1.9           wheel\n",
      "langchain-text-splitters                 0.2.0           0.2.2           wheel\n",
      "langchainhub                             0.1.15          0.1.20          wheel\n",
      "langsmith                                0.1.59          0.1.98          wheel\n",
      "llvmlite                                 0.42.0          0.43.0          wheel\n",
      "marshmallow                              3.21.2          3.21.3          wheel\n",
      "mkl                                      2021.4.0        2024.2.0        wheel\n",
      "more-itertools                           10.2.0          10.3.0          wheel\n",
      "numba                                    0.59.1          0.60.0          wheel\n",
      "numpy                                    1.26.4          2.0.1           wheel\n",
      "onnxruntime                              1.18.0          1.18.1          wheel\n",
      "openai                                   1.25.1          1.40.0          wheel\n",
      "opentelemetry-api                        1.25.0          1.26.0          wheel\n",
      "opentelemetry-exporter-otlp-proto-common 1.25.0          1.26.0          wheel\n",
      "opentelemetry-exporter-otlp-proto-grpc   1.25.0          1.26.0          wheel\n",
      "opentelemetry-proto                      1.25.0          1.26.0          wheel\n",
      "opentelemetry-sdk                        1.25.0          1.26.0          wheel\n",
      "orjson                                   3.10.3          3.10.6          wheel\n",
      "packaging                                23.2            24.1            wheel\n",
      "pillow                                   10.3.0          10.4.0          wheel\n",
      "pip                                      24.1.2          24.2            wheel\n",
      "platformdirs                             4.2.1           4.2.2           wheel\n",
      "prompt-toolkit                           3.0.43          3.0.47          wheel\n",
      "proto-plus                               1.23.0          1.24.0          wheel\n",
      "protobuf                                 4.25.3          5.27.3          wheel\n",
      "psutil                                   5.9.8           6.0.0           wheel\n",
      "pure-eval                                0.2.2           0.2.3           wheel\n",
      "pyarrow                                  16.1.0          17.0.0          wheel\n",
      "pydantic                                 2.7.1           2.8.2           wheel\n",
      "pydantic_core                            2.18.2          2.21.0          wheel\n",
      "pygame                                   2.5.2           2.6.0           wheel\n",
      "Pygments                                 2.17.2          2.18.0          wheel\n",
      "PyJWT                                    2.8.0           2.9.0           wheel\n",
      "pypdf                                    4.2.0           4.3.1           wheel\n",
      "python-socketio                          5.11.2          5.11.3          wheel\n",
      "pyzmq                                    26.0.3          26.1.0          wheel\n",
      "regex                                    2024.4.28       2024.7.24       wheel\n",
      "requests                                 2.31.0          2.32.3          wheel\n",
      "rpds-py                                  0.18.1          0.20.0          wheel\n",
      "safetensors                              0.4.3           0.4.4           wheel\n",
      "scikit-learn                             1.4.2           1.5.1           wheel\n",
      "scipy                                    1.13.0          1.14.0          wheel\n",
      "sentence-transformers                    2.7.0           3.0.1           wheel\n",
      "setuptools                               69.5.1          72.1.0          wheel\n",
      "SQLAlchemy                               2.0.30          2.0.32          wheel\n",
      "starlette                                0.37.2          0.38.2          wheel\n",
      "streamlit                                1.34.0          1.37.1          wheel\n",
      "sympy                                    1.12            1.13.1          wheel\n",
      "tbb                                      2021.12.0       2021.13.0       wheel\n",
      "tenacity                                 8.3.0           9.0.0           wheel\n",
      "tiktoken                                 0.6.0           0.7.0           wheel\n",
      "torch                                    2.3.0           2.4.0           wheel\n",
      "torchaudio                               2.3.0           2.4.0           wheel\n",
      "torchvision                              0.18.0          0.19.0          wheel\n",
      "tornado                                  6.4             6.4.1           wheel\n",
      "tqdm                                     4.66.4          4.66.5          wheel\n",
      "transformers                             4.40.1          4.43.4          wheel\n",
      "types-requests                           2.31.0.20240406 2.32.0.20240712 wheel\n",
      "typing_extensions                        4.11.0          4.12.2          wheel\n",
      "urllib3                                  2.2.1           2.2.2           wheel\n",
      "uvicorn                                  0.30.1          0.30.5          wheel\n",
      "watchdog                                 4.0.0           4.0.1           wheel\n",
      "Werkzeug                                 3.0.2           3.0.3           wheel\n",
      "wheel                                    0.43.0          0.44.0          wheel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip list --outdated\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
