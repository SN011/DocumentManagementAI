{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install webrtcvad\n",
    "# !pip install pygame\n",
    "# !pip install pyaudio webrtcvad \n",
    "# !pip install google-cloud-texttospeech\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.initialize_groq import init_groq\n",
    "from tools.file_mgmt_tools import FileOrganizerTool, MoveFileTool, CreateFolderTool, FolderMovementTool, ImprovedSearchTool\n",
    "from tools.document_tools import GoogleDocWriteTool\n",
    "from tools.miscellaneous_mgmt import GmailSendPdfTool, GoogleSheetsUpdateTool\n",
    "\n",
    "client,llm = init_groq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools.initialize_groq\n",
    "import random\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents import initialize_agent, AgentType, AgentExecutor\n",
    "from google.cloud import texttospeech\n",
    "from langchain.agents import load_agent\n",
    "\n",
    "\n",
    "# Define the template\n",
    "template = \"\"\"\n",
    "YOU ARE A VERY ADVANCED DOCUMENT MANAGER WHO USES GOOGLE DRIVE FOR DOCUMENT MANAGEMENT.\n",
    "WHEN USER INDICATES THEY WANT TO MOVE SOMETHING INTO GOOGLE DRIVE OR MY DRIVE, YOU PASS IN 'ROOT'!!!!! OKAY!!!!!\n",
    "RESPOND IN A CLEAR CUT MANNER.\n",
    "DO NOT SAY THINGS LIKE - 'here is the response' and the like. OKAY!!?!??\n",
    "YOU SHALL NOT INDICATE ANY TOOL USE UNTIL YOU KNOW YOU HAVE EVERYTHING YOU NEED.\n",
    "DO NOT ASSUME USER WANTS TO DO ANYTHING AT ALL UNLESS YOU ARE 100% SURE!!!!! UNDERSTAND??????!!!!!! OR ELSE I WILL BECOME ANGRY\n",
    "BE REALLY CAREFUL WITH FILE AND FOLDER ID'S! ANY WRONG ID'S WILL RESULT IN FAILURE OF OPERATIONS\n",
    "\n",
    "If user tells you to do something that is not one of these tools/operations,\\\n",
    "      you kindly say that you don't have access to that functionality.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# User credentials\n",
    "credentials = {\n",
    "    \"name\": \"Gautham Ramachandran\",\n",
    "    \"email\": \"sriramnallani35@gmail.com\",\n",
    "    \"recemail\": \"gauthamramachandran3@gmail.com\",\n",
    "    \"phone\": \"5715996302\"\n",
    "}\n",
    "\n",
    "\n",
    "agent = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify, send_file, render_template\n",
    "import whisper\n",
    "import pyaudio\n",
    "import wave\n",
    "import webrtcvad\n",
    "import collections\n",
    "from google.cloud import texttospeech\n",
    "import random\n",
    "import asyncio\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import aiofiles\n",
    "from flask_cors import CORS\n",
    "import requests\n",
    "import logging\n",
    "from tools.imports import *\n",
    "import tools.initialize_groq\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "my_tools = []\n",
    "load_dotenv()\n",
    "\n",
    "from langchain.agents import load_tools\n",
    "humantool = load_tools(\n",
    "    [\"human\"],\n",
    "    llm=llm,\n",
    ")[0]\n",
    "\n",
    "credentials_path = os.getenv('CREDENTIALS_PATH')\n",
    "my_tools.extend(\n",
    "    \n",
    "    [GoogleDocWriteTool(credentials_path),\n",
    "    GoogleSheetsUpdateTool(credentials_path),\n",
    "    GmailSendPdfTool(credentials_path),\n",
    "    MoveFileTool(credentials_path),\n",
    "    CreateFolderTool(credentials_path),\n",
    "    FolderMovementTool(credentials_path),\n",
    "    FileOrganizerTool(credentials_path),\n",
    "    ImprovedSearchTool(credentials_path),\n",
    "    humantool,]\n",
    ")\n",
    "\n",
    "import tools\n",
    "llm.groq_api_key = random.choice(tools.initialize_groq.api_keys)\n",
    "agent = initialize_agent(my_tools,llm,handle_parsing_errors=True,agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,verbose=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s [%(threadName)s] %(levelname)s: %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# Global variables\n",
    "chat_history = []\n",
    "model = whisper.load_model(\"base\")\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "CHUNK = 1024\n",
    "RECORD_SECONDS = 1000000\n",
    "vad = webrtcvad.Vad(3)\n",
    "audio = pyaudio.PyAudio()\n",
    "credentials = {\"name\": \"\", \"email\": \"\", \"recemail\": \"\", \"phone\": \"\"}\n",
    "from flask_socketio import SocketIO, emit\n",
    "\n",
    "#tts_service_acct_path = 'C:\\\\Users\\\\THEBATMAN\\\\Documents\\\\GitHub\\\\RealEstateAI\\\\filemanager-425819-341d30387005.json'\n",
    "tts_service_acct_path = os.getenv('SERVICE_ACCOUNT_PATH')\n",
    "tts_client = texttospeech.TextToSpeechClient.from_service_account_file(tts_service_acct_path)\n",
    "\n",
    "executor = ThreadPoolExecutor(max_workers=5)\n",
    "\n",
    "socketio = SocketIO(app, cors_allowed_origins=\"*\")\n",
    "\n",
    "is_recording = False\n",
    "\n",
    "@app.route('/start_recording', methods=['POST'])\n",
    "def start_recording():\n",
    "    global is_recording\n",
    "    is_recording = True\n",
    "    record_audio()\n",
    "    return jsonify({\"status\": \"recording started\"})\n",
    "\n",
    "@app.route('/stop_recording', methods=['POST'])\n",
    "def stop_recording():\n",
    "    global is_recording\n",
    "    is_recording = False\n",
    "    return jsonify({\"status\": \"recording stopped\"})\n",
    "\n",
    "def record_audio():\n",
    "    global is_recording\n",
    "    logger.debug('Starting audio recording...')\n",
    "    try:\n",
    "        stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                            rate=RATE, input=True,\n",
    "                            frames_per_buffer=CHUNK)\n",
    "        frames = []\n",
    "        ring_buffer = collections.deque(maxlen=100)\n",
    "        triggered = False\n",
    "        voiced_frames = []\n",
    "        silence_threshold = 10\n",
    "        silence_chunks = 0\n",
    "\n",
    "        while is_recording:\n",
    "            data = stream.read(CHUNK)\n",
    "            frames.append(data)\n",
    "\n",
    "            num_subframes = int(len(data) / 320)\n",
    "            for i in range(num_subframes):\n",
    "                subframe = data[i*320:(i+1)*320]\n",
    "                is_speech = vad.is_speech(subframe, RATE)\n",
    "                ring_buffer.append((subframe, is_speech))\n",
    "\n",
    "            num_voiced = len([f for f, speech in ring_buffer if speech])\n",
    "\n",
    "            if not triggered:\n",
    "                if num_voiced > 0.6 * ring_buffer.maxlen:\n",
    "                    triggered = True\n",
    "                    voiced_frames.extend([f for f, s in ring_buffer])\n",
    "                    ring_buffer.clear()\n",
    "            else:\n",
    "                voiced_frames.append(data)\n",
    "                if num_voiced < 0.2 * ring_buffer.maxlen:\n",
    "                    silence_chunks += 1\n",
    "                    if silence_chunks > silence_threshold:\n",
    "                        triggered = False\n",
    "                        break\n",
    "                else:\n",
    "                    silence_chunks = 0\n",
    "\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "\n",
    "        with wave.open(os.getenv('AUDIO_PATH'), 'wb') as wf:\n",
    "            wf.setnchannels(CHANNELS)\n",
    "            wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "            wf.setframerate(RATE)\n",
    "            wf.writeframes(b''.join(voiced_frames))\n",
    "        logger.debug('Audio recording completed and file saved.')\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred while recording audio: {e}\")\n",
    "\n",
    "def transcribe_audio():\n",
    "    result = model.transcribe(os.getenv('AUDIO_PATH'))\n",
    "    transcription = result['text']\n",
    "    \n",
    "    logger.debug(f'Audio transcription completed: {transcription}')\n",
    "    return transcription\n",
    "\n",
    "def run_agent(input_text):\n",
    "    global chat_history\n",
    "    input_text += \"\\n\\n\\nNEVER SAY ANY EXTRANEOUS STUFF LIKE 'Thought: blah blah blah' !!!!!!!! \\\n",
    "        STRICTTTTLLLYYYY ADHERE TO INSTRUCTIONS!!! PAY ATTENTION TO JSON WHEN CALLING THE TOOLS!!!!!!! \\\n",
    "            ONLY USE TOOLS WHEN USER TELLS YOU TO!!!! \\\n",
    "            DO ONLY WHAT IS SAID IN INSTRUCTIONS!!!!!!!  AND FORMAT YOUR RESPONSES ONLY AS SAID IN INSTRUCTIONS !!!! OR ELSE LIFE WILL END AS WE KNOW IT.\\\n",
    "            ALWAYS GENERATE THE GOOGLE DOC CONTENT YOURSELF! NEVER SPEAK TO HUMAN UNLESS INSTRUCTED. \\\n",
    "            DO EVERYTHING SAID HERE. NOT EVEN ONE THING SHALL BE LEFT INCOMPLETE.\\\n",
    "            DO NOT CREATE FOLDERS WHEN ORGANIZING FILES.\\\n",
    "            UNLESS USER TELLS YOU TO WRITE SOMETHING IN GOOGLE DOC DO NOT PASS ANYTHING INTO 'input_text' PARAMETER! \\\n",
    "            ALSO, WHEN MOVING A FOLDER INTO ANOTHER FOLDER, ALWAYS USE FOLDER MOVEMENT TOOL\\n\" + template + \"\\n\"\n",
    "\n",
    "    \n",
    "    input_text += (\"\\n\\n Here is extra info you will need: \\nCredentials:\\n\" + str(credentials) + \"\\n\"\n",
    "                   + \"\\nTHE CHAT HISTORY: \\n\" + str(chat_history))\n",
    "    print(input_text)\n",
    "    llm.groq_api_key = random.choice(tools.initialize_groq.api_keys)\n",
    "\n",
    "    agent = initialize_agent(\n",
    "        tools=my_tools,\n",
    "        llm=llm,\n",
    "        agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        handle_parsing_errors=True,\n",
    "        verbose=True,\n",
    "        max_iterations=1000,\n",
    "        return_intermediate_steps=True\n",
    "    )\n",
    "    \n",
    "    result = agent.invoke({\n",
    "        \"input\": input_text,\n",
    "    })\n",
    "    chat_history.append({\"input\": input_text, \"response\": result})\n",
    "    mystr = (str(result['intermediate_steps']) + \"\\n\" + str(result['output']))\n",
    "    \n",
    "    \n",
    "    synthesize_speech(client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\":\"please sanitize this input so that someone can speak it. START THE SPEAKABLE INPUT WITH '@' symbol: \" + mystr\n",
    "            }\n",
    "        ],\n",
    "        model='llama3-70b-8192',\n",
    "    ).choices[0].message.content, os.getenv('TTS_SYNTHESIS')\n",
    "    )\n",
    "\n",
    "    return result\n",
    "\n",
    "    \n",
    "\n",
    "def synthesize_speech(text, output_file=os.getenv('TTS_SYNTHESIS')):\n",
    "    print('THE TEXT: ', text)\n",
    "    idx = text.rfind('@')\n",
    "    text = text[idx + 1:].strip()\n",
    "    print('MODIFIED RESPONSE = ', text)\n",
    "    tts_service_acct_path = os.getenv('SERVICE_ACCOUNT_PATH')\n",
    "    client = texttospeech.TextToSpeechClient.from_service_account_file(tts_service_acct_path)\n",
    "\n",
    "    \n",
    "    input_text = texttospeech.SynthesisInput(text=text)\n",
    "    voice = texttospeech.VoiceSelectionParams(\n",
    "        language_code=\"en-US\",\n",
    "        ssml_gender=texttospeech.SsmlVoiceGender.MALE\n",
    "    )\n",
    "    audio_config = texttospeech.AudioConfig(\n",
    "        audio_encoding=texttospeech.AudioEncoding.MP3\n",
    "    )\n",
    "    response = client.synthesize_speech(\n",
    "        input=input_text,\n",
    "        voice=voice,\n",
    "        audio_config=audio_config\n",
    "    )\n",
    "    with open(os.getenv('TTS_SYNTHESIS'), \"wb\") as out:\n",
    "        out.write(response.audio_content)\n",
    "    print(f'Audio content written to \"{output_file}\"')\n",
    "\n",
    "@app.route('/set_credentials', methods=['POST'])\n",
    "def set_credentials():\n",
    "    global credentials\n",
    "    data = request.get_json()\n",
    "    if not data:\n",
    "        return jsonify({\"status\": \"failed\", \"message\": \"No data received\"}), 400\n",
    "    credentials['name'] = data.get('name')\n",
    "    credentials['email'] = data.get('email')\n",
    "    credentials['recemail'] = data.get('recemail')\n",
    "    credentials['phone'] = data.get('phone')\n",
    "    logger.info(\"THE CREDENTIALS ****** -------------> \", credentials)\n",
    "    return jsonify({\"status\": \"success\"})\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index2.html')\n",
    "\n",
    "@app.route('/voice_assistant')\n",
    "def voice_assistant():\n",
    "    return render_template('index2.html')\n",
    "\n",
    "@app.route('/authenticate', methods=['POST'])\n",
    "def authenticate():\n",
    "    auth_header = request.headers.get('Authorization')\n",
    "    token = auth_header.split(' ')[1] if auth_header else None\n",
    "\n",
    "    if not token:\n",
    "        return jsonify({'error': 'Missing token'}), 400\n",
    "\n",
    "    response = requests.get(\n",
    "        'https://www.googleapis.com/oauth2/v3/userinfo',\n",
    "        headers={'Authorization': f'Bearer {token}'}\n",
    "    )\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        return jsonify({'error': 'Failed to fetch user info'}), response.status_code\n",
    "\n",
    "    user_info = response.json()\n",
    "    return jsonify(user_info), 200\n",
    "\n",
    "@app.route('/talk', methods=['POST'])\n",
    "async def talk():\n",
    "    loop = asyncio.get_event_loop()\n",
    "\n",
    "    global is_recording\n",
    "    if is_recording:\n",
    "        return jsonify({\"error\": \"Recording is still in progress\"}), 400\n",
    "\n",
    "    transcription = await loop.run_in_executor(executor, transcribe_audio)\n",
    "\n",
    "    ai_resp = await run_agent(transcription)\n",
    "\n",
    "    return jsonify({'response': ai_resp})\n",
    "\n",
    "@app.route('/get_audio')\n",
    "def get_audio():\n",
    "    return send_file(os.getenv('TTS_SYNTHESIS'), mimetype=\"audio/mp3\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
