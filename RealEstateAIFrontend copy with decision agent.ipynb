{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install webrtcvad\n",
    "# !pip install pygame\n",
    "# !pip install pyaudio webrtcvad \n",
    "# !pip install google-cloud-texttospeech\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.initialize_groq import init_groq\n",
    "from tools.file_mgmt_tools import FileOrganizerTool, MoveFileTool, CreateFolderTool, FolderMovementTool, ImprovedSearchTool\n",
    "from tools.document_tools import GoogleDocWriteTool\n",
    "from tools.miscellaneous_mgmt import GmailSendPdfTool, GoogleDriveUploadTool, GoogleSheetsUpdateTool\n",
    "\n",
    "client,llm = init_groq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools.initialize_groq\n",
    "import random\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents import initialize_agent, AgentType, AgentExecutor\n",
    "from google.cloud import texttospeech\n",
    "from langchain.agents import load_agent\n",
    "\n",
    "\n",
    "# Define the template\n",
    "template = \"\"\"\n",
    "YOU ARE A VERY ADVANCED DOCUMENT MANAGER WHO USES GOOGLE DRIVE FOR DOCUMENT MANAGEMENT.\n",
    "WHEN USER INDICATES THEY WANT TO MOVE SOMETHING INTO GOOGLE DRIVE OR MY DRIVE, YOU PASS IN 'ROOT'!!!!! OKAY!!!!!\n",
    "RESPOND IN A CLEAR CUT MANNER.\n",
    "DO NOT SAY THINGS LIKE - 'here is the response' and the like. OKAY!!?!??\n",
    "YOU SHALL NOT INDICATE ANY TOOL USE UNTIL YOU KNOW YOU HAVE EVERYTHING YOU NEED.\n",
    "DO NOT ASSUME USER WANTS TO DO ANYTHING AT ALL UNLESS YOU ARE 100% SURE!!!!! UNDERSTAND??????!!!!!! OR ELSE I WILL BECOME ANGRY\n",
    "BE REALLY CAREFUL WITH FILE AND FOLDER ID'S! ANY WRONG ID'S WILL RESULT IN FAILURE OF OPERATIONS\n",
    "\n",
    "If user tells you to do something that is not one of these tools/operations,\\\n",
    "      you kindly say that you don't have access to that functionality.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# User credentials\n",
    "credentials = {\n",
    "    \"name\": \"Gautham Ramachandran\",\n",
    "    \"email\": \"sriramnallani35@gmail.com\",\n",
    "    \"recemail\": \"gauthamramachandran3@gmail.com\",\n",
    "    \"phone\": \"5715996302\"\n",
    "}\n",
    "\n",
    "\n",
    "agent = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-30 11:27:45,420 [MainThread] DEBUG: Generated new state jaZTmUhKbWeQV1rqNNKt3sPFRFKa0Z.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=291175256673-gr5p5vf3pi2h0m46h5qnd3ila4iitfqs.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A58326%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocuments+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&state=jaZTmUhKbWeQV1rqNNKt3sPFRFKa0Z&access_type=offline\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, send_file, render_template\n",
    "import whisper\n",
    "import pyaudio\n",
    "import wave\n",
    "import webrtcvad\n",
    "import collections\n",
    "from google.cloud import texttospeech\n",
    "import random\n",
    "import asyncio\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import aiofiles\n",
    "from flask_cors import CORS\n",
    "import requests\n",
    "import logging\n",
    "from tools.imports import *\n",
    "import tools.initialize_groq\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "my_tools = []\n",
    "load_dotenv()\n",
    "\n",
    "from langchain.agents import load_tools\n",
    "humantool = load_tools(\n",
    "    [\"human\"],\n",
    "    llm=llm,\n",
    ")[0]\n",
    "\n",
    "credentials_path = os.getenv('CREDENTIALS_PATH')\n",
    "my_tools.extend(\n",
    "    \n",
    "    iterable=[GoogleDocWriteTool(credentials_path),\n",
    "    GoogleSheetsUpdateTool(credentials_path),\n",
    "    GmailSendPdfTool(credentials_path),\n",
    "    MoveFileTool(credentials_path),\n",
    "    CreateFolderTool(credentials_path),\n",
    "    FolderMovementTool(credentials_path),\n",
    "    FileOrganizerTool(credentials_path),\n",
    "    ImprovedSearchTool(credentials_path),\n",
    "    humantool,]\n",
    ")\n",
    "\n",
    "import tools\n",
    "llm.groq_api_key = random.choice(tools.initialize_groq.api_keys)\n",
    "agent = initialize_agent(my_tools,llm,handle_parsing_errors=True,agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,verbose=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s [%(threadName)s] %(levelname)s: %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# Global variables\n",
    "chat_history = []\n",
    "model = whisper.load_model(\"base\")\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "CHUNK = 1024\n",
    "RECORD_SECONDS = 1000000\n",
    "vad = webrtcvad.Vad(3)\n",
    "audio = pyaudio.PyAudio()\n",
    "credentials = {\"name\": \"\", \"email\": \"\", \"recemail\": \"\", \"phone\": \"\"}\n",
    "from flask_socketio import SocketIO, emit\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "credentials_path = os.getenv('CREDENTIALS_PATH')\n",
    "#tts_service_acct_path = 'C:\\\\Users\\\\THEBATMAN\\\\Documents\\\\GitHub\\\\RealEstateAI\\\\filemanager-425819-341d30387005.json'\n",
    "tts_service_acct_path = os.getenv('SERVICE_ACCOUNT_PATH')\n",
    "tts_client = texttospeech.TextToSpeechClient.from_service_account_file(tts_service_acct_path)\n",
    "\n",
    "executor = ThreadPoolExecutor(max_workers=5)\n",
    "\n",
    "socketio = SocketIO(app, cors_allowed_origins=\"*\")\n",
    "\n",
    "is_recording = False\n",
    "\n",
    "@app.route('/start_recording', methods=['POST'])\n",
    "def start_recording():\n",
    "    global is_recording\n",
    "    is_recording = True\n",
    "    record_audio()\n",
    "    return jsonify({\"status\": \"recording started\"})\n",
    "\n",
    "@app.route('/stop_recording', methods=['POST'])\n",
    "def stop_recording():\n",
    "    global is_recording\n",
    "    is_recording = False\n",
    "    return jsonify({\"status\": \"recording stopped\"})\n",
    "\n",
    "def record_audio():\n",
    "    global is_recording\n",
    "    logger.debug('Starting audio recording...')\n",
    "    try:\n",
    "        stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                            rate=RATE, input=True,\n",
    "                            frames_per_buffer=CHUNK)\n",
    "        frames = []\n",
    "        ring_buffer = collections.deque(maxlen=100)\n",
    "        triggered = False\n",
    "        voiced_frames = []\n",
    "        silence_threshold = 10\n",
    "        silence_chunks = 0\n",
    "\n",
    "        while is_recording:\n",
    "            data = stream.read(CHUNK)\n",
    "            frames.append(data)\n",
    "\n",
    "            num_subframes = int(len(data) / 320)\n",
    "            for i in range(num_subframes):\n",
    "                subframe = data[i*320:(i+1)*320]\n",
    "                is_speech = vad.is_speech(subframe, RATE)\n",
    "                ring_buffer.append((subframe, is_speech))\n",
    "\n",
    "            num_voiced = len([f for f, speech in ring_buffer if speech])\n",
    "\n",
    "            if not triggered:\n",
    "                if num_voiced > 0.6 * ring_buffer.maxlen:\n",
    "                    triggered = True\n",
    "                    voiced_frames.extend([f for f, s in ring_buffer])\n",
    "                    ring_buffer.clear()\n",
    "            else:\n",
    "                voiced_frames.append(data)\n",
    "                if num_voiced < 0.2 * ring_buffer.maxlen:\n",
    "                    silence_chunks += 1\n",
    "                    if silence_chunks > silence_threshold:\n",
    "                        triggered = False\n",
    "                        break\n",
    "                else:\n",
    "                    silence_chunks = 0\n",
    "\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "\n",
    "        with wave.open(os.getenv('AUDIO_PATH'), 'wb') as wf:\n",
    "            wf.setnchannels(CHANNELS)\n",
    "            wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "            wf.setframerate(RATE)\n",
    "            wf.writeframes(b''.join(voiced_frames))\n",
    "        logger.debug('Audio recording completed and file saved.')\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred while recording audio: {e}\")\n",
    "\n",
    "def transcribe_audio():\n",
    "    result = model.transcribe(os.getenv('AUDIO_PATH'))\n",
    "    transcription = result['text']\n",
    "    \n",
    "    logger.debug(f'Audio transcription completed: {transcription}')\n",
    "    return transcription\n",
    "\n",
    "async def run_agent(input_text):\n",
    "    global chat_history\n",
    "    input_text += \"ALWAYS GENERATE THE GOOGLE DOC CONTENT YOURSELF! NEVER SPEAK TO HUMAN UNLESS INSTRUCTED. \\\n",
    "            DO ONLY WHAT IS SAID IN INSTRUCTIONS, AND FORMAT YOUR RESPONSES ONLY AS SAID IN INSTRUCTIONS OR ELSE LIFE WILL END AS WE KNOW IT. \\\n",
    "            DO EVERYTHING SAID HERE. NOT EVEN ONE THING SHALL BE LEFT INCOMPLETE.\\\n",
    "            DO NOT CREATE FOLDERS WHEN ORGANIZING FILES.\\\n",
    "            UNLESS USER TELLS YOU TO WRITE SOMETHING IN GOOGLE DOC DO NOT PASS ANYTHING INTO 'input_text' PARAMETER! \\\n",
    "            ALSO, WHEN MOVING A FOLDER INTO ANOTHER FOLDER, ALWAYS USE FOLDER MOVEMENT TOOL\\n\"\n",
    "\n",
    "    \n",
    "    input_text += (\"\\n\\n Here is extra info you will need: \\nCredentials:\\n\" + str(credentials) + \"\\n\"\n",
    "                   + \"\\nTHE CHAT HISTORY: \\n\" + str(chat_history))\n",
    "    print(input_text)\n",
    "    llm.groq_api_key = random.choice(tools.initialize_groq.api_keys)\n",
    "\n",
    "    agent = initialize_agent(\n",
    "        tools=my_tools,\n",
    "        llm=llm,\n",
    "        agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        handle_parsing_errors=True,\n",
    "        verbose=True,\n",
    "        max_iterations=1000,\n",
    "        return_intermediate_steps=True\n",
    "    )\n",
    "\n",
    "    result = await asyncio.get_event_loop().run_in_executor(\n",
    "        executor, lambda: agent.invoke({\n",
    "            \"input\": input_text,\n",
    "        })\n",
    "    )\n",
    "    chat_history.append({\"input\": input_text, \"response\": result})\n",
    "    mystr = (str(result['intermediate_steps']) + \"\\n\" + str(result['output']))\n",
    "\n",
    "    sanitized_response = await asyncio.get_event_loop().run_in_executor(\n",
    "        executor, lambda: client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"please sanitize this input so that someone can speak it. START THE SPEAKABLE INPUT WITH '@' symbol: \" + mystr\n",
    "                }\n",
    "            ],\n",
    "            model='llama3-70b-8192',\n",
    "        ).choices[0].message.content\n",
    "    )\n",
    "\n",
    "    await synthesize_speech(sanitized_response, \"intermediateoutput.mp3\")\n",
    "\n",
    "    return result\n",
    "\n",
    "async def synthesize_speech(text):\n",
    "    idx = text.rfind('@')\n",
    "    text = text[idx + 1:].strip()\n",
    "    print('MODIFIED RESPONSE = ', text)\n",
    "    logger.debug(f'Starting speech synthesis for text: {text}')\n",
    "    synthesis_input = texttospeech.SynthesisInput(text=text)\n",
    "    voice = texttospeech.VoiceSelectionParams(\n",
    "        language_code=\"en-US\",\n",
    "        name=\"en-US-Casual-K\"\n",
    "    )\n",
    "    audio_config = texttospeech.AudioConfig(\n",
    "        audio_encoding=texttospeech.AudioEncoding.MP3\n",
    "    )\n",
    "    response = await asyncio.get_event_loop().run_in_executor(\n",
    "        executor, lambda: tts_client.synthesize_speech(\n",
    "            input=synthesis_input, voice=voice, audio_config=audio_config\n",
    "        )\n",
    "    )\n",
    "    async with aiofiles.open(os.getenv('TTS_SYNTHESIS'), 'wb') as out:\n",
    "        await out.write(response.audio_content)\n",
    "    print('Audio content written to file \"synthesis.mp3\"')\n",
    "    logger.debug('Speech synthesis completed and file saved.')\n",
    "\n",
    "\n",
    "@app.route('/set_credentials', methods=['POST'])\n",
    "def set_credentials():\n",
    "    global credentials\n",
    "    data = request.get_json()\n",
    "    if not data:\n",
    "        return jsonify({\"status\": \"failed\", \"message\": \"No data received\"}), 400\n",
    "    credentials['name'] = data.get('name')\n",
    "    credentials['email'] = data.get('email')\n",
    "    credentials['recemail'] = data.get('recemail')\n",
    "    credentials['phone'] = data.get('phone')\n",
    "    logger.info(\"THE CREDENTIALS ****** -------------> \", credentials)\n",
    "    return jsonify({\"status\": \"success\"})\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index2.html')\n",
    "\n",
    "@app.route('/voice_assistant')\n",
    "def voice_assistant():\n",
    "    return render_template('index2.html')\n",
    "\n",
    "\n",
    "@app.route('/authenticate', methods=['POST'])\n",
    "def authenticate():\n",
    "    auth_header = request.headers.get('Authorization')\n",
    "    token = auth_header.split(' ')[1] if auth_header else None\n",
    "\n",
    "    if not token:\n",
    "        return jsonify({'error': 'Missing token'}), 400\n",
    "\n",
    "    response = requests.get(\n",
    "        'https://www.googleapis.com/oauth2/v3/userinfo',\n",
    "        headers={'Authorization': f'Bearer {token}'}\n",
    "    )\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        return jsonify({'error': 'Failed to fetch user info'}), response.status_code\n",
    "\n",
    "    user_info = response.json()\n",
    "    return jsonify(user_info), 200\n",
    "\n",
    "@app.route('/talk', methods=['POST'])\n",
    "async def talk():\n",
    "    loop = asyncio.get_event_loop()\n",
    "\n",
    "    global is_recording\n",
    "    if is_recording:\n",
    "        return jsonify({\"error\": \"Recording is still in progress\"}), 400\n",
    "\n",
    "    transcription = await loop.run_in_executor(executor, transcribe_audio)\n",
    "\n",
    "    ai_resp = await run_agent(transcription)\n",
    "\n",
    "    return jsonify({'response': ai_resp})\n",
    "\n",
    "\n",
    "@app.route('/get_audio')\n",
    "def get_audio():\n",
    "    return send_file(os.getenv('TTS_SYNTHESIS'), mimetype=\"audio/mp3\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
