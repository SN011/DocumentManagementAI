{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=291175256673-gr5p5vf3pi2h0m46h5qnd3ila4iitfqs.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A59880%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.metadata.readonly&state=rOPvALsdlbiKk0qE7k7JsngsKeoRdX&access_type=offline\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# Define the scopes\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive.metadata.readonly']\n",
    "\n",
    "# Function to authenticate and get the service\n",
    "def authenticate_with_oauth():\n",
    "    creds = None\n",
    "    if os.path.exists('token.pickle'):\n",
    "        with open('token.pickle', 'rb') as token:\n",
    "            creds = pickle.load(token)\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(os.getenv('CREDENTIALS_PATH'), SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        with open('token.pickle', 'wb') as token:\n",
    "            pickle.dump(creds, token)\n",
    "    service = build('drive', 'v3', credentials=creds)\n",
    "    return service\n",
    "\n",
    "# Function to list files and write to intermediate files\n",
    "def list_files_and_write(service, output_dir, batch_size=100):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    page_token = None\n",
    "    batch_num = 0\n",
    "    file_count = 0\n",
    "    batch_data = []\n",
    "\n",
    "    while True:\n",
    "        response = service.files().list(\n",
    "            q=\"'me' in owners\",\n",
    "            spaces='drive',\n",
    "            fields='nextPageToken, files(id, name, mimeType, createdTime, modifiedTime)',\n",
    "            pageToken=page_token\n",
    "        ).execute()\n",
    "        \n",
    "        items = response.get('files', [])\n",
    "        if not items:\n",
    "            break\n",
    "        \n",
    "        for item in items:\n",
    "            batch_data.append(item)\n",
    "            file_count += 1\n",
    "            \n",
    "            if file_count >= batch_size:\n",
    "                batch_file = os.path.join(output_dir, f'batch_{batch_num}.json')\n",
    "                with open(batch_file, 'w') as f:\n",
    "                    json.dump(batch_data, f, indent=4)\n",
    "                \n",
    "                batch_num += 1\n",
    "                file_count = 0\n",
    "                batch_data = []\n",
    "\n",
    "        page_token = response.get('nextPageToken', None)\n",
    "        if page_token is None:\n",
    "            break\n",
    "    \n",
    "    # Write remaining data if exists\n",
    "    if batch_data:\n",
    "        batch_file = os.path.join(output_dir, f'batch_{batch_num}.json')\n",
    "        with open(batch_file, 'w') as f:\n",
    "            json.dump(batch_data, f, indent=4)\n",
    "\n",
    "# Authenticate and get the service\n",
    "service = authenticate_with_oauth()\n",
    "\n",
    "# List files and write to intermediate files\n",
    "output_dir = 'drive_batches'\n",
    "list_files_and_write(service, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "import json\n",
    "\n",
    "def map_function(batch_file, output_dir):\n",
    "    with open(batch_file, 'r') as f:\n",
    "        items = json.load(f)\n",
    "    \n",
    "    mapped_data = defaultdict(list)\n",
    "    for item in items:\n",
    "        date_key = item['createdTime'][:10]  # Use only the date part\n",
    "        file_info = {\n",
    "            'id': item['id'],\n",
    "            'name': item['name'],\n",
    "            'type': item['mimeType'],\n",
    "            'created_time': item['createdTime'],\n",
    "            'modified_time': item['modifiedTime']\n",
    "        }\n",
    "        mapped_data[date_key].append(file_info)\n",
    "    \n",
    "    for date, files in mapped_data.items():\n",
    "        output_file = os.path.join(output_dir, f'{date}.json')\n",
    "        with open(output_file, 'a') as f:\n",
    "            json.dump(files, f)\n",
    "            f.write(\"\\n\")  # Ensure each batch is on a new line\n",
    "\n",
    "map_output_dir = 'mapped_batches'\n",
    "if not os.path.exists(map_output_dir):\n",
    "    os.makedirs(map_output_dir)\n",
    "\n",
    "for batch_file in os.listdir(output_dir):\n",
    "    map_function(os.path.join(output_dir, batch_file), map_output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_function(input_dir, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    for map_file in os.listdir(input_dir):\n",
    "        aggregated_data = defaultdict(list)\n",
    "        with open(os.path.join(input_dir, map_file), 'r') as f:\n",
    "            for line in f:\n",
    "                batch_data = json.loads(line)\n",
    "                for item in batch_data:\n",
    "                    aggregated_data[item['created_time'][:10]].append(item)\n",
    "        \n",
    "        # Write aggregated data to final file\n",
    "        for date, files in aggregated_data.items():\n",
    "            output_file = os.path.join(output_dir, f'final_{date}.json')\n",
    "            with open(output_file, 'w') as f:\n",
    "                json.dump(files, f, indent=4)\n",
    "\n",
    "reduce_output_dir = 'final_aggregated'\n",
    "reduce_function(map_output_dir, reduce_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found folder(s) named 'a':\n",
      "Name: a, ID: 1kIVSZss1hp9kHhQJmmCozYYTayLH6CIa, Created Time: 2023-12-14T23:27:40.417Z, Modified Time: 2023-12-14T23:27:40.417Z\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': '1kIVSZss1hp9kHhQJmmCozYYTayLH6CIa',\n",
       "  'name': 'a',\n",
       "  'type': 'application/vnd.google-apps.folder',\n",
       "  'created_time': '2023-12-14T23:27:40.417Z',\n",
       "  'modified_time': '2023-12-14T23:27:40.417Z'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def search_item_in_reduced_files(reduce_output_dir, item_name):\n",
    "    unique_items = set()\n",
    "    folder_items = []\n",
    "\n",
    "    for output_file in os.listdir(reduce_output_dir):\n",
    "        if output_file.endswith('.json'):\n",
    "            with open(os.path.join(reduce_output_dir, output_file), 'r') as f:\n",
    "                data = json.load(f)\n",
    "                for item in data:\n",
    "                    if item['name'].lower() == item_name.lower():\n",
    "                        if item['id'] not in unique_items:\n",
    "                            unique_items.add(item['id'])\n",
    "                            folder_items.append(item)\n",
    "    \n",
    "    if not folder_items:\n",
    "        print(f\"No folder named '{item_name}' found.\")\n",
    "    else:\n",
    "        print(f\"Found folder(s) named '{item_name}':\")\n",
    "        for item in folder_items:\n",
    "            print(f\"Name: {item['name']}, ID: {item['id']}, Created Time: {item['created_time']}, Modified Time: {item['modified_time']}\")\n",
    "    return folder_items\n",
    "\n",
    "# Search for the folder named 'a' in the reduced output files\n",
    "reduce_output_dir = 'final_aggregated'\n",
    "item_name = 'a'\n",
    "search_item_in_reduced_files(reduce_output_dir, item_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total counts of items in 'drive_batches':\n",
      "application/vnd.google-apps.spreadsheet: 4\n",
      "application/vnd.google-apps.document: 57\n",
      "application/vnd.google-apps.folder: 95\n",
      "application/pdf: 30\n",
      "audio/mpeg: 1003\n",
      "application/json: 6\n",
      "application/vnd.google.colaboratory: 10\n",
      "image/jpeg: 6\n",
      "application/vnd.openxmlformats-officedocument.wordprocessingml.document: 2\n",
      "video/mp4: 1\n",
      "application/octet-stream: 11263\n",
      "application/x-ipynb+json: 12\n",
      "text/plain: 22\n",
      "application/xml: 1\n",
      "text/xml: 1\n",
      "application/vnd.palm: 5\n",
      "application/x-dosexec: 4\n",
      "image/heif: 18\n",
      "application/x-zip-compressed: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'application/octet-stream': 11263,\n",
       "         'audio/mpeg': 1003,\n",
       "         'application/vnd.google-apps.folder': 95,\n",
       "         'application/vnd.google-apps.document': 57,\n",
       "         'application/pdf': 30,\n",
       "         'text/plain': 22,\n",
       "         'image/heif': 18,\n",
       "         'application/x-ipynb+json': 12,\n",
       "         'application/vnd.google.colaboratory': 10,\n",
       "         'application/x-zip-compressed': 10,\n",
       "         'application/json': 6,\n",
       "         'image/jpeg': 6,\n",
       "         'application/vnd.palm': 5,\n",
       "         'application/vnd.google-apps.spreadsheet': 4,\n",
       "         'application/x-dosexec': 4,\n",
       "         'application/vnd.openxmlformats-officedocument.wordprocessingml.document': 2,\n",
       "         'video/mp4': 1,\n",
       "         'application/xml': 1,\n",
       "         'text/xml': 1})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "def count_drive_items(batch_dir):\n",
    "    # Initialize counters\n",
    "    item_counts = Counter()\n",
    "\n",
    "    # Iterate over each batch file in the directory\n",
    "    for batch_file in os.listdir(batch_dir):\n",
    "        if batch_file.endswith('.json'):\n",
    "            with open(os.path.join(batch_dir, batch_file), 'r') as f:\n",
    "                items = json.load(f)\n",
    "                for item in items:\n",
    "                    item_type = item['mimeType']\n",
    "                    item_counts[item_type] += 1\n",
    "\n",
    "    # Print the counts\n",
    "    print(\"Total counts of items in 'drive_batches':\")\n",
    "    for item_type, count in item_counts.items():\n",
    "        print(f\"{item_type}: {count}\")\n",
    "\n",
    "    return item_counts\n",
    "\n",
    "# Directory containing the batch files\n",
    "batch_dir = 'drive_batches'\n",
    "\n",
    "# Count the items\n",
    "count_drive_items(batch_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
