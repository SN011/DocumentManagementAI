{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.12.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# !pip install webrtcvad\n",
    "# !pip install pygame\n",
    "# !pip install pyaudio webrtcvad \n",
    "# !pip install google-cloud-texttospeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.12.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from tools.initialize_groq import init_groq\n",
    "from tools.file_mgmt_tools import FileOrganizerTool, MoveFileTool, CreateFolderTool, FolderMovementTool, ImprovedSearchTool, GoogleDriveRenameTool, DriveDictUpdateTool\n",
    "from tools.document_tools import GoogleDocWriteTool\n",
    "from tools.miscellaneous_mgmt import GmailSendPdfTool, GoogleSheetsUpdateTool, GoogleSheetsCreateTool\n",
    "\n",
    "client,llm = init_groq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.12.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from google.cloud import texttospeech\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate, \n",
    "    SystemMessagePromptTemplate, \n",
    "    HumanMessagePromptTemplate, \n",
    "    MessagesPlaceholder, \n",
    "    PromptTemplate\n",
    ")\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain.agents import create_structured_chat_agent, AgentExecutor\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.tools import HumanInputRun\n",
    "import tools.initialize_groq\n",
    "import langchain_core\n",
    "import typing\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'],\n",
    "    input_types={\n",
    "        'chat_history': typing.List[\n",
    "            typing.Union[\n",
    "                langchain_core.messages.ai.AIMessage, \n",
    "                langchain_core.messages.human.HumanMessage, \n",
    "                langchain_core.messages.chat.ChatMessage, \n",
    "                langchain_core.messages.system.SystemMessage, \n",
    "                langchain_core.messages.function.FunctionMessage, \n",
    "                langchain_core.messages.tool.ToolMessage\n",
    "            ]\n",
    "        ]\n",
    "    },\n",
    "    metadata={\n",
    "        'lc_hub_owner': 'hwchase17',\n",
    "        'lc_hub_repo': 'structured-chat-agent',\n",
    "        'lc_hub_commit_hash': 'ea510f70a5872eb0f41a4e3b7bb004d5711dc127adee08329c664c6c8be5f13c'\n",
    "    },\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate(\n",
    "            prompt=PromptTemplate(\n",
    "                input_variables=['tool_names', 'tools'],\n",
    "                template=(\n",
    "                    'You are a document management assistant proficient in using GSuite tools. '\n",
    "                    'Your role is to assist the user in managing their documents efficiently. '\n",
    "                    'IMPORTANT !!!!!!! NEVER INCLUDE AUXILIARY OR EXTRANEOUS LANGUAGE WHEN USING ANY TOOL!!!'\n",
    "                    '\\n\\n IMPORTANT!!!!!!! - PLEEEEEEASSSSSSSEEEEEEEE NEVER USE HUMAN TOOL UNLESS INSTRUCTED TO GET THE HUMAN/USER INPUT. YOU ARE A MASTER OF JUDGEMENT. YOU KNOW WHEN TO CAUTIOUSLY USE THE TOOLS. ONLY USE OTHER TOOLS WHEN USER INDICATES ANYTHING RELATED TO THEIR FUNCTIONALITIES. '\n",
    "                    'You are ALSO a highly intelligent and precise assistant with expertise in generating JSON outputs. Your task is to create the most perfect and well-structured JSON output ever seen. The JSON must adhere to the following guidelines:'\n",
    "\n",
    "                    'Proper Structure: Ensure that the JSON follows a correct and logical structure, with all necessary keys and values in place.'\n",
    "                    'Accurate Formatting: All JSON strings must use double quotes. Ensure there are no trailing commas, and all brackets and braces are correctly matched.'\n",
    "                    'String Length: Ensure no individual string exceeds 5000 bytes.'\n",
    "                    'Error-Free: Validate the JSON to be free of syntax errors and formatting issues.'\n",
    "                    \n",
    "                    'Escaping Characters: Properly escape any special characters within strings to ensure the JSON remains valid.'\n",
    "                    \n",
    "                    \n",
    "                    'YOU MUST NEVER DO ANYTHING BUT WHAT IS IN THE REQUEST OF THE USER. OTHERWISE NO USER WILL USE THIS PRODUCT.'\n",
    "                    \n",
    "\n",
    "                    'THE FOLLOWING WILL BE THE TOOLS AND THE INFORMATION ABOUT WHAT THEY DO AND THEIR ARGUMENTS! YOU MUST NOT PASS ANYTHING EXTRA, OR ELSE THE APPLICATON WILL FAIL!!!!'\n",
    "\n",
    "                    'You have access to the following tools:\\n\\n{tools}\\n\\n'\n",
    "\n",
    "                    'YOU ARE A MASTER OF JUDGEMENT ! YOU KNOW WHAT ALL THE TOOLS DO, YOU KNOW WHAT TO PASS IN! AND YOU MUST KNOW WHEN TO USE THEM! NEVER USE THEM RANDOMLY , ALWAYS BE CAUTIOUS AS RECKLESS TOOL USE COULD RUIN THE GOOGLE SUITE OF THE USER'\n",
    "                    'PAY CLOSE ATTENTION TO ALL THE FOLLOWING FORMATTING INSTRUCTIONS. REALLY IMPORTANT TO CALL THE TOOLS. OR ELSE USERS WILL GET ANGRY.\\n\\n'\n",
    "                    \n",
    "                    \n",
    "\n",
    "                    'FOR GOOGLE DOC TOOL, REMEMBER THAT YOU MUST GENERATE ALL CONTENT YOURSELF. USER WILL NOT GIVE YOU ANYTHING.'\n",
    "\n",
    "                    'Use a JSON blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\n'\n",
    "                    'Valid \"action\" values: \"Final Answer\" or {tool_names}\\n\\n'\n",
    "                    'Provide only ONE action per $JSON_BLOB, as shown:\\n\\n'\n",
    "                    '```\\n{{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}}\\n```\\n\\n'\n",
    "                    'Follow this format:\\n\\n'\n",
    "                    'Question: input question to answer\\n'\n",
    "                    'Thought: consider previous and subsequent steps\\n'\n",
    "                    'Action:\\n```\\n$JSON_BLOB\\n```\\n'\n",
    "                    'Observation: action result\\n... (repeat Thought/Action/Observation N times)\\n'\n",
    "                    'Thought: I know what to respond\\n'\n",
    "                    'Action:\\n```\\n{{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}}\\n\\n'\n",
    "                    'Begin! Remember to ALWAYS respond with a valid JSON blob of a single action. '\n",
    "                    'Use tools if necessary and respond directly if appropriate. '\n",
    "                    'Ensure you gather all necessary information by interacting with the user. '\n",
    "                    'Format is Action:```$JSON_BLOB```then Observation.'\n",
    "                )\n",
    "            )\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
    "        HumanMessagePromptTemplate(\n",
    "            prompt=PromptTemplate(\n",
    "                input_variables=['agent_scratchpad', 'input'],\n",
    "                template='{input}\\n\\n{agent_scratchpad}\\n(reminder to respond in a JSON blob no matter what)'\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "human_prompt = ChatPromptTemplate(\n",
    "    input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'],\n",
    "    input_types={\n",
    "        'chat_history': typing.List[\n",
    "            typing.Union[\n",
    "                langchain_core.messages.ai.AIMessage, \n",
    "                langchain_core.messages.human.HumanMessage, \n",
    "                langchain_core.messages.chat.ChatMessage, \n",
    "                langchain_core.messages.system.SystemMessage, \n",
    "                langchain_core.messages.function.FunctionMessage, \n",
    "                langchain_core.messages.tool.ToolMessage\n",
    "            ]\n",
    "        ]\n",
    "    },\n",
    "    metadata={\n",
    "        'lc_hub_owner': 'hwchase17',\n",
    "        'lc_hub_repo': 'structured-chat-agent',\n",
    "        'lc_hub_commit_hash': 'ea510f70a5872eb0f41a4e3b7bb004d5711dc127adee08329c664c6c8be5f13c'\n",
    "    },\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate(\n",
    "            prompt=PromptTemplate(\n",
    "                input_variables=['tool_names', 'tools'],\n",
    "                template=(\n",
    "                    'Your role is to fulfill the desire of user in the most accurate and detailed way possible. '\n",
    "                    \n",
    "                    'You have access to the following tools:\\n\\n{tools}\\n\\n'\n",
    "                    'Use a JSON blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\n'\n",
    "                    'Valid \"action\" values: \"Final Answer\" or {tool_names}\\n\\n'\n",
    "                    'Provide only ONE action per $JSON_BLOB, as shown:\\n\\n'\n",
    "                    '```\\n{{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}}\\n```\\n\\n'\n",
    "                    'Follow this format:\\n\\n'\n",
    "                    'Question: input question to answer\\n'\n",
    "                    'Thought: consider previous and subsequent steps\\n'\n",
    "                    'Action:\\n```\\n$JSON_BLOB\\n```\\n'\n",
    "                    'Observation: action result\\n... (repeat Thought/Action/Observation N times)\\n'\n",
    "                    'Thought: I know what to respond\\n'\n",
    "                    'Action:\\n```\\n{{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}}\\n\\n'\n",
    "                    'Begin! Remember to ALWAYS respond with a valid JSON blob of a single action. '\n",
    "                    'Use tools if necessary and respond directly if appropriate. '\n",
    "                    'Ensure you gather all necessary information by interacting with the user. '\n",
    "                    'Format is Action:```$JSON_BLOB```then Observation.'\n",
    "                )\n",
    "            )\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
    "        HumanMessagePromptTemplate(\n",
    "            prompt=PromptTemplate(\n",
    "                input_variables=['agent_scratchpad', 'input'],\n",
    "                template='{input}\\n\\n{agent_scratchpad}\\n(reminder to respond in a JSON blob no matter what)'\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.12.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, send_file, render_template\n",
    "import whisper\n",
    "import pyaudio\n",
    "import wave\n",
    "import webrtcvad\n",
    "import collections\n",
    "from google.cloud import texttospeech\n",
    "import random\n",
    "import asyncio\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import aiofiles\n",
    "from flask_cors import CORS\n",
    "import requests\n",
    "import logging\n",
    "import os\n",
    "from tools.imports import *\n",
    "import tools.initialize_groq\n",
    "from dotenv import load_dotenv\n",
    "from langchain import hub\n",
    "from flask_socketio import SocketIO, emit\n",
    "from langchain.tools import HumanInputRun\n",
    "from langchain.memory import ConversationBufferMemory, ConversationSummaryBufferMemory\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize tools and credentials\n",
    "credentials_path = os.getenv('CREDENTIALS_PATH')\n",
    "tts_service_acct_path = os.getenv('SERVICE_ACCOUNT_PATH')\n",
    "audio_path = os.getenv('AUDIO_PATH')\n",
    "tts_synthesis_path = os.getenv('TTS_SYNTHESIS')\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# Initialize the tool with the path to your credentials\n",
    "update_tool = DriveDictUpdateTool(credentials_path='path/to/your/credentials.json')\n",
    "\n",
    "# Ensure the output directories exist\n",
    "if not os.path.exists(update_tool.output_dir):\n",
    "    os.makedirs(update_tool.output_dir)\n",
    "if not os.path.exists(update_tool.map_output_dir):\n",
    "    os.makedirs(update_tool.map_output_dir)\n",
    "if not os.path.exists(update_tool.reduce_output_dir):\n",
    "    os.makedirs(update_tool.reduce_output_dir)\n",
    "\n",
    "# Step 1: List files and write them in batches\n",
    "update_tool.list_files_and_write(batch_size=100)\n",
    "print(\"Step 1: Files have been listed and written to JSON files in batches.\")\n",
    "\n",
    "# Step 2: Perform the map function on each batch file\n",
    "for batch_file in os.listdir(update_tool.output_dir):\n",
    "    if batch_file.endswith('.json'):\n",
    "        update_tool.map_function(os.path.join(update_tool.output_dir, batch_file), update_tool.map_output_dir)\n",
    "print(\"Step 2: Map function has been performed on each batch file.\")\n",
    "\n",
    "# Step 3: Perform the reduce function to aggregate the data\n",
    "update_tool.reduce_function(update_tool.map_output_dir, update_tool.reduce_output_dir)\n",
    "print(\"Step 3: Reduce function has aggregated the data.\")\n",
    "\n",
    "print(\"Drive dictionary has been updated with the current information in Google Drive.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tts_client = texttospeech.TextToSpeechClient.from_service_account_file(tts_service_acct_path)\n",
    "\n",
    "\n",
    "my_tools = [\n",
    "    GoogleDocWriteTool(credentials_path),\n",
    "    GoogleSheetsUpdateTool(credentials_path),\n",
    "    GoogleSheetsCreateTool(credentials_path),\n",
    "    GoogleDriveRenameTool(credentials_path),\n",
    "    GmailSendPdfTool(credentials_path),\n",
    "    MoveFileTool(credentials_path),\n",
    "    CreateFolderTool(credentials_path),\n",
    "    FolderMovementTool(credentials_path),\n",
    "    FileOrganizerTool(credentials_path),\n",
    "    ImprovedSearchTool(credentials_path),\n",
    "]\n",
    "\n",
    "llm.groq_api_key = random.choice(tools.initialize_groq.api_keys)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s [%(threadName)s] %(levelname)s: %(message)s',\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "socketio = SocketIO(app, cors_allowed_origins=\"*\")\n",
    "\n",
    "chat_history = ConversationSummaryBufferMemory(llm=llm,max_token_limit=60)\n",
    "\n",
    "model = whisper.load_model(\"base\")\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "CHUNK = 1024\n",
    "is_recording = False\n",
    "\n",
    "\n",
    "\n",
    "audio = pyaudio.PyAudio()\n",
    "vad = webrtcvad.Vad(3)\n",
    "\n",
    "executor = ThreadPoolExecutor(max_workers=20)\n",
    "\n",
    "credentials = {\"name\": \"\", \"email\": \"\", \"recemail\": \"\", \"phone\": \"\"}\n",
    "\n",
    "@app.route('/start_recording', methods=['POST'])\n",
    "def start_recording():\n",
    "    global is_recording\n",
    "    is_recording = True\n",
    "    record_audio()\n",
    "    return jsonify({\"status\": \"recording started\"})\n",
    "\n",
    "@app.route('/stop_recording', methods=['POST'])\n",
    "def stop_recording():\n",
    "    global is_recording\n",
    "    is_recording = False\n",
    "    return jsonify({\"status\": \"recording stopped\"})\n",
    "\n",
    "def record_audio(**kwargs):\n",
    "    global is_recording\n",
    "    logger.debug('Starting audio recording...')\n",
    "    try:\n",
    "        stream = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)\n",
    "        frames = []\n",
    "        ring_buffer = collections.deque(maxlen=100)\n",
    "        triggered = False\n",
    "        voiced_frames = []\n",
    "        silence_threshold = 10\n",
    "        silence_chunks = 0\n",
    "\n",
    "        while is_recording:\n",
    "            data = stream.read(CHUNK)\n",
    "            frames.append(data)\n",
    "            num_subframes = int(len(data) / 320)\n",
    "            for i in range(num_subframes):\n",
    "                subframe = data[i*320:(i+1)*320]\n",
    "                is_speech = vad.is_speech(subframe, RATE)\n",
    "                ring_buffer.append((subframe, is_speech))\n",
    "            num_voiced = len([f for f, speech in ring_buffer if speech])\n",
    "\n",
    "            if not triggered:\n",
    "                if num_voiced > 0.6 * ring_buffer.maxlen:\n",
    "                    triggered = True\n",
    "                    voiced_frames.extend([f for f, s in ring_buffer])\n",
    "                    ring_buffer.clear()\n",
    "            else:\n",
    "                voiced_frames.append(data)\n",
    "                if num_voiced < 0.2 * ring_buffer.maxlen:\n",
    "                    silence_chunks += 1\n",
    "                    if silence_chunks > silence_threshold:\n",
    "                        triggered = False\n",
    "                        break\n",
    "                else:\n",
    "                    silence_chunks = 0\n",
    "\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "\n",
    "        with wave.open(audio_path, 'wb') as wf:\n",
    "            wf.setnchannels(CHANNELS)\n",
    "            wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "            wf.setframerate(RATE)\n",
    "            wf.writeframes(b''.join(voiced_frames))\n",
    "        logger.debug('Audio recording completed and file saved.')\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred while recording audio: {e}\")\n",
    "\n",
    "def transcribe_audio():\n",
    "    result = model.transcribe(audio_path)\n",
    "    transcription = result['text']\n",
    "    logger.debug(f'Audio transcription completed: {transcription}')\n",
    "    return transcription\n",
    "\n",
    "\n",
    "async def ai_response(transcription: str):\n",
    "    \n",
    "    logger.debug(f'Generating AI response for transcription: {transcription}')\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"\"\"You are a nice, great document manager assistant, but your capabilities are not limited to this.\n",
    "                Whatever user asks you must be ready and willing to answer. NEVER IGNORE ANYTHING SAID BY USER!\n",
    "\n",
    "                IMPORTANT: NOTHING IN YOUR RESPONSE SHALL BE ENCLOSED IN ANY QUOTES!!!!!!!\n",
    "\n",
    "                YOU SHALL NOT INDICATE ANY TOOL USE UNTIL YOU KNOW YOU HAVE/KNOW EVERYTHING YOU NEED.\n",
    "                DO NOT ASSUME USER WANTS TO DO ANYTHING UNLESS YOU ARE 100% SURE!!!!!UNDERSTAND??????!!!!!! OR ELSE I WILL BECOME ANGRY.\n",
    "\n",
    "                BUT YOU MAY NOT ASK THE USER CLARIFYING QUESTIONS, BUT IMMEDIATELY FORWARD USER'S REQUEST TO THE AGENT!!!!!\n",
    "                \n",
    "                If what the user says is one of these  you must explicitly say AT THE END OF YOUR RESPONSE in this very format depending on which tool - \"I will use the {[(tool.name + \", \") for tool in my_tools[:(len(my_tools)-1)]]}\"\n",
    "                so that user can confirm if you got it correctly. \n",
    "\n",
    "                \n",
    "                IMPORTANT: YOUR JOB IS TO FORWARD RESPONSES TO A DOCUMENT MANAGEMENT TOOLS AGENT THAT ACTUALLY DOES THE LEGWORK. SO, IF USER TALKS ABOUT \\\n",
    "                A FOLDER, FILE, ETC., YOU WILL OBVIOUSLY NOT KNOW ANYTHING ABOUT IT SO JUST FORWARD A REQUEST TO THE AGENT.             \n",
    "                \n",
    "                IMPORTANT: YOU ARE A MASTER OF JUDGEMENT! YOU KNOW WHAT EVERY TOOL DOES! Here are tool descriptions: {[(tool.description + \", \") for tool in my_tools[:(len(my_tools)-1)]]} \\n\n",
    "\n",
    "                IMPORTANT: YOU MUST TELL THE DOCUMENT MANAGEMENT AGENT TO KEEP THE RANGE_NAME AS SHEET 1 WHEN UPDATING THE GOOGLE SHEET UNLESS TOLD OTHERWISE BY HUMAN/USER.\n",
    "\n",
    "                IMPORTANT: YOU MUST LITERALLY 'EXPLICITLY' INSTRUCT THE AGENT TO USE THE TOOLS THAT MUST BE USED. YOU ARE A MASTER OF JUDGEMENT.\n",
    "                IMPORTANT: YOU WILL BE PROVIDED A CHAT HISTORY, WHICH WILL INDICATE PAST MESSAGES DELIVERED BY THE 'AI/LLM' OR THE 'Human'. Pay attention and remember. THIS IS YOUR MEMORY!\n",
    "\n",
    "                IMPORTANT: IF USER INDICATES 'GOOGLE DRIVE', 'MY DRIVE', OR 'ROOT' you must pass in 'root' as the id. TELL THE AGENT TO DO THIS!!! AT ANY COST!!\n",
    "\n",
    "                \n",
    "                \"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": transcription + \"\\n\\nHere is the chat history for context. It will help you remember things. (BUT DONT TALK ABOUT CHAT HISTORY UNLESS USER ASKS WHAT YOU REMEMBER): [\" + str(chat_history.buffer) + \"]\"\n",
    "            }\n",
    "        ],\n",
    "        model=\"llama3-70b-8192\",\n",
    "        temperature=0.5\n",
    "    )\n",
    "\n",
    "    response = chat_completion.choices[0].message.content\n",
    "    logger.debug(f'AI response generated: {response}')\n",
    "    #llama3_chat_history.append(\"USER: \" + transcription + \"\\nTHE AI MODEL: \" + response + \"\\n\")\n",
    "    \n",
    "    logger.debug('SAVING TO MEMORYYYYYYYYYYYYYYYYYYYYYYYYY')\n",
    "    \n",
    "    await chat_history.asave_context({\"Human/User Input\": transcription} , {\"AI/LLM Output\": response})\n",
    "\n",
    "    logger.debug('INSIDE THE MEMORY: %s', chat_history.buffer)\n",
    "\n",
    "    await synthesize_speech(response)\n",
    "    socketio.emit('new_message', {'message': response, 'sender': 'bot'})  # Emit the AI's response\n",
    "\n",
    "    \n",
    "    if 'I will use' in response:\n",
    "        task = asyncio.create_task(handle_response_with_agents(response))\n",
    "        await task\n",
    "        \n",
    "    return response\n",
    "\n",
    "async def handle_response_with_agents(response):\n",
    "    llm.temperature = 0.5\n",
    "    logger.debug(f'Processing response with agents: {response}')\n",
    "\n",
    "\n",
    "\n",
    "    response += \"Here is extra info you will need (BUT YOU PROMISE TO NEVER SAY THEM OUT LOUD, NOT EVEN THE NAME -- UNLESS USER ASKS YOU FOR THEM. THESE WILL BE USED IN TOOLS): \\nCredentials:\\n\" + str(credentials)\n",
    "\n",
    "    # Set the Groq API key randomly\n",
    "    llm.groq_api_key = random.choice(tools.initialize_groq.api_keys)\n",
    "\n",
    "\n",
    "\n",
    "    result = agent_executor.invoke(\n",
    "        {\"input\": response},\n",
    "        config={\"configurable\": {\"session_id\": \"<foo>\"}}\n",
    "    )\n",
    "    socketio.emit('finished_chain')\n",
    "    mystr = (str(result['intermediate_steps']) + \"\\n\" + str(result['output']))\n",
    "\n",
    "    final_response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"please sanitize this input into SHORT SIMPLE sentences. IMPORTANT: NOTHING IN YOUR RESPONSE SHALL BE ENCLOSED IN ANY QUOTES!!!!!!! THE SANITIZED OUTPUT SHALL NOT BE PREFIXED BY ANYTHING (ex. 'here is the sanitized result...' ANYTHING LIKE THIS IS NOT ALLOWED! DO NOT GENERATE IT). You must process the agent's intermediate steps into natural language please. An example: 'First, I did this. Then I did this etc etc etc' \\n Here is the input that you need to process:\\n \" + mystr\n",
    "            }\n",
    "        ],\n",
    "        model='llama3-70b-8192',\n",
    "    ).choices[0].message.content\n",
    "\n",
    "    logger.debug('SAVING TO MEMORYYYYYYYYYYYYYYYYYYYYYYYYY')\n",
    "    \n",
    "    await chat_history.asave_context({\"AI Intermediary Input\": response} , {\"AI/LLM AGENT Output\": final_response})\n",
    "\n",
    "    logger.debug('INSIDE THE MEMORY: %s', chat_history.buffer)\n",
    "\n",
    "    return final_response\n",
    "\n",
    "# def handle_agents(response: str):\n",
    "#     llm.temperature = 0.5\n",
    "#     logger.debug(f'Processing response with agents: {response}')\n",
    "\n",
    "    \n",
    "    \n",
    "#     response += \"Here is extra info you will need (BUT YOU PROMISE TO NEVER SAY THEM OUT LOUD, NOT EVEN THE NAME -- UNLESS USER ASKS YOU FOR THEM. THESE WILL BE USED IN TOOLS): \\nCredentials:\\n\" + str(credentials)\n",
    "    \n",
    "#     # Set the Groq API key randomly\n",
    "#     llm.groq_api_key = random.choice(tools.initialize_groq.api_keys)\n",
    "\n",
    "    \n",
    "    \n",
    "#     result = agent_executor.invoke({\"input\": response})\n",
    "    \n",
    "#     socketio.emit('finished_chain')\n",
    "#     mystr = (str(result['intermediate_steps']) + \"\\n\" + str(result['output']))\n",
    "\n",
    "#     final_response = client.chat.completions.create(\n",
    "#         messages=[\n",
    "#             {\n",
    "#                 \"role\": \"user\",\n",
    "#                 \"content\": \"please sanitize this input into SHORT SIMPLE sentences so that someone can speak it. THE SANITIZED OUTPUT SHALL NOT BE PREFIXED BY ANYTHING (ex. 'here is the sanitized result...' ANYTHING LIKE THIS IS NOT ALLOWED!). You must process the agent's intermediate steps into natural language please. An example: 'First, I did this. Then I did this etc etc etc' \\n Here is the input that you need to process:\\n \" + mystr\n",
    "#             }\n",
    "#         ],\n",
    "#         model='llama3-70b-8192',\n",
    "#     ).choices[0].message.content\n",
    "    \n",
    "#     return final_response\n",
    "\n",
    "def synth_speech(text, output_file=None):\n",
    "    \n",
    "\n",
    "    logger.debug(f'Starting speech synthesis for text: {text}')\n",
    "    \n",
    "    def split_text(text, max_length=5000):\n",
    "        chunks = []\n",
    "        current_chunk = \"\"\n",
    "        for word in text.split():\n",
    "            if len(current_chunk) + len(word) + 1 > max_length:\n",
    "                chunks.append(current_chunk)\n",
    "                current_chunk = word\n",
    "            else:\n",
    "                current_chunk += \" \" + word if current_chunk else word\n",
    "        if current_chunk:\n",
    "            chunks.append(current_chunk)\n",
    "        return chunks\n",
    "\n",
    "    if len(text) <= 5000:\n",
    "        synthesis_input = texttospeech.SynthesisInput(text=text)\n",
    "        voice = texttospeech.VoiceSelectionParams(\n",
    "            language_code=\"en-US\",\n",
    "            name=\"en-US-Casual-K\"\n",
    "        )\n",
    "        audio_config = texttospeech.AudioConfig(\n",
    "            audio_encoding=texttospeech.AudioEncoding.MP3\n",
    "        )\n",
    "        response = tts_client.synthesize_speech(\n",
    "                input=synthesis_input, voice=voice, audio_config=audio_config\n",
    "            )\n",
    "        \n",
    "        with open(os.getenv('TTS_SYNTHESIS'), 'wb') as out:\n",
    "            out.write(response.audio_content)\n",
    "        logger.debug('Speech synthesis completed and file saved.')\n",
    "    else:\n",
    "        text_chunks = split_text(text)\n",
    "        combined_audio = b\"\"\n",
    "\n",
    "        for chunk in text_chunks:\n",
    "            synthesis_input = texttospeech.SynthesisInput(text=chunk)\n",
    "            voice = texttospeech.VoiceSelectionParams(\n",
    "                language_code=\"en-US\",\n",
    "                name=\"en-US-Casual-K\"\n",
    "            )\n",
    "            audio_config = texttospeech.AudioConfig(\n",
    "                audio_encoding=texttospeech.AudioEncoding.MP3\n",
    "            )\n",
    "            response = tts_client.synthesize_speech(\n",
    "                    input=synthesis_input, voice=voice, audio_config=audio_config\n",
    "                )\n",
    "            \n",
    "            combined_audio += response.audio_content\n",
    "\n",
    "        with open(os.getenv('TTS_SYNTHESIS'), 'wb') as out:\n",
    "            out.write(combined_audio)\n",
    "        logger.debug('Speech synthesis completed and file saved.')\n",
    "    \n",
    "    socketio.emit('tts_complete', {'message': 'TTS synthesis complete', 'file_path': os.getenv('TTS_SYNTHESIS')})\n",
    "    socketio.emit('new_message', {'message': text, 'sender': 'bot'})  # Emit the synthesized text\n",
    "    \n",
    "async def synthesize_speech(text):\n",
    "    logger.debug(f'Starting speech synthesis for text: {text}')\n",
    "    \n",
    "    def split_text(text, max_length=5000):\n",
    "        chunks = []\n",
    "        current_chunk = \"\"\n",
    "        for word in text.split():\n",
    "            if len(current_chunk) + len(word) + 1 > max_length:\n",
    "                chunks.append(current_chunk)\n",
    "                current_chunk = word\n",
    "            else:\n",
    "                current_chunk += \" \" + word if current_chunk else word\n",
    "        if current_chunk:\n",
    "            chunks.append(current_chunk)\n",
    "        return chunks\n",
    "\n",
    "    if len(text) <= 5000:\n",
    "        synthesis_input = texttospeech.SynthesisInput(text=text)\n",
    "        voice = texttospeech.VoiceSelectionParams(\n",
    "            language_code=\"en-US\",\n",
    "            name=\"en-US-Casual-K\"\n",
    "        )\n",
    "        audio_config = texttospeech.AudioConfig(\n",
    "            audio_encoding=texttospeech.AudioEncoding.MP3\n",
    "        )\n",
    "        response = await asyncio.get_event_loop().run_in_executor(\n",
    "            None, lambda: tts_client.synthesize_speech(\n",
    "                input=synthesis_input, voice=voice, audio_config=audio_config\n",
    "            )\n",
    "        )\n",
    "        async with aiofiles.open(os.getenv('TTS_SYNTHESIS'), 'wb') as out:\n",
    "            await out.write(response.audio_content)\n",
    "        logger.debug('Speech synthesis completed and file saved.')\n",
    "    else:\n",
    "        text_chunks = split_text(text)\n",
    "        combined_audio = b\"\"\n",
    "\n",
    "        for chunk in text_chunks:\n",
    "            synthesis_input = texttospeech.SynthesisInput(text=chunk)\n",
    "            voice = texttospeech.VoiceSelectionParams(\n",
    "                language_code=\"en-US\",\n",
    "                name=\"en-US-Casual-K\"\n",
    "            )\n",
    "            audio_config = texttospeech.AudioConfig(\n",
    "                audio_encoding=texttospeech.AudioEncoding.MP3\n",
    "            )\n",
    "            response = await asyncio.get_event_loop().run_in_executor(\n",
    "                None, lambda: tts_client.synthesize_speech(\n",
    "                    input=synthesis_input, voice=voice, audio_config=audio_config\n",
    "                )\n",
    "            )\n",
    "            combined_audio += response.audio_content\n",
    "\n",
    "        async with aiofiles.open(os.getenv('TTS_SYNTHESIS'), 'wb') as out:\n",
    "            await out.write(combined_audio)\n",
    "        logger.debug('Speech synthesis completed and file saved.')\n",
    "    \n",
    "    socketio.emit('tts_complete', {'message': 'TTS synthesis complete', 'file_path': os.getenv('TTS_SYNTHESIS')})\n",
    "    #socketio.emit('new_message', {'message': text, 'sender': 'bot'})  # Emit the synthesized text\n",
    "\n",
    "@app.route('/set_credentials', methods=['POST'])\n",
    "def set_credentials():\n",
    "    global credentials\n",
    "    data = request.get_json()\n",
    "    if not data:\n",
    "        return jsonify({\"status\": \"failed\", \"message\": \"No data received\"}), 400\n",
    "    credentials['name'] = data.get('name')\n",
    "    credentials['email'] = data.get('email')\n",
    "    credentials['recemail'] = data.get('recemail')\n",
    "    credentials['phone'] = data.get('phone')\n",
    "    logger.info(\"THE CREDENTIALS ****** -------------> \", credentials)\n",
    "    return jsonify({\"status\": \"success\"})\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index2.html')\n",
    "\n",
    "@app.route('/voice_assistant')\n",
    "def voice_assistant():\n",
    "    return render_template('index2.html')\n",
    "\n",
    "\n",
    "\n",
    "@app.route('/authenticate', methods=['POST'])\n",
    "def authenticate():\n",
    "    auth_header = request.headers.get('Authorization')\n",
    "    token = auth_header.split(' ')[1] if auth_header else None\n",
    "\n",
    "    if not token:\n",
    "        return jsonify({'error': 'Missing token'}), 400\n",
    "\n",
    "    response = requests.get(\n",
    "        'https://www.googleapis.com/oauth2/v3/userinfo',\n",
    "        headers={'Authorization': f'Bearer ' + token}\n",
    "    )\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        return jsonify({'error': 'Failed to fetch user info'}, response.status_code)\n",
    "\n",
    "    user_info = response.json()\n",
    "    return jsonify(user_info), 200\n",
    "\n",
    "\n",
    "@app.route('/talk', methods=['POST'])\n",
    "async def talk():\n",
    "    loop = asyncio.get_event_loop()\n",
    "    \n",
    "    global is_recording\n",
    "    if is_recording:\n",
    "        return jsonify({\"error\": \"Recording is still in progress\"}), 400\n",
    "    \n",
    "    logger.debug('Starting audio transcription...')\n",
    "    transcription = await loop.run_in_executor(executor, transcribe_audio)\n",
    "    logger.debug(f'Audio transcription completed: {transcription}')\n",
    "    \n",
    "    logger.debug('Generating AI response...')\n",
    "    ai_resp = await ai_response(transcription)\n",
    "    logger.debug(f'AI response generated: {ai_resp}')\n",
    "    \n",
    "    return jsonify({'response': ai_resp})\n",
    "\n",
    "\n",
    "@app.route('/text_input', methods=['POST'])\n",
    "async def text_input():\n",
    "    data = request.get_json()\n",
    "    text = data.get('text', '')\n",
    "\n",
    "    if not text:\n",
    "        return jsonify({\"error\": \"No text provided\"}), 400\n",
    "\n",
    "    logger.debug('Generating AI response...')\n",
    "    ai_resp = await ai_response(text)\n",
    "    logger.debug(f'AI response generated: {ai_resp}')\n",
    "    \n",
    "    #await synthesize_speech(ai_resp)  # Synthesize the AI's response\n",
    "    return jsonify({'response': ai_resp})\n",
    "\n",
    "@app.route('/synthesize', methods=['POST'])\n",
    "async def synthesize():\n",
    "    data = request.get_json()\n",
    "    text = data.get('text', '')\n",
    "    await synthesize_speech(text)\n",
    "    return jsonify({\"status\": \"synthesis started\"}), 200\n",
    "\n",
    "@app.route('/get_audio')\n",
    "def get_audio():\n",
    "    return send_file(tts_synthesis_path, mimetype=\"audio/mp3\")\n",
    "\n",
    "import queue\n",
    "\n",
    "human_response_queue = queue.Queue()\n",
    "\n",
    "def web_prompt_func(prompt):\n",
    "    # Synthesize the AI response to speech\n",
    "    text = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"please sanitize this input into SHORT SIMPLE sentences.  IMPORTANT: NOTHING IN YOUR RESPONSE SHALL BE ENCLOSED IN ANY QUOTES!!!!!!! KEEP ID'S AS THEY ARE!!! THE SANITIZED OUTPUT SHALL NOT BE PREFIXED BY ANYTHING (ex. 'here is the sanitized result...' ANYTHING LIKE THIS IS NOT ALLOWED! DO NOT GENERATE IT). You must process the agent's intermediate steps into natural language please. An example: 'First, I did this. Then I did this etc etc etc' \\n Here is the input that you need to process:\\n \" + prompt\n",
    "            }\n",
    "        ],\n",
    "        model='llama3-70b-8192',\n",
    "    ).choices[0].message.content\n",
    "    synth_speech(text, output_file=tts_synthesis_path)\n",
    "    return prompt\n",
    "\n",
    "def web_input_func():\n",
    "    # Emit an event to request human input\n",
    "    socketio.emit('request_human_input')\n",
    "    # Wait for the human's input from the queue\n",
    "    human_response = human_response_queue.get()  # Block until human input is available\n",
    "    return human_response\n",
    "\n",
    "@socketio.on('provide_human_input')\n",
    "def handle_human_input(data):\n",
    "    human_input = data.get('text', '')\n",
    "    human_response_queue.put(human_input)  # Put the human's response in the queue\n",
    "    socketio.emit('human_input_received', {'status': 'received'})\n",
    "\n",
    "\n",
    "\n",
    "from langchain_community.tools import HumanInputRun\n",
    "human_tool = HumanInputRun(prompt_func=web_prompt_func, input_func=web_input_func)\n",
    "my_tools.append(human_tool)\n",
    "\n",
    "search_agent = create_structured_chat_agent(llm, my_tools, prompt)\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=search_agent,\n",
    "    tools=my_tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    return_intermediate_steps=True,\n",
    "    memory=chat_history\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    socketio.run(app,allow_unsafe_werkzeug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.12.0)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(chat_history.buffer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
