{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !pip install webrtcvad\n",
    "# !pip install pygame\n",
    "# !pip install pyaudio webrtcvad \n",
    "# !pip install google-cloud-texttospeech\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader, PyPDFLoader, WebBaseLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, TextSplitter\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.agents.agent_toolkits import ZapierToolkit\n",
    "from docx import Document\n",
    "from langchain.utilities.zapier import ZapierNLAWrapper\n",
    "from langchain.agents import initialize_agent , create_structured_chat_agent, AgentType\n",
    "import random\n",
    "from groq import Groq\n",
    "from QuoteUtils import CtxMgr\n",
    "from groq import Groq\n",
    "import random\n",
    "from langchain_groq import ChatGroq\n",
    "api_keys = ['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','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',\n",
    "            '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','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']\n",
    "\n",
    "client = Groq(\n",
    "    \n",
    "    api_key = random.choice(api_keys)\n",
    ")\n",
    "\n",
    "llm = ChatGroq(groq_api_key = client.api_key,\n",
    "               model_name = \"llama3-70b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from docx import Document\n",
    "from docx.shared import Pt, RGBColor\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "from docx.oxml.ns import qn\n",
    "from docx.oxml import OxmlElement\n",
    "from docx2pdf import convert\n",
    "from langchain.tools import BaseTool\n",
    "import re\n",
    "\n",
    "llm.groq_api_key = random.choice(api_keys)\n",
    "\n",
    "def add_section(doc, text, font_name='Arial', font_size=12, bold=False, italic=False, alignment='left', color=None):\n",
    "    # Check if the text should be a bullet point\n",
    "    if text.startswith(\"- \") or text.startswith(\"+ \"):\n",
    "        paragraph = doc.add_paragraph(style='ListBullet')\n",
    "        text = text[2:]  # Remove the bullet point indicator\n",
    "    else:\n",
    "        paragraph = doc.add_paragraph()\n",
    "    \n",
    "    run = paragraph.add_run(text)\n",
    "    run.font.name = font_name\n",
    "    run.font.size = Pt(font_size)\n",
    "    run.bold = bold\n",
    "    run.italic = italic\n",
    "    if color:\n",
    "        run.font.color.rgb = RGBColor(*color)\n",
    "    \n",
    "    if alignment == 'center':\n",
    "        paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "    elif alignment == 'right':\n",
    "        paragraph.alignment = WD_ALIGN_PARAGRAPH.RIGHT\n",
    "    else:\n",
    "        paragraph.alignment = WD_ALIGN_PARAGRAPH.LEFT\n",
    "\n",
    "\n",
    "def write_file(title, sections, append=False):\n",
    "    most_recent_file_created_path = \"most_recent_file_created.txt\"\n",
    "    if os.path.exists(most_recent_file_created_path):\n",
    "        with open(most_recent_file_created_path, 'r') as mostrec:\n",
    "            most_recent_title = mostrec.read().strip()\n",
    "        if most_recent_title:\n",
    "            \n",
    "            if most_recent_title != title:\n",
    "                title = most_recent_title\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        print(\"Most recent file created does not exist.\")\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "    documents_path = os.path.join(os.getcwd(), 'documents')\n",
    "    os.makedirs(documents_path, exist_ok=True)\n",
    "    docx_path = os.path.join(documents_path, f'{title}.docx')\n",
    "    pdf_path = os.path.join(documents_path, f'{title}.pdf')\n",
    "    \n",
    "    with open(most_recent_file_created_path,'w') as mostrec:\n",
    "        mostrec.write(title)\n",
    "        \n",
    "    if append and os.path.exists(docx_path):\n",
    "        doc = Document(docx_path)\n",
    "    else:\n",
    "        doc = Document()\n",
    "\n",
    "    for section in sections:\n",
    "        add_section(\n",
    "            doc,\n",
    "            section[\"content\"],\n",
    "            font_name=section.get(\"font_name\", \"Arial\"),\n",
    "            font_size=section.get(\"font_size\", 12),\n",
    "            bold=section.get(\"bold\", False),\n",
    "            italic=section.get(\"italic\", False),\n",
    "            alignment=section.get(\"alignment\", \"left\"),\n",
    "            color=section.get(\"color\", None)\n",
    "        )\n",
    "    \n",
    "    doc.save(docx_path)\n",
    "    convert(docx_path, pdf_path)\n",
    "\n",
    "    return f\"Document written and converted to pdf. No further action needed. STOP RIGHT THERE! THAT IS ENOUGH! NO MORE ! YOU ARE DONE! YOU ARE DONNNNEEEEEEEEEEEEE!!!!!!!! TOOL EXECUTED SUCCESSFULLY!!!!!!!!!!!!!\"\n",
    "\n",
    "\n",
    "class WriteFileTool(BaseTool):\n",
    "    name = \"write_file\"\n",
    "    description = \"Writes content into a .docx file with specified formatting and converts it to a .pdf file.\\\n",
    "        If you encounter errors, use this tool ONLY and input everything properly and try again.\\\n",
    "            IMPORTANT! - STOP AFTER ONE SUCCESSFUL EXECUTION! STOP AFTER ONE SUCCESSFUL EXECUTION! STOP AFTER ONE SUCCESSFUL EXECUTION! \"\n",
    "    \n",
    "    def _run(self, title, sections, append=False):\n",
    "        self.process_sections_in_batches(title, sections, append)\n",
    "        return (\"STOP RIGHT THERE! THAT IS ENOUGH! NO MORE ! YOU ARE DONE! YOU ARE DONNNNEEEEEEEEEEEEE!!!!!!!! TOOL EXECUTED SUCCESSFULLY!!!!!!!!!!!!!\")\n",
    "\n",
    "    def process_sections_in_batches(self, title, sections, append, batch_size=1):\n",
    "        for i in range(0, len(sections), batch_size):\n",
    "            batch = sections[i:i+batch_size]\n",
    "            result = write_file(title, batch, append=(i > 0))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def parse_formatted_response(response):\n",
    "    title_match = re.search(r'\"title\":\\s*\"([^\"]+)\"', response)\n",
    "    title = title_match.group(1) if title_match else \"Untitled Document\"\n",
    "    \n",
    "    sections_matches = re.findall(r'\\{([^}]+)\\}', response)\n",
    "    sections = []\n",
    "    for match in sections_matches:\n",
    "        section = {}\n",
    "        content_match = re.search(r'\"content\":\\s*\"([^\"]+)\"', match)\n",
    "        font_name_match = re.search(r'\"font_name\":\\s*\"([^\"]+)\"', match)\n",
    "        font_size_match = re.search(r'\"font_size\":\\s*(\\d+)', match)\n",
    "        bold_match = re.search(r'\"bold\":\\s*(true|false)', match)\n",
    "        italic_match = re.search(r'\"italic\":\\s*(true|false)', match)\n",
    "        alignment_match = re.search(r'\"alignment\":\\s*\"([^\"]+)\"', match)\n",
    "        color_match = re.search(r'\"color\":\\s*\\[(\\d+),\\s*(\\d+),\\s*(\\d+)\\]', match)\n",
    "        \n",
    "        if content_match:\n",
    "            content = content_match.group(1)\n",
    "            # Replace double quotes indicating inches with the word \"inch\"\n",
    "            content = re.sub(r'(?<=\\d)\"', ' inch', content)\n",
    "            section[\"content\"] = content\n",
    "        else:\n",
    "            section[\"content\"] = \"\"\n",
    "        \n",
    "        section[\"font_name\"] = font_name_match.group(1) if font_name_match else \"Arial\"\n",
    "        section[\"font_size\"] = int(font_size_match.group(1)) if font_size_match else 12\n",
    "        section[\"bold\"] = bold_match.group(1) == \"true\" if bold_match else False\n",
    "        section[\"italic\"] = italic_match.group(1) == \"true\" if italic_match else False\n",
    "        section[\"alignment\"] = alignment_match.group(1) if alignment_match else \"left\"\n",
    "        if color_match:\n",
    "            section[\"color\"] = (int(color_match.group(1)), int(color_match.group(2)), int(color_match.group(3)))\n",
    "        \n",
    "        sections.append(section)\n",
    "    \n",
    "    append_match = re.search(r'\"append\":\\s*(true|false)', response)\n",
    "    append = append_match.group(1) == \"true\" if append_match else False\n",
    "    \n",
    "    return title, sections, append\n",
    "\n",
    "\n",
    "# cc_out = \"\"\"Emotional Intelligence (EI) refers to the ability to recognize and understand emotions in oneself and others. It involves being aware of one's emotions and how they impact behavior, as well as being able to manage and regulate those emotions to achieve goals and maintain healthy relationships. People with high emotional intelligence are better equipped to navigate complex social situations, build stronger relationships, and make more informed decisions.\n",
    "\n",
    "# Developing emotional intelligence can have numerous benefits, both personally and professionally. It can lead to improved communication, increased empathy, and enhanced teamwork and leadership skills. Additionally, high emotional intelligence has been linked to better stress management, increased resilience, and improved overall well-being. By cultivating emotional awareness, self-regulation, and social skills, individuals can unlock their full potential and achieve greater success in all areas of life.\"\"\"\n",
    "\n",
    "\n",
    "def make_docmgr_write_to_file(cc_out):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"You are a detailed and professional assistant. Your task is to generate comprehensive and detailed formatted text. \n",
    "                Ensure everything is included without summarizing or truncating any content.\n",
    "                Your response must be well-formed and include all details. \n",
    "\n",
    "                You must ALWAYS ALWAYS ALWAYS!!!!! output in a structured format as follows AND NO QUOTATION MARKS OR BACKSLASHES!:\n",
    "                \n",
    "                            \n",
    "                {\n",
    "                    \"title\": \"The Great Renovation\",\n",
    "                    \"sections\": [\n",
    "                        {\n",
    "                            \"content\": \"<specific text content>\",\n",
    "                            \"font_name\": \"<font family>\",\n",
    "                            \"font_size\": <integer specifying font size>,\n",
    "                            \"bold\": <true or false>,\n",
    "                            \"italic\": <true or false>,\n",
    "                            \"alignment\": \"<right, left, justify or center>\"\n",
    "                            \"color\": [<integer for red>, <integer for green>, <integer for blue>]\n",
    "                        },\n",
    "                        {\n",
    "                            \"content\": \"<another specific text content>\",\n",
    "                            \"font_name\": \"<another font family>\",\n",
    "                            \"font_size\": <another integer specifying font size>,\n",
    "                            \"bold\": <true or false>,\n",
    "                            \"italic\": <true or false>,\n",
    "                            \"alignment\": \"<right, left, justify or center>\"\n",
    "                            \"color\": [<integer for red>, <integer for green>, <integer for blue>]\n",
    "                        }\n",
    "                        // ... more sections as needed\n",
    "                    ],\n",
    "                    \"append\": <true or false> (this indicates appending to document or not)\n",
    "                }\n",
    "                PLEASE! Ensure the output is well-formed and valid.\"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Give whatever file title you want;NO COLONS!. Please Include a new title IN THE DOCUMENT, headings if you deem fit, and please format in a nice readable and coherent way.  \\\n",
    "                    Specify the formatting for this text. Please make it a \\\n",
    "                        PROFESSIONALLY formatted text WITH black & blue colors and times new roman font PLEASE. NO NO NO bullet points of ANY KIND unless specified: \" + cc_out\n",
    "            }\n",
    "        ],\n",
    "        model=\"llama3-70b-8192\",\n",
    "    )\n",
    "\n",
    "    cc_out2 = chat_completion.choices[0].message.content\n",
    "\n",
    "    print('CCOUT2\\n',cc_out2)\n",
    "\n",
    "    # title, sections, append = parse_formatted_response(cc_out2)\n",
    "\n",
    "    # WriteFileTool()._run(title, sections, append)\n",
    "\n",
    "    return cc_out2\n",
    "\n",
    "#make_docmgr_write_to_file()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc-user1\\AppData\\Local\\Temp\\ipykernel_10804\\4267615534.py:191: PydanticDeprecatedSince20: `pydantic.config.Extra` is deprecated, use literal values instead (e.g. `extra='allow'`). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.7/migration/\n",
      "  extra = Extra.allow\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import BaseTool\n",
    "import os\n",
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "import googleapiclient\n",
    "import google.auth.exceptions\n",
    "\n",
    "class GoogleDriveUploadTool(BaseTool):\n",
    "    name = \"GoogleDriveUploadTool\"\n",
    "    description = (\"Uploads a PDF to Google Drive and sets permissions for a specific user. \"\n",
    "                   \"Please set the 'rename' parameter to None if the user does not want to rename the file before uploading \"\n",
    "                   \"to Google Drive. STOP AFTER ONE-TIME SUCCESSFUL EXECUTION\")\n",
    "\n",
    "    def _run(self, file_path: str, user_email: str, rename: str) -> str:\n",
    "        credentials_path = \"C:\\\\DEV\\\\WebdevFolder\\\\realestateai-doc-mgr-051849e19181.json\"\n",
    "\n",
    "        # Authenticate and create the service\n",
    "        try:\n",
    "            credentials = service_account.Credentials.from_service_account_file(credentials_path)\n",
    "            service = build('drive', 'v3', credentials=credentials)\n",
    "            print(\"Successfully authenticated and created the service.\")\n",
    "        except google.auth.exceptions.GoogleAuthError as e:\n",
    "            return f\"Authentication error: {e}\"\n",
    "\n",
    "        # File details\n",
    "        if rename is not None:\n",
    "            file_metadata = {'name': rename}\n",
    "        else:\n",
    "            file_metadata = {'name': os.path.basename(file_path)}\n",
    "\n",
    "        if not os.path.exists(file_path):\n",
    "            return f\"File not found: {file_path}\"\n",
    "        else:\n",
    "            media = MediaFileUpload(file_path, mimetype='application/pdf')\n",
    "            try:\n",
    "                # Upload file\n",
    "                file = service.files().create(body=file_metadata, media_body=media, fields='id, name, parents').execute()\n",
    "                file_id = file.get('id')\n",
    "                with open('file_id_history.txt','w') as id_hist_file:\n",
    "                    id_hist_file.write(file_id)\n",
    "                print(f\"File ID: {file_id}\")\n",
    "\n",
    "                # Verify the upload by fetching the file details\n",
    "                file_info = service.files().get(fileId=file_id, fields='id, name, parents').execute()\n",
    "                print(\"File details:\")\n",
    "                print(file_info)\n",
    "\n",
    "                # Sharing settings\n",
    "                permission = {\n",
    "                    'type': 'user',\n",
    "                    'role': 'writer',  # Set to 'reader' if read-only access is needed\n",
    "                    'emailAddress': user_email,\n",
    "                    \n",
    "                }\n",
    "                \n",
    "\n",
    "                # Grant permission to the specific user\n",
    "                try:\n",
    "                    service.permissions().create(\n",
    "                        fileId=file_id,\n",
    "                        body=permission,\n",
    "                        fields='id',\n",
    "                        sendNotificationEmail=False\n",
    "                    ).execute()\n",
    "                    \n",
    "                    print(f\"Granted {permission['role']} access to {user_email}\")\n",
    "                    \n",
    "                    \n",
    "\n",
    "                except googleapiclient.errors.HttpError as e:\n",
    "                    print(f\"Error setting permission: {e}\")\n",
    "                    return f\"Error setting permission: {e}\"\n",
    "\n",
    "                return f\"File uploaded and permissions set successfully. File ID: {file_id}. PLEASE STOP WORKING! THE TOOL HAS BEEN EXECUTED PROPERLY!\" \n",
    "\n",
    "            except Exception as e:\n",
    "                return f\"Error during file upload or conversion: {e}\"\n",
    "\n",
    "    \n",
    "\n",
    "    def _arun(self, file_path: str, user_email: str, rename: str):\n",
    "        raise NotImplementedError(\"This tool does not support asynchronous operation yet.\")\n",
    "\n",
    "# Example usage\n",
    "# tool = GoogleDriveUploadTool()\n",
    "# response = tool._run(file_path='./documents/The Great Renovation.pdf', user_email='specific-user@example.com', rename=None)\n",
    "# print(response)\n",
    "\n",
    "import os\n",
    "import google.auth\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "\n",
    "class GoogleSheetsUpdateTool(BaseTool):\n",
    "    name = \"GoogleSheetsUpdateTool\"\n",
    "    description = (\"Appends three columns - name, phone number, and link to a PDF - to a preexisting logging google sheet. STOP AFTER ONE-TIME SUCCESSFUL EXECUTION\")\n",
    "    SCOPES = ['https://www.googleapis.com/auth/spreadsheets']\n",
    "    credentials_path = 'C:\\\\DEV\\\\WebdevFolder\\\\realestateai-doc-mgr-051849e19181.json'\n",
    "    spreadsheet_id = '1TSFyiTwctC1tABr2RQouBzLRMCG4RZ7lXdTVi-I58Mo'\n",
    "    range_name = 'Sheet1'\n",
    "    \n",
    "    #creds = authenticate_google_sheets()\n",
    "    \n",
    "    def authenticate_google_sheets(self):\n",
    "        creds = service_account.Credentials.from_service_account_file(\n",
    "            self.credentials_path, scopes=self.SCOPES)\n",
    "        return creds\n",
    "    \n",
    "    def read_file_content(self, file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            content = file.read().strip()\n",
    "        return content\n",
    "    \n",
    "    # def extract_file_id(self,output):\n",
    "    #     match = re.search(r\"File ID: ([^'}]+)\", output)\n",
    "    #     if match:\n",
    "    #         file_id = match.group(1).strip()\n",
    "    #         return file_id\n",
    "    #     else:\n",
    "    #         raise ValueError(\"File ID not found in the inputted string\")\n",
    "    \n",
    "    def append_row_to_google_sheets(self, values):\n",
    "        \"\"\"\n",
    "        Appends a row to the specified range in the Google Sheets spreadsheet.\n",
    "        \n",
    "        :param values: The data to append, as a list of lists (e.g., [['A1', 'B1', 'C1']]).\n",
    "        \"\"\"\n",
    "        service = build('sheets', 'v4', credentials=self.authenticate_google_sheets())\n",
    "        sheet = service.spreadsheets()\n",
    "        body = {'values': values}\n",
    "        result = sheet.values().append(\n",
    "            spreadsheetId=self.spreadsheet_id, range=self.range_name,\n",
    "            valueInputOption=\"RAW\", body=body,\n",
    "            insertDataOption=\"INSERT_ROWS\"\n",
    "        ).execute()\n",
    "        print(f\"{result.get('updates').get('updatedCells')} cells appended.\")\n",
    "\n",
    "    def _run(self, name: str, phone_number: str, linkstr:str):\n",
    "        \"\"\"\n",
    "        Run the tool to append the row with the given name, phone number, and link to the PDF.\n",
    "        \n",
    "        :param name: The full legal name to append.\n",
    "        :param phone_number: The phone number to append.\n",
    "        \"\"\"\n",
    "        fileID = self.read_file_content('file_id_history.txt')\n",
    "        \n",
    "        print(f\"Extracted file ID: {fileID}\")\n",
    "        link = f\"https://drive.google.com/file/d/{fileID}/view\"\n",
    "        values = [[]]\n",
    "        if linkstr:\n",
    "            values = [[name, phone_number, linkstr]]\n",
    "        else:\n",
    "            values = [[name, phone_number, link]]\n",
    "        self.append_row_to_google_sheets(values)\n",
    "        return \"Row appended successfully. YOU ARE DONNNNEEEEEEEEEEEEE!!!!!!!! TOOL EXECUTED SUCCESSFULLY!!!!!!!!!!!!!\"\n",
    "\n",
    "    def _arun(self, name: str, phone_number: str):\n",
    "        raise NotImplementedError(\"This tool does not support asynchronous operation yet.\")\n",
    "    \n",
    "import os\n",
    "import base64\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.base import MIMEBase\n",
    "from email.mime.text import MIMEText\n",
    "from email import encoders\n",
    "from langchain.tools import BaseTool\n",
    "from pydantic import BaseModel, Field, Extra\n",
    "\n",
    "# If modifying these SCOPES, delete the file token.json.\n",
    "SCOPES = ['https://www.googleapis.com/auth/gmail.send']\n",
    "\n",
    "class GmailSendPdfTool(BaseTool):\n",
    "    name = \"GmailSendPdfTool\"\n",
    "    description = \"Sends an email with an optional PDF attachment using Gmail API.\"\n",
    "\n",
    "    credentials_path: str = Field(..., description=\"Path to the credentials JSON file\")\n",
    "\n",
    "    class Config:\n",
    "        extra = Extra.allow\n",
    "\n",
    "    def __init__(self, credentials_path: str):\n",
    "        super().__init__()\n",
    "        self.credentials_path = credentials_path\n",
    "        self.creds = None\n",
    "        self.service = None\n",
    "        self.authenticate()\n",
    "\n",
    "    def authenticate(self):\n",
    "        \"\"\"Authenticate the user with Gmail API.\"\"\"\n",
    "        if not self.creds or not self.creds.valid:\n",
    "            if self.creds and self.creds.expired and self.creds.refresh_token:\n",
    "                self.creds.refresh(Request())\n",
    "            else:\n",
    "                flow = InstalledAppFlow.from_client_secrets_file(self.credentials_path, SCOPES)\n",
    "                self.creds = flow.run_local_server(port=0)\n",
    "            \n",
    "        self.service = build('gmail', 'v1', credentials=self.creds)\n",
    "\n",
    "    def send_email(self, sender_email, recipient_email, subject, body, pdf_path=None):\n",
    "        \"\"\"Send an email with an optional PDF attachment.\"\"\"\n",
    "        message = MIMEMultipart()\n",
    "        message['to'] = recipient_email\n",
    "        message['from'] = sender_email\n",
    "        message['subject'] = subject\n",
    "        body_part = MIMEText(body, 'plain')\n",
    "        message.attach(body_part)\n",
    "        \n",
    "        if pdf_path:\n",
    "            part = MIMEBase('application', 'octet-stream')\n",
    "            with open(pdf_path, 'rb') as file:\n",
    "                part.set_payload(file.read())\n",
    "            encoders.encode_base64(part)\n",
    "            part.add_header('Content-Disposition', f'attachment; filename=\"{os.path.basename(pdf_path)}\"')\n",
    "            message.attach(part)\n",
    "       \n",
    "        raw_message = base64.urlsafe_b64encode(message.as_bytes()).decode()\n",
    "        raw_message = {'raw': raw_message}\n",
    "\n",
    "        try:\n",
    "            message = (self.service.users().messages().send(userId=\"me\", body=raw_message).execute())\n",
    "            print(f'Message Id: {message[\"id\"]}')\n",
    "            return message\n",
    "        except HttpError as error:\n",
    "            print(f'An error occurred: {error}')\n",
    "            return None\n",
    "\n",
    "    def _run(self, sender_email: str, recipient_email: str, subject: str, body: str, pdf_path: str = None):\n",
    "        \"\"\"Run the tool to send the email with the optional PDF attachment.\"\"\"\n",
    "        result = self.send_email(sender_email, recipient_email, subject, body, pdf_path)\n",
    "        return \"Email sent successfully. YOU ARE DONNNNEEEEEEEEEEEEE!!!!!!!! TOOL EXECUTED SUCCESSFULLY!!!!!!!!!!!!!\" if result else \"Failed to send email.\"\n",
    "\n",
    "    def _arun(self):\n",
    "        raise NotImplementedError(\"This tool does not support asynchronous operation yet.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-01 21:34:12,066 [MainThread] DEBUG: Generated new state NDVJy4Q0C70URfTbGSwsfcJzCo30no.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=291175256673-gr5p5vf3pi2h0m46h5qnd3ila4iitfqs.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A64282%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.send&state=NDVJy4Q0C70URfTbGSwsfcJzCo30no&access_type=offline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-01 21:34:20,203 [MainThread] INFO: \"GET /?state=NDVJy4Q0C70URfTbGSwsfcJzCo30no&code=4/0AdLIrYelU1vLf_B9KzYRYmOKf7BPtFYCXjFtg9rRuuVZAQFBGChscgYHHbttwhQ6bIBp7Q&scope=https://www.googleapis.com/auth/gmail.send HTTP/1.1\" 200 65\n",
      "2024-06-01 21:34:20,203 [MainThread] DEBUG: Encoding `client_id` \"291175256673-gr5p5vf3pi2h0m46h5qnd3ila4iitfqs.apps.googleusercontent.com\" with `client_secret` as Basic auth credentials.\n",
      "2024-06-01 21:34:20,203 [MainThread] DEBUG: Requesting url https://oauth2.googleapis.com/token using method POST.\n",
      "2024-06-01 21:34:20,203 [MainThread] DEBUG: Supplying headers {'Accept': 'application/json', 'Content-Type': 'application/x-www-form-urlencoded'} and data {'grant_type': 'authorization_code', 'code': '4/0AdLIrYelU1vLf_B9KzYRYmOKf7BPtFYCXjFtg9rRuuVZAQFBGChscgYHHbttwhQ6bIBp7Q', 'redirect_uri': 'http://localhost:64282/'}\n",
      "2024-06-01 21:34:20,203 [MainThread] DEBUG: Passing through key word arguments {'timeout': None, 'auth': <requests.auth.HTTPBasicAuth object at 0x00000226744768D0>, 'verify': None, 'proxies': None, 'cert': None}.\n",
      "2024-06-01 21:34:20,212 [MainThread] DEBUG: Starting new HTTPS connection (1): oauth2.googleapis.com:443\n",
      "2024-06-01 21:34:20,744 [MainThread] DEBUG: https://oauth2.googleapis.com:443 \"POST /token HTTP/1.1\" 200 None\n",
      "2024-06-01 21:34:20,744 [MainThread] DEBUG: Request to fetch token completed with status 200.\n",
      "2024-06-01 21:34:20,744 [MainThread] DEBUG: Request url was https://oauth2.googleapis.com/token\n",
      "2024-06-01 21:34:20,744 [MainThread] DEBUG: Request headers were {'User-Agent': 'python-requests/2.31.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': 'application/json', 'Connection': 'keep-alive', 'Content-Type': 'application/x-www-form-urlencoded', 'Content-Length': '157', 'Authorization': 'Basic MjkxMTc1MjU2NjczLWdyNXA1dmYzcGkyaDBtNDZoNXFuZDNpbGE0aWl0ZnFzLmFwcHMuZ29vZ2xldXNlcmNvbnRlbnQuY29tOkdPQ1NQWC1ndVFoTUJaQzNkYjdrSFVNY1RIMFdnZFBBSjJ0'}\n",
      "2024-06-01 21:34:20,744 [MainThread] DEBUG: Request body was grant_type=authorization_code&code=4%2F0AdLIrYelU1vLf_B9KzYRYmOKf7BPtFYCXjFtg9rRuuVZAQFBGChscgYHHbttwhQ6bIBp7Q&redirect_uri=http%3A%2F%2Flocalhost%3A64282%2F\n",
      "2024-06-01 21:34:20,759 [MainThread] DEBUG: Response headers were {'Cache-Control': 'no-cache, no-store, max-age=0, must-revalidate', 'Pragma': 'no-cache', 'Expires': 'Mon, 01 Jan 1990 00:00:00 GMT', 'Date': 'Sun, 02 Jun 2024 01:34:11 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Vary': 'Origin, X-Origin, Referer', 'Content-Encoding': 'gzip', 'Server': 'scaffolding on HTTPServer2', 'X-XSS-Protection': '0', 'X-Frame-Options': 'SAMEORIGIN', 'X-Content-Type-Options': 'nosniff', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000', 'Transfer-Encoding': 'chunked'} and content {\n",
      "  \"access_token\": \"ya29.a0AXooCgs53CfHNbSVUjp2yPck0L03lL2NrSthqTmY7x7nig18NXd6sCthFJNitMBnPtqwzZWPa1Z4COVhPhfIOkl2-I1sXhgGmHdvMTCK5m8RXgyf-OQ0DX5PdslXYBIVH24ALdaVPETmgN7AnVQ-jN22o6DYDhB9MIV7aCgYKAR8SARASFQHGX2MiI9laAjSR73hfTZ-Ny7K99A0171\",\n",
      "  \"expires_in\": 3599,\n",
      "  \"refresh_token\": \"1//05Vv8uY5Pd_S3CgYIARAAGAUSNwF-L9IrddzjhwfiGzViwphdDbGDygCCyVReL-QzhXh41vb-2ulQvhuTweMIXvWrEG5QEopViA0\",\n",
      "  \"scope\": \"https://www.googleapis.com/auth/gmail.send\",\n",
      "  \"token_type\": \"Bearer\"\n",
      "}.\n",
      "2024-06-01 21:34:20,759 [MainThread] DEBUG: Invoking 0 token response hooks.\n",
      "2024-06-01 21:34:20,759 [MainThread] DEBUG: Obtained token {'access_token': 'ya29.a0AXooCgs53CfHNbSVUjp2yPck0L03lL2NrSthqTmY7x7nig18NXd6sCthFJNitMBnPtqwzZWPa1Z4COVhPhfIOkl2-I1sXhgGmHdvMTCK5m8RXgyf-OQ0DX5PdslXYBIVH24ALdaVPETmgN7AnVQ-jN22o6DYDhB9MIV7aCgYKAR8SARASFQHGX2MiI9laAjSR73hfTZ-Ny7K99A0171', 'expires_in': 3599, 'refresh_token': '1//05Vv8uY5Pd_S3CgYIARAAGAUSNwF-L9IrddzjhwfiGzViwphdDbGDygCCyVReL-QzhXh41vb-2ulQvhuTweMIXvWrEG5QEopViA0', 'scope': ['https://www.googleapis.com/auth/gmail.send'], 'token_type': 'Bearer', 'expires_at': 1717295659.7599382}.\n",
      "2024-06-01 21:34:20,762 [MainThread] INFO: file_cache is only supported with oauth2client<4.0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-01 21:34:21,850 [MainThread] INFO: \u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "2024-06-01 21:34:21,850 [MainThread] INFO: \u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "2024-06-01 21:34:24,453 [Thread-8 (process_request_thread)] INFO: 127.0.0.1 - - [01/Jun/2024 21:34:24] \"GET / HTTP/1.1\" 200 -\n",
      "2024-06-01 21:34:24,484 [Thread-9 (process_request_thread)] INFO: 127.0.0.1 - - [01/Jun/2024 21:34:24] \"\u001b[36mGET /static/favicon.ico HTTP/1.1\u001b[0m\" 304 -\n",
      "2024-06-01 21:34:42,086 [Thread-10 (process_request_thread)] DEBUG: Using selector: SelectSelector\n",
      "2024-06-01 21:34:42,086 [ThreadPoolExecutor-4_0] DEBUG: Starting audio recording...\n",
      "2024-06-01 21:34:42,094 [ThreadPoolExecutor-3_0] DEBUG: Starting audio recording...\n",
      "2024-06-01 21:34:46,429 [ThreadPoolExecutor-3_0] DEBUG: Audio recording completed and file saved.\n",
      "2024-06-01 21:34:46,429 [ThreadPoolExecutor-4_0] DEBUG: Audio recording completed.\n",
      "2024-06-01 21:34:46,429 [ThreadPoolExecutor-4_0] DEBUG: Starting audio transcription...\n",
      "c:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\Lib\\site-packages\\whisper\\transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "2024-06-01 21:34:52,146 [ThreadPoolExecutor-3_0] DEBUG: Audio transcription completed:  How are you today?\n",
      "2024-06-01 21:34:52,146 [ThreadPoolExecutor-4_0] DEBUG: Audio transcription completed:  How are you today?\n",
      "2024-06-01 21:34:52,146 [ThreadPoolExecutor-4_0] DEBUG: Generating AI response...\n",
      "2024-06-01 21:34:52,146 [ThreadPoolExecutor-4_0] DEBUG: Generating AI response for transcription:  How are you today?\n",
      "2024-06-01 21:34:52,161 [ThreadPoolExecutor-4_0] DEBUG: Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a nice, great assistant. User will tell you things. You just respond. \\n                If user\\'s query relates to the following: you delegate the tasks to certain tools - namely, writing to a file, sending an email, uploading to google drive, or updating a google sheet. \\n                If what the user says is one of these three you must explicitly say AT THE END OF YOUR RESPONSE in this very format depending on which tool - \"I will use the [write file tool, gmail tool, sheets tool, OR drive upload tool]\". \\n                so that user can confirm if you got it correctly. \\n                When writing to a file, just start the content with \\'@\\' symbol when generating file content.\\n                IMPORTANT: ONCE YOU HAVE EXECUTED THE TOOL YOU MUST SAY THAT IT EXECUTED SUCCESSFULLY. \\n                IMPORTANT: IF YOU REMEMBER YOU HAVE USED A TOOL ALREADY (REFER TO CHAT HISTORY), AND YOU ARE IN THE PROCESS OF USING IT AGAIN,                 YOU MUST ASK USER IF THEY ARE SURE TO USE THE TOOL AGAIN OR NOT.\\n\\n                If you have to use a google related tool, you MUST prompt the user or remind user to enter credentials in the doc manager extension. \\n                If user tells you to do something that is not one of these, you kindly say that you don\\'t have access to that functionality.\\n                '}, {'role': 'user', 'content': ' How are you today?Here is the chat history for context (NEVER TALK ABOUT CHAT HISTORY IT IS ONLY FOR YOU NEVER TALK ABOUT IT IN YOUR RESPONSES!!!!): [[]]'}], 'model': 'llama3-70b-8192'}}\n",
      "2024-06-01 21:34:52,161 [ThreadPoolExecutor-4_0] DEBUG: connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-06-01 21:34:52,286 [ThreadPoolExecutor-4_0] DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000022674475C40>\n",
      "2024-06-01 21:34:52,286 [ThreadPoolExecutor-4_0] DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x000002266B3DF150> server_hostname='api.groq.com' timeout=5.0\n",
      "2024-06-01 21:34:52,302 [ThreadPoolExecutor-4_0] DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000022673E05C70>\n",
      "2024-06-01 21:34:52,305 [ThreadPoolExecutor-4_0] DEBUG: send_request_headers.started request=<Request [b'POST']>\n",
      "2024-06-01 21:34:52,306 [ThreadPoolExecutor-4_0] DEBUG: send_request_headers.complete\n",
      "2024-06-01 21:34:52,306 [ThreadPoolExecutor-4_0] DEBUG: send_request_body.started request=<Request [b'POST']>\n",
      "2024-06-01 21:34:52,306 [ThreadPoolExecutor-4_0] DEBUG: send_request_body.complete\n",
      "2024-06-01 21:34:52,306 [ThreadPoolExecutor-4_0] DEBUG: receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-06-01 21:34:52,685 [ThreadPoolExecutor-4_0] DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 02 Jun 2024 01:34:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5619'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'3.81s'), (b'x-request-id', b'req_01hzb9b9k1ehksgk1ev2fk2hyc'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=\":443\"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=0AK6jLe7NsIeesO_XzBxvLu02AJ1a8Um.XgfhDSZ69c-1717292083-1.0.1.1-bB3P2FKnC3cGH6hwaQNlRHtJPTzn7Xr3HSijdwN7HVNm6hjeSEq5CQS79kT4dowOiSaL_QGl01myOns488tbsw; path=/; expires=Sun, 02-Jun-24 02:04:43 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'88d3b3dd299b5997-IAD'), (b'Content-Encoding', b'gzip')])\n",
      "2024-06-01 21:34:52,685 [ThreadPoolExecutor-4_0] INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-01 21:34:52,685 [ThreadPoolExecutor-4_0] DEBUG: receive_response_body.started request=<Request [b'POST']>\n",
      "2024-06-01 21:34:52,685 [ThreadPoolExecutor-4_0] DEBUG: receive_response_body.complete\n",
      "2024-06-01 21:34:52,689 [ThreadPoolExecutor-4_0] DEBUG: response_closed.started\n",
      "2024-06-01 21:34:52,689 [ThreadPoolExecutor-4_0] DEBUG: response_closed.complete\n",
      "2024-06-01 21:34:52,689 [ThreadPoolExecutor-4_0] DEBUG: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"200 OK\"\n",
      "2024-06-01 21:34:52,689 [ThreadPoolExecutor-4_0] DEBUG: AI response generated: I'm doing great, thanks for asking! I'm ready to assist you with any tasks you have. What's on your mind today?\n",
      "2024-06-01 21:34:52,689 [ThreadPoolExecutor-4_0] DEBUG: Starting speech synthesis for text: I'm doing great, thanks for asking! I'm ready to assist you with any tasks you have. What's on your mind today?\n",
      "2024-06-01 21:34:52,689 [ThreadPoolExecutor-4_0] DEBUG: Handling response with agents: I'm doing great, thanks for asking! I'm ready to assist you with any tasks you have. What's on your mind today?\n",
      "2024-06-01 21:34:52,696 [ThreadPoolExecutor-3_1] DEBUG: Processing response with agents: I'm doing great, thanks for asking! I'm ready to assist you with any tasks you have. What's on your mind today?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-01 21:34:53,348 [ThreadPoolExecutor-4_0] DEBUG: Speech synthesis completed and file saved.\n",
      "2024-06-01 21:34:53,348 [ThreadPoolExecutor-4_0] DEBUG: AI response generated: I'm doing great, thanks for asking! I'm ready to assist you with any tasks you have. What's on your mind today?\n",
      "2024-06-01 21:34:53,348 [Thread-10 (process_request_thread)] INFO: 127.0.0.1 - - [01/Jun/2024 21:34:53] \"POST /talk HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio content written to file \"synthesis.mp3\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-01 21:35:07,798 [Thread-15 (process_request_thread)] INFO: 127.0.0.1 - - [01/Jun/2024 21:35:07] \"\u001b[35m\u001b[1mGET /get_audio?1717292093355 HTTP/1.1\u001b[0m\" 206 -\n",
      "2024-06-01 21:35:08,072 [Thread-16 (process_request_thread)] INFO: 127.0.0.1 - - [01/Jun/2024 21:35:08] \"GET /static/favicon.ico HTTP/1.1\" 200 -\n",
      "2024-06-01 21:35:19,740 [Thread-17 (process_request_thread)] DEBUG: Using selector: SelectSelector\n",
      "2024-06-01 21:35:19,740 [ThreadPoolExecutor-5_0] DEBUG: Starting audio recording...\n",
      "2024-06-01 21:35:19,745 [ThreadPoolExecutor-3_1] DEBUG: Starting audio recording...\n",
      "2024-06-01 21:35:28,004 [ThreadPoolExecutor-3_1] DEBUG: Audio recording completed and file saved.\n",
      "2024-06-01 21:35:28,021 [ThreadPoolExecutor-5_0] DEBUG: Audio recording completed.\n",
      "2024-06-01 21:35:28,021 [ThreadPoolExecutor-5_0] DEBUG: Starting audio transcription...\n",
      "2024-06-01 21:35:32,953 [ThreadPoolExecutor-3_0] DEBUG: Audio transcription completed:  Can you write an essay about chat GPT to a file?\n",
      "2024-06-01 21:35:32,953 [ThreadPoolExecutor-5_0] DEBUG: Audio transcription completed:  Can you write an essay about chat GPT to a file?\n",
      "2024-06-01 21:35:32,953 [ThreadPoolExecutor-5_0] DEBUG: Generating AI response...\n",
      "2024-06-01 21:35:32,953 [ThreadPoolExecutor-5_0] DEBUG: Generating AI response for transcription:  Can you write an essay about chat GPT to a file?\n",
      "2024-06-01 21:35:32,959 [ThreadPoolExecutor-5_0] DEBUG: Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a nice, great assistant. User will tell you things. You just respond. \\n                If user\\'s query relates to the following: you delegate the tasks to certain tools - namely, writing to a file, sending an email, uploading to google drive, or updating a google sheet. \\n                If what the user says is one of these three you must explicitly say AT THE END OF YOUR RESPONSE in this very format depending on which tool - \"I will use the [write file tool, gmail tool, sheets tool, OR drive upload tool]\". \\n                so that user can confirm if you got it correctly. \\n                When writing to a file, just start the content with \\'@\\' symbol when generating file content.\\n                IMPORTANT: ONCE YOU HAVE EXECUTED THE TOOL YOU MUST SAY THAT IT EXECUTED SUCCESSFULLY. \\n                IMPORTANT: IF YOU REMEMBER YOU HAVE USED A TOOL ALREADY (REFER TO CHAT HISTORY), AND YOU ARE IN THE PROCESS OF USING IT AGAIN,                 YOU MUST ASK USER IF THEY ARE SURE TO USE THE TOOL AGAIN OR NOT.\\n\\n                If you have to use a google related tool, you MUST prompt the user or remind user to enter credentials in the doc manager extension. \\n                If user tells you to do something that is not one of these, you kindly say that you don\\'t have access to that functionality.\\n                '}, {'role': 'user', 'content': ' Can you write an essay about chat GPT to a file?Here is the chat history for context (NEVER TALK ABOUT CHAT HISTORY IT IS ONLY FOR YOU NEVER TALK ABOUT IT IN YOUR RESPONSES!!!!): [[\"USER:  How are you today?\\\\nTHE AI MODEL: I\\'m doing great, thanks for asking! I\\'m ready to assist you with any tasks you have. What\\'s on your mind today?\\\\n\"]]'}], 'model': 'llama3-70b-8192'}}\n",
      "2024-06-01 21:35:32,959 [ThreadPoolExecutor-5_0] DEBUG: close.started\n",
      "2024-06-01 21:35:32,959 [ThreadPoolExecutor-5_0] DEBUG: close.complete\n",
      "2024-06-01 21:35:32,959 [ThreadPoolExecutor-5_0] DEBUG: connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-06-01 21:35:32,987 [ThreadPoolExecutor-5_0] DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002267797FE60>\n",
      "2024-06-01 21:35:32,987 [ThreadPoolExecutor-5_0] DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x000002266B3DF150> server_hostname='api.groq.com' timeout=5.0\n",
      "2024-06-01 21:35:33,008 [ThreadPoolExecutor-5_0] DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000022674467DD0>\n",
      "2024-06-01 21:35:33,008 [ThreadPoolExecutor-5_0] DEBUG: send_request_headers.started request=<Request [b'POST']>\n",
      "2024-06-01 21:35:33,008 [ThreadPoolExecutor-5_0] DEBUG: send_request_headers.complete\n",
      "2024-06-01 21:35:33,008 [ThreadPoolExecutor-5_0] DEBUG: send_request_body.started request=<Request [b'POST']>\n",
      "2024-06-01 21:35:33,008 [ThreadPoolExecutor-5_0] DEBUG: send_request_body.complete\n",
      "2024-06-01 21:35:33,008 [ThreadPoolExecutor-5_0] DEBUG: receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-06-01 21:35:33,699 [ThreadPoolExecutor-5_0] DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 02 Jun 2024 01:35:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5572'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'4.28s'), (b'x-request-id', b'req_01hzb9chbne2raj1x2zjfzmxsg'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=\":443\"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'88d3b4db9f133b42-IAD'), (b'Content-Encoding', b'gzip')])\n",
      "2024-06-01 21:35:33,699 [ThreadPoolExecutor-5_0] INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-01 21:35:33,699 [ThreadPoolExecutor-5_0] DEBUG: receive_response_body.started request=<Request [b'POST']>\n",
      "2024-06-01 21:35:33,699 [ThreadPoolExecutor-5_0] DEBUG: receive_response_body.complete\n",
      "2024-06-01 21:35:33,699 [ThreadPoolExecutor-5_0] DEBUG: response_closed.started\n",
      "2024-06-01 21:35:33,699 [ThreadPoolExecutor-5_0] DEBUG: response_closed.complete\n",
      "2024-06-01 21:35:33,703 [ThreadPoolExecutor-5_0] DEBUG: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"200 OK\"\n",
      "2024-06-01 21:35:33,703 [ThreadPoolExecutor-5_0] DEBUG: AI response generated: I'd be happy to write an essay about chat GPT to a file. \n",
      "\n",
      "Here's the content of the file:\n",
      "\n",
      "@Chat GPT is a revolutionary artificial intelligence model that has been designed to engage in natural-sounding conversations with humans. It uses a massive language model that is trained on a vast amount of text data, allowing it to understand and respond to a wide range of questions and topics. One of the key features of chat GPT is its ability to learn and adapt to the context of a conversation, allowing it to provide more accurate and relevant responses as the conversation progresses. \n",
      "\n",
      "I will use the write file tool.\n",
      "2024-06-01 21:35:33,703 [ThreadPoolExecutor-5_0] DEBUG: Starting speech synthesis for text: I'd be happy to write an essay about chat GPT to a file. \n",
      "\n",
      "Here's the content of the file:\n",
      "\n",
      "@Chat GPT is a revolutionary artificial intelligence model that has been designed to engage in natural-sounding conversations with humans. It uses a massive language model that is trained on a vast amount of text data, allowing it to understand and respond to a wide range of questions and topics. One of the key features of chat GPT is its ability to learn and adapt to the context of a conversation, allowing it to provide more accurate and relevant responses as the conversation progresses. \n",
      "\n",
      "I will use the write file tool.\n",
      "2024-06-01 21:35:33,707 [ThreadPoolExecutor-5_0] DEBUG: Handling response with agents: I'd be happy to write an essay about chat GPT to a file. \n",
      "\n",
      "Here's the content of the file:\n",
      "\n",
      "@Chat GPT is a revolutionary artificial intelligence model that has been designed to engage in natural-sounding conversations with humans. It uses a massive language model that is trained on a vast amount of text data, allowing it to understand and respond to a wide range of questions and topics. One of the key features of chat GPT is its ability to learn and adapt to the context of a conversation, allowing it to provide more accurate and relevant responses as the conversation progresses. \n",
      "\n",
      "I will use the write file tool.\n",
      "2024-06-01 21:35:33,707 [ThreadPoolExecutor-3_0] DEBUG: Processing response with agents: I'd be happy to write an essay about chat GPT to a file. \n",
      "\n",
      "Here's the content of the file:\n",
      "\n",
      "@Chat GPT is a revolutionary artificial intelligence model that has been designed to engage in natural-sounding conversations with humans. It uses a massive language model that is trained on a vast amount of text data, allowing it to understand and respond to a wide range of questions and topics. One of the key features of chat GPT is its ability to learn and adapt to the context of a conversation, allowing it to provide more accurate and relevant responses as the conversation progresses. \n",
      "\n",
      "I will use the write file tool.\n",
      "2024-06-01 21:35:33,707 [ThreadPoolExecutor-3_0] DEBUG: Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a detailed and professional assistant. Your task is to generate comprehensive and detailed formatted text. \\n                Ensure everything is included without summarizing or truncating any content.\\n                Your response must be well-formed and include all details. \\n\\n                You must ALWAYS ALWAYS ALWAYS!!!!! output in a structured format as follows AND NO QUOTATION MARKS OR BACKSLASHES!:\\n                \\n                            \\n                {\\n                    \"title\": \"The Great Renovation\",\\n                    \"sections\": [\\n                        {\\n                            \"content\": \"<specific text content>\",\\n                            \"font_name\": \"<font family>\",\\n                            \"font_size\": <integer specifying font size>,\\n                            \"bold\": <true or false>,\\n                            \"italic\": <true or false>,\\n                            \"alignment\": \"<right, left, justify or center>\"\\n                            \"color\": [<integer for red>, <integer for green>, <integer for blue>]\\n                        },\\n                        {\\n                            \"content\": \"<another specific text content>\",\\n                            \"font_name\": \"<another font family>\",\\n                            \"font_size\": <another integer specifying font size>,\\n                            \"bold\": <true or false>,\\n                            \"italic\": <true or false>,\\n                            \"alignment\": \"<right, left, justify or center>\"\\n                            \"color\": [<integer for red>, <integer for green>, <integer for blue>]\\n                        }\\n                        // ... more sections as needed\\n                    ],\\n                    \"append\": <true or false> (this indicates appending to document or not)\\n                }\\n                PLEASE! Ensure the output is well-formed and valid.'}, {'role': 'user', 'content': 'Give whatever file title you want;NO COLONS!. Please Include a new title IN THE DOCUMENT, headings if you deem fit, and please format in a nice readable and coherent way.                      Specify the formatting for this text. Please make it a                         PROFESSIONALLY formatted text WITH black & blue colors and times new roman font PLEASE. NO NO NO bullet points of ANY KIND unless specified: Chat GPT is a revolutionary artificial intelligence model that has been designed to engage in natural-sounding conversations with humans. It uses a massive language model that is trained on a vast amount of text data, allowing it to understand and respond to a wide range of questions and topics. One of the key features of chat GPT is its ability to learn and adapt to the context of a conversation, allowing it to provide more accurate and relevant responses as the conversation progresses. \\n\\nI will use the write file tool.'}], 'model': 'llama3-70b-8192'}}\n",
      "2024-06-01 21:35:33,714 [ThreadPoolExecutor-3_0] DEBUG: send_request_headers.started request=<Request [b'POST']>\n",
      "2024-06-01 21:35:33,714 [ThreadPoolExecutor-3_0] DEBUG: send_request_headers.complete\n",
      "2024-06-01 21:35:33,714 [ThreadPoolExecutor-3_0] DEBUG: send_request_body.started request=<Request [b'POST']>\n",
      "2024-06-01 21:35:33,718 [ThreadPoolExecutor-3_0] DEBUG: send_request_body.complete\n",
      "2024-06-01 21:35:33,719 [ThreadPoolExecutor-3_0] DEBUG: receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "MODIFIED RESPONSE =  Chat GPT is a revolutionary artificial intelligence model that has been designed to engage in natural-sounding conversations with humans. It uses a massive language model that is trained on a vast amount of text data, allowing it to understand and respond to a wide range of questions and topics. One of the key features of chat GPT is its ability to learn and adapt to the context of a conversation, allowing it to provide more accurate and relevant responses as the conversation progresses. \n",
      "\n",
      "I will use the write file tool.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-01 21:35:34,520 [ThreadPoolExecutor-5_0] DEBUG: Speech synthesis completed and file saved.\n",
      "2024-06-01 21:35:34,520 [ThreadPoolExecutor-5_0] DEBUG: AI response generated: I'd be happy to write an essay about chat GPT to a file. \n",
      "\n",
      "Here's the content of the file:\n",
      "\n",
      "@Chat GPT is a revolutionary artificial intelligence model that has been designed to engage in natural-sounding conversations with humans. It uses a massive language model that is trained on a vast amount of text data, allowing it to understand and respond to a wide range of questions and topics. One of the key features of chat GPT is its ability to learn and adapt to the context of a conversation, allowing it to provide more accurate and relevant responses as the conversation progresses. \n",
      "\n",
      "I will use the write file tool.\n",
      "2024-06-01 21:35:34,520 [Thread-17 (process_request_thread)] INFO: 127.0.0.1 - - [01/Jun/2024 21:35:34] \"POST /talk HTTP/1.1\" 200 -\n",
      "2024-06-01 21:35:34,537 [Thread-21 (process_request_thread)] INFO: 127.0.0.1 - - [01/Jun/2024 21:35:34] \"\u001b[35m\u001b[1mGET /get_audio?1717292134536 HTTP/1.1\u001b[0m\" 206 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio content written to file \"synthesis.mp3\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-01 21:35:35,104 [ThreadPoolExecutor-3_0] DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 02 Jun 2024 01:35:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'5279'), (b'x-ratelimit-reset-requests', b'11.305s'), (b'x-ratelimit-reset-tokens', b'7.21s'), (b'x-request-id', b'req_01hzb9cj19e8gt8n1s2x16039p'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=\":443\"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'88d3b4dffc073b42-IAD'), (b'Content-Encoding', b'gzip')])\n",
      "2024-06-01 21:35:35,104 [ThreadPoolExecutor-3_0] INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-01 21:35:35,106 [ThreadPoolExecutor-3_0] DEBUG: receive_response_body.started request=<Request [b'POST']>\n",
      "2024-06-01 21:35:35,106 [ThreadPoolExecutor-3_0] DEBUG: receive_response_body.complete\n",
      "2024-06-01 21:35:35,106 [ThreadPoolExecutor-3_0] DEBUG: response_closed.started\n",
      "2024-06-01 21:35:35,106 [ThreadPoolExecutor-3_0] DEBUG: response_closed.complete\n",
      "2024-06-01 21:35:35,109 [ThreadPoolExecutor-3_0] DEBUG: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"200 OK\"\n",
      "2024-06-01 21:35:35,126 [ThreadPoolExecutor-3_0] DEBUG: Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\nwrite_file: Writes content into a .docx file with specified formatting and converts it to a .pdf file.        If you encounter errors, use this tool ONLY and input everything properly and try again.            IMPORTANT! - STOP AFTER ONE SUCCESSFUL EXECUTION! STOP AFTER ONE SUCCESSFUL EXECUTION! STOP AFTER ONE SUCCESSFUL EXECUTION! , args: {\\'title\\': {\\'title\\': \\'Title\\'}, \\'sections\\': {\\'title\\': \\'Sections\\'}, \\'append\\': {\\'title\\': \\'Append\\', \\'default\\': False}}\\nGoogleDriveUploadTool: Uploads a PDF to Google Drive and sets permissions for a specific user. Please set the \\'rename\\' parameter to None if the user does not want to rename the file before uploading to Google Drive. STOP AFTER ONE-TIME SUCCESSFUL EXECUTION, args: {\\'file_path\\': {\\'title\\': \\'File Path\\', \\'type\\': \\'string\\'}, \\'user_email\\': {\\'title\\': \\'User Email\\', \\'type\\': \\'string\\'}, \\'rename\\': {\\'title\\': \\'Rename\\', \\'type\\': \\'string\\'}}\\nGoogleSheetsUpdateTool: Appends three columns - name, phone number, and link to a PDF - to a preexisting logging google sheet. STOP AFTER ONE-TIME SUCCESSFUL EXECUTION, args: {\\'name\\': {\\'title\\': \\'Name\\', \\'type\\': \\'string\\'}, \\'phone_number\\': {\\'title\\': \\'Phone Number\\', \\'type\\': \\'string\\'}, \\'linkstr\\': {\\'title\\': \\'Linkstr\\', \\'type\\': \\'string\\'}}\\nGmailSendPdfTool: Sends an email with an optional PDF attachment using Gmail API., args: {\\'sender_email\\': {\\'title\\': \\'Sender Email\\', \\'type\\': \\'string\\'}, \\'recipient_email\\': {\\'title\\': \\'Recipient Email\\', \\'type\\': \\'string\\'}, \\'subject\\': {\\'title\\': \\'Subject\\', \\'type\\': \\'string\\'}, \\'body\\': {\\'title\\': \\'Body\\', \\'type\\': \\'string\\'}, \\'pdf_path\\': {\\'title\\': \\'Pdf Path\\', \\'type\\': \\'string\\'}}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \"action\" values: \"Final Answer\" or write_file, GoogleDriveUploadTool, GoogleSheetsUpdateTool, GmailSendPdfTool\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}\\n```\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\\nThought:'}, {'role': 'user', 'content': 'use ONLY write_file tool!!! INPUT EVERYTHING CORRECTLY!!!!!!!! INPUT ONLY WHAT YOURE GIVEN ! NO CREATIVITIES!!!! append-->true or false lowercase only!!! --> TITLE: Revolutionary Conversations, SECTIONS: [{\"content\": \"Revolutionary Conversations\", \"font_name\": \"Times New Roman\", \"font_size\": 24, \"bold\": true, \"italic\": false, \"alignment\": \"center\", \"color\": [0, 0, 0]}, {\"content\": \"Artificial Intelligence in Conversation\", \"font_name\": \"Times New Roman\", \"font_size\": 18, \"bold\": true, \"italic\": false, \"alignment\": \"center\", \"color\": [0, 0, 255]}, {\"content\": \"Chat GPT is a revolutionary artificial intelligence model that has been designed to engage in natural-sounding conversations with humans.\", \"font_name\": \"Times New Roman\", \"font_size\": 12, \"bold\": false, \"italic\": false, \"alignment\": \"justify\", \"color\": [0, 0, 0]}, {\"content\": \"It uses a massive language model that is trained on a vast amount of text data, allowing it to understand and respond to a wide range of questions and topics.\", \"font_name\": \"Times New Roman\", \"font_size\": 12, \"bold\": false, \"italic\": false, \"alignment\": \"justify\", \"color\": [0, 0, 0]}, {\"content\": \"One of the key features of chat GPT is its ability to learn and adapt to the context of a conversation, allowing it to provide more accurate and relevant responses as the conversation progresses.\", \"font_name\": \"Times New Roman\", \"font_size\": 12, \"bold\": false, \"italic\": false, \"alignment\": \"justify\", \"color\": [0, 0, 0]}], APPEND: True\\n\\n'}], 'model': 'llama3-70b-8192', 'n': 1, 'stop': ['Observation:'], 'stream': False, 'temperature': 0.7}}\n",
      "2024-06-01 21:35:35,126 [ThreadPoolExecutor-3_0] DEBUG: connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=None socket_options=None\n",
      "2024-06-01 21:35:35,146 [ThreadPoolExecutor-3_0] DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000022674477200>\n",
      "2024-06-01 21:35:35,146 [ThreadPoolExecutor-3_0] DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x000002266B3DF1D0> server_hostname='api.groq.com' timeout=None\n",
      "2024-06-01 21:35:35,166 [ThreadPoolExecutor-3_0] DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000022674476060>\n",
      "2024-06-01 21:35:35,166 [ThreadPoolExecutor-3_0] DEBUG: send_request_headers.started request=<Request [b'POST']>\n",
      "2024-06-01 21:35:35,170 [ThreadPoolExecutor-3_0] DEBUG: send_request_headers.complete\n",
      "2024-06-01 21:35:35,170 [ThreadPoolExecutor-3_0] DEBUG: send_request_body.started request=<Request [b'POST']>\n",
      "2024-06-01 21:35:35,170 [ThreadPoolExecutor-3_0] DEBUG: send_request_body.complete\n",
      "2024-06-01 21:35:35,174 [ThreadPoolExecutor-3_0] DEBUG: receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCOUT2\n",
      " {\n",
      "\"title\": \"Revolutionary Conversations\",\n",
      "\"sections\": [\n",
      "{\n",
      "\"content\": \"Revolutionary Conversations\",\n",
      "\"font_name\": \"Times New Roman\",\n",
      "\"font_size\": 24,\n",
      "\"bold\": true,\n",
      "\"italic\": false,\n",
      "\"alignment\": \"center\",\n",
      "\"color\": [0, 0, 0]\n",
      "},\n",
      "{\n",
      "\"content\": \"Artificial Intelligence in Conversation\",\n",
      "\"font_name\": \"Times New Roman\",\n",
      "\"font_size\": 18,\n",
      "\"bold\": true,\n",
      "\"italic\": false,\n",
      "\"alignment\": \"center\",\n",
      "\"color\": [0, 0, 255]\n",
      "},\n",
      "{\n",
      "\"content\": \"Chat GPT is a revolutionary artificial intelligence model that has been designed to engage in natural-sounding conversations with humans.\",\n",
      "\"font_name\": \"Times New Roman\",\n",
      "\"font_size\": 12,\n",
      "\"bold\": false,\n",
      "\"italic\": false,\n",
      "\"alignment\": \"justify\",\n",
      "\"color\": [0, 0, 0]\n",
      "},\n",
      "{\n",
      "\"content\": \"It uses a massive language model that is trained on a vast amount of text data, allowing it to understand and respond to a wide range of questions and topics.\",\n",
      "\"font_name\": \"Times New Roman\",\n",
      "\"font_size\": 12,\n",
      "\"bold\": false,\n",
      "\"italic\": false,\n",
      "\"alignment\": \"justify\",\n",
      "\"color\": [0, 0, 0]\n",
      "},\n",
      "{\n",
      "\"content\": \"One of the key features of chat GPT is its ability to learn and adapt to the context of a conversation, allowing it to provide more accurate and relevant responses as the conversation progresses.\",\n",
      "\"font_name\": \"Times New Roman\",\n",
      "\"font_size\": 12,\n",
      "\"bold\": false,\n",
      "\"italic\": false,\n",
      "\"alignment\": \"justify\",\n",
      "\"color\": [0, 0, 0]\n",
      "}],\n",
      "\"append\": true\n",
      "}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-01 21:35:36,926 [ThreadPoolExecutor-3_0] DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 02 Jun 2024 01:35:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14397'), (b'x-ratelimit-remaining-tokens', b'4981'), (b'x-ratelimit-reset-requests', b'16.551999999s'), (b'x-ratelimit-reset-tokens', b'10.19s'), (b'x-request-id', b'req_01hzb9ckekepaa5nmhj2t9hevv'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=\":443\"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=AYDyuU6EB_iFBMsGKgKKusZnvZuOTAt_rqVpjECuG70-1717292127-1.0.1.1-ljVHyaf9p2qrw3sOTOGcYjNqCBmCS8Sr0Kt.LOF5NTLG0VtMbGNQgtsmAhCM7H9IRPkbSDNG3RZfHUx4VbUXzg; path=/; expires=Sun, 02-Jun-24 02:05:27 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'88d3b4e90c148215-IAD'), (b'Content-Encoding', b'gzip')])\n",
      "2024-06-01 21:35:36,926 [ThreadPoolExecutor-3_0] INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-01 21:35:36,926 [ThreadPoolExecutor-3_0] DEBUG: receive_response_body.started request=<Request [b'POST']>\n",
      "2024-06-01 21:35:36,926 [ThreadPoolExecutor-3_0] DEBUG: receive_response_body.complete\n",
      "2024-06-01 21:35:36,926 [ThreadPoolExecutor-3_0] DEBUG: response_closed.started\n",
      "2024-06-01 21:35:36,926 [ThreadPoolExecutor-3_0] DEBUG: response_closed.complete\n",
      "2024-06-01 21:35:36,926 [ThreadPoolExecutor-3_0] DEBUG: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"write_file\",\n",
      "  \"action_input\": {\n",
      "    \"title\": \"Revolutionary Conversations\",\n",
      "    \"sections\": [\n",
      "      {\"content\": \"Revolutionary Conversations\", \"font_name\": \"Times New Roman\", \"font_size\": 24, \"bold\": true, \"italic\": false, \"alignment\": \"center\", \"color\": [0, 0, 0]},\n",
      "      {\"content\": \"Artificial Intelligence in Conversation\", \"font_name\": \"Times New Roman\", \"font_size\": 18, \"bold\": true, \"italic\": false, \"alignment\": \"center\", \"color\": [0, 0, 255]},\n",
      "      {\"content\": \"Chat GPT is a revolutionary artificial intelligence model that has been designed to engage in natural-sounding conversations with humans.\", \"font_name\": \"Times New Roman\", \"font_size\": 12, \"bold\": false, \"italic\": false, \"alignment\": \"justify\", \"color\": [0, 0, 0]},\n",
      "      {\"content\": \"It uses a massive language model that is trained on a vast amount of text data, allowing it to understand and respond to a wide range of questions and topics.\", \"font_name\": \"Times New Roman\", \"font_size\": 12, \"bold\": false, \"italic\": false, \"alignment\": \"justify\", \"color\": [0, 0, 0]},\n",
      "      {\"content\": \"One of the key features of chat GPT is its ability to learn and adapt to the context of a conversation, allowing it to provide more accurate and relevant responses as the conversation progresses.\", \"font_name\": \"Times New Roman\", \"font_size\": 12, \"bold\": false, \"italic\": false, \"alignment\": \"justify\", \"color\": [0, 0, 0]}\n",
      "    ],\n",
      "    \"append\": true\n",
      "  }\n",
      "}\n",
      "```\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.37s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.49s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/it]\n",
      "2024-06-01 21:35:51,576 [ThreadPoolExecutor-3_0] DEBUG: Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\nwrite_file: Writes content into a .docx file with specified formatting and converts it to a .pdf file.        If you encounter errors, use this tool ONLY and input everything properly and try again.            IMPORTANT! - STOP AFTER ONE SUCCESSFUL EXECUTION! STOP AFTER ONE SUCCESSFUL EXECUTION! STOP AFTER ONE SUCCESSFUL EXECUTION! , args: {\\'title\\': {\\'title\\': \\'Title\\'}, \\'sections\\': {\\'title\\': \\'Sections\\'}, \\'append\\': {\\'title\\': \\'Append\\', \\'default\\': False}}\\nGoogleDriveUploadTool: Uploads a PDF to Google Drive and sets permissions for a specific user. Please set the \\'rename\\' parameter to None if the user does not want to rename the file before uploading to Google Drive. STOP AFTER ONE-TIME SUCCESSFUL EXECUTION, args: {\\'file_path\\': {\\'title\\': \\'File Path\\', \\'type\\': \\'string\\'}, \\'user_email\\': {\\'title\\': \\'User Email\\', \\'type\\': \\'string\\'}, \\'rename\\': {\\'title\\': \\'Rename\\', \\'type\\': \\'string\\'}}\\nGoogleSheetsUpdateTool: Appends three columns - name, phone number, and link to a PDF - to a preexisting logging google sheet. STOP AFTER ONE-TIME SUCCESSFUL EXECUTION, args: {\\'name\\': {\\'title\\': \\'Name\\', \\'type\\': \\'string\\'}, \\'phone_number\\': {\\'title\\': \\'Phone Number\\', \\'type\\': \\'string\\'}, \\'linkstr\\': {\\'title\\': \\'Linkstr\\', \\'type\\': \\'string\\'}}\\nGmailSendPdfTool: Sends an email with an optional PDF attachment using Gmail API., args: {\\'sender_email\\': {\\'title\\': \\'Sender Email\\', \\'type\\': \\'string\\'}, \\'recipient_email\\': {\\'title\\': \\'Recipient Email\\', \\'type\\': \\'string\\'}, \\'subject\\': {\\'title\\': \\'Subject\\', \\'type\\': \\'string\\'}, \\'body\\': {\\'title\\': \\'Body\\', \\'type\\': \\'string\\'}, \\'pdf_path\\': {\\'title\\': \\'Pdf Path\\', \\'type\\': \\'string\\'}}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \"action\" values: \"Final Answer\" or write_file, GoogleDriveUploadTool, GoogleSheetsUpdateTool, GmailSendPdfTool\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}\\n```\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\\nThought:'}, {'role': 'user', 'content': 'use ONLY write_file tool!!! INPUT EVERYTHING CORRECTLY!!!!!!!! INPUT ONLY WHAT YOURE GIVEN ! NO CREATIVITIES!!!! append-->true or false lowercase only!!! --> TITLE: Revolutionary Conversations, SECTIONS: [{\"content\": \"Revolutionary Conversations\", \"font_name\": \"Times New Roman\", \"font_size\": 24, \"bold\": true, \"italic\": false, \"alignment\": \"center\", \"color\": [0, 0, 0]}, {\"content\": \"Artificial Intelligence in Conversation\", \"font_name\": \"Times New Roman\", \"font_size\": 18, \"bold\": true, \"italic\": false, \"alignment\": \"center\", \"color\": [0, 0, 255]}, {\"content\": \"Chat GPT is a revolutionary artificial intelligence model that has been designed to engage in natural-sounding conversations with humans.\", \"font_name\": \"Times New Roman\", \"font_size\": 12, \"bold\": false, \"italic\": false, \"alignment\": \"justify\", \"color\": [0, 0, 0]}, {\"content\": \"It uses a massive language model that is trained on a vast amount of text data, allowing it to understand and respond to a wide range of questions and topics.\", \"font_name\": \"Times New Roman\", \"font_size\": 12, \"bold\": false, \"italic\": false, \"alignment\": \"justify\", \"color\": [0, 0, 0]}, {\"content\": \"One of the key features of chat GPT is its ability to learn and adapt to the context of a conversation, allowing it to provide more accurate and relevant responses as the conversation progresses.\", \"font_name\": \"Times New Roman\", \"font_size\": 12, \"bold\": false, \"italic\": false, \"alignment\": \"justify\", \"color\": [0, 0, 0]}], APPEND: True\\n\\nThis was your previous work (but I haven\\'t seen any of it! I only see what you return as final answer):\\nAction:\\n```\\n{\\n  \"action\": \"write_file\",\\n  \"action_input\": {\\n    \"title\": \"Revolutionary Conversations\",\\n    \"sections\": [\\n      {\"content\": \"Revolutionary Conversations\", \"font_name\": \"Times New Roman\", \"font_size\": 24, \"bold\": true, \"italic\": false, \"alignment\": \"center\", \"color\": [0, 0, 0]},\\n      {\"content\": \"Artificial Intelligence in Conversation\", \"font_name\": \"Times New Roman\", \"font_size\": 18, \"bold\": true, \"italic\": false, \"alignment\": \"center\", \"color\": [0, 0, 255]},\\n      {\"content\": \"Chat GPT is a revolutionary artificial intelligence model that has been designed to engage in natural-sounding conversations with humans.\", \"font_name\": \"Times New Roman\", \"font_size\": 12, \"bold\": false, \"italic\": false, \"alignment\": \"justify\", \"color\": [0, 0, 0]},\\n      {\"content\": \"It uses a massive language model that is trained on a vast amount of text data, allowing it to understand and respond to a wide range of questions and topics.\", \"font_name\": \"Times New Roman\", \"font_size\": 12, \"bold\": false, \"italic\": false, \"alignment\": \"justify\", \"color\": [0, 0, 0]},\\n      {\"content\": \"One of the key features of chat GPT is its ability to learn and adapt to the context of a conversation, allowing it to provide more accurate and relevant responses as the conversation progresses.\", \"font_name\": \"Times New Roman\", \"font_size\": 12, \"bold\": false, \"italic\": false, \"alignment\": \"justify\", \"color\": [0, 0, 0]}\\n    ],\\n    \"append\": true\\n  }\\n}\\n```\\n\\nObservation: STOP RIGHT THERE! THAT IS ENOUGH! NO MORE ! YOU ARE DONE! YOU ARE DONNNNEEEEEEEEEEEEE!!!!!!!! TOOL EXECUTED SUCCESSFULLY!!!!!!!!!!!!!\\nThought:'}], 'model': 'llama3-70b-8192', 'n': 1, 'stop': ['Observation:'], 'stream': False, 'temperature': 0.7}}\n",
      "2024-06-01 21:35:51,576 [ThreadPoolExecutor-3_0] DEBUG: close.started\n",
      "2024-06-01 21:35:51,576 [ThreadPoolExecutor-3_0] DEBUG: close.complete\n",
      "2024-06-01 21:35:51,576 [ThreadPoolExecutor-3_0] DEBUG: connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=None socket_options=None\n",
      "2024-06-01 21:35:51,589 [ThreadPoolExecutor-3_0] DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000226744767B0>\n",
      "2024-06-01 21:35:51,589 [ThreadPoolExecutor-3_0] DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x000002266B3DF1D0> server_hostname='api.groq.com' timeout=None\n",
      "2024-06-01 21:35:51,606 [ThreadPoolExecutor-3_0] DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000022673E958E0>\n",
      "2024-06-01 21:35:51,609 [ThreadPoolExecutor-3_0] DEBUG: send_request_headers.started request=<Request [b'POST']>\n",
      "2024-06-01 21:35:51,609 [ThreadPoolExecutor-3_0] DEBUG: send_request_headers.complete\n",
      "2024-06-01 21:35:51,609 [ThreadPoolExecutor-3_0] DEBUG: send_request_body.started request=<Request [b'POST']>\n",
      "2024-06-01 21:35:51,609 [ThreadPoolExecutor-3_0] DEBUG: send_request_body.complete\n",
      "2024-06-01 21:35:51,609 [ThreadPoolExecutor-3_0] DEBUG: receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mSTOP RIGHT THERE! THAT IS ENOUGH! NO MORE ! YOU ARE DONE! YOU ARE DONNNNEEEEEEEEEEEEE!!!!!!!! TOOL EXECUTED SUCCESSFULLY!!!!!!!!!!!!!\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-01 21:35:52,192 [ThreadPoolExecutor-3_0] DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 02 Jun 2024 01:35:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'4554'), (b'x-ratelimit-reset-requests', b'7.550999999s'), (b'x-ratelimit-reset-tokens', b'14.46s'), (b'x-request-id', b'req_01hzb9d3ghfyystt728s3cr47x'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=\":443\"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'88d3b54fc84a3b66-IAD'), (b'Content-Encoding', b'gzip')])\n",
      "2024-06-01 21:35:52,192 [ThreadPoolExecutor-3_0] INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-01 21:35:52,192 [ThreadPoolExecutor-3_0] DEBUG: receive_response_body.started request=<Request [b'POST']>\n",
      "2024-06-01 21:35:52,192 [ThreadPoolExecutor-3_0] DEBUG: receive_response_body.complete\n",
      "2024-06-01 21:35:52,192 [ThreadPoolExecutor-3_0] DEBUG: response_closed.started\n",
      "2024-06-01 21:35:52,192 [ThreadPoolExecutor-3_0] DEBUG: response_closed.complete\n",
      "2024-06-01 21:35:52,192 [ThreadPoolExecutor-3_0] DEBUG: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"File created successfully!\"\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-01 21:36:15,457 [Thread-22 (process_request_thread)] DEBUG: Using selector: SelectSelector\n",
      "2024-06-01 21:36:15,457 [ThreadPoolExecutor-6_0] DEBUG: Starting audio recording...\n",
      "2024-06-01 21:36:15,457 [ThreadPoolExecutor-3_1] DEBUG: Starting audio recording...\n",
      "2024-06-01 21:36:19,278 [ThreadPoolExecutor-3_1] DEBUG: Audio recording completed and file saved.\n",
      "2024-06-01 21:36:19,278 [ThreadPoolExecutor-6_0] DEBUG: Audio recording completed.\n",
      "2024-06-01 21:36:19,286 [ThreadPoolExecutor-6_0] DEBUG: Starting audio transcription...\n",
      "c:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\Lib\\site-packages\\whisper\\transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "2024-06-01 21:36:23,965 [ThreadPoolExecutor-3_0] DEBUG: Audio transcription completed:  Thank you so much.\n",
      "2024-06-01 21:36:23,965 [ThreadPoolExecutor-6_0] DEBUG: Audio transcription completed:  Thank you so much.\n",
      "2024-06-01 21:36:23,965 [ThreadPoolExecutor-6_0] DEBUG: Generating AI response...\n",
      "2024-06-01 21:36:23,965 [ThreadPoolExecutor-6_0] DEBUG: Generating AI response for transcription:  Thank you so much.\n",
      "2024-06-01 21:36:23,965 [ThreadPoolExecutor-6_0] DEBUG: Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a nice, great assistant. User will tell you things. You just respond. \\n                If user\\'s query relates to the following: you delegate the tasks to certain tools - namely, writing to a file, sending an email, uploading to google drive, or updating a google sheet. \\n                If what the user says is one of these three you must explicitly say AT THE END OF YOUR RESPONSE in this very format depending on which tool - \"I will use the [write file tool, gmail tool, sheets tool, OR drive upload tool]\". \\n                so that user can confirm if you got it correctly. \\n                When writing to a file, just start the content with \\'@\\' symbol when generating file content.\\n                IMPORTANT: ONCE YOU HAVE EXECUTED THE TOOL YOU MUST SAY THAT IT EXECUTED SUCCESSFULLY. \\n                IMPORTANT: IF YOU REMEMBER YOU HAVE USED A TOOL ALREADY (REFER TO CHAT HISTORY), AND YOU ARE IN THE PROCESS OF USING IT AGAIN,                 YOU MUST ASK USER IF THEY ARE SURE TO USE THE TOOL AGAIN OR NOT.\\n\\n                If you have to use a google related tool, you MUST prompt the user or remind user to enter credentials in the doc manager extension. \\n                If user tells you to do something that is not one of these, you kindly say that you don\\'t have access to that functionality.\\n                '}, {'role': 'user', 'content': ' Thank you so much.Here is the chat history for context (NEVER TALK ABOUT CHAT HISTORY IT IS ONLY FOR YOU NEVER TALK ABOUT IT IN YOUR RESPONSES!!!!): [[\"USER:  How are you today?\\\\nTHE AI MODEL: I\\'m doing great, thanks for asking! I\\'m ready to assist you with any tasks you have. What\\'s on your mind today?\\\\n\", \"USER:  Can you write an essay about chat GPT to a file?\\\\nTHE AI MODEL: I\\'d be happy to write an essay about chat GPT to a file. \\\\n\\\\nHere\\'s the content of the file:\\\\n\\\\n@Chat GPT is a revolutionary artificial intelligence model that has been designed to engage in natural-sounding conversations with humans. It uses a massive language model that is trained on a vast amount of text data, allowing it to understand and respond to a wide range of questions and topics. One of the key features of chat GPT is its ability to learn and adapt to the context of a conversation, allowing it to provide more accurate and relevant responses as the conversation progresses. \\\\n\\\\nI will use the write file tool.\\\\n\"]]'}], 'model': 'llama3-70b-8192'}}\n",
      "2024-06-01 21:36:23,972 [ThreadPoolExecutor-6_0] DEBUG: close.started\n",
      "2024-06-01 21:36:23,972 [ThreadPoolExecutor-6_0] DEBUG: close.complete\n",
      "2024-06-01 21:36:23,972 [ThreadPoolExecutor-6_0] DEBUG: connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "2024-06-01 21:36:24,102 [ThreadPoolExecutor-6_0] DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000022677A21880>\n",
      "2024-06-01 21:36:24,102 [ThreadPoolExecutor-6_0] DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x000002266B3DF150> server_hostname='api.groq.com' timeout=5.0\n",
      "2024-06-01 21:36:24,122 [ThreadPoolExecutor-6_0] DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000022674477830>\n",
      "2024-06-01 21:36:24,122 [ThreadPoolExecutor-6_0] DEBUG: send_request_headers.started request=<Request [b'POST']>\n",
      "2024-06-01 21:36:24,122 [ThreadPoolExecutor-6_0] DEBUG: send_request_headers.complete\n",
      "2024-06-01 21:36:24,122 [ThreadPoolExecutor-6_0] DEBUG: send_request_body.started request=<Request [b'POST']>\n",
      "2024-06-01 21:36:24,122 [ThreadPoolExecutor-6_0] DEBUG: send_request_body.complete\n",
      "2024-06-01 21:36:24,122 [ThreadPoolExecutor-6_0] DEBUG: receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-06-01 21:36:24,801 [ThreadPoolExecutor-6_0] DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 02 Jun 2024 01:36:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14399'), (b'x-ratelimit-remaining-tokens', b'5404'), (b'x-ratelimit-reset-requests', b'6s'), (b'x-ratelimit-reset-tokens', b'5.96s'), (b'x-request-id', b'req_01hzb9e38hehrb0tvkaf61gva9'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=\":443\"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'88d3b61aff2007fb-IAD'), (b'Content-Encoding', b'gzip')])\n",
      "2024-06-01 21:36:24,801 [ThreadPoolExecutor-6_0] INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-01 21:36:24,801 [ThreadPoolExecutor-6_0] DEBUG: receive_response_body.started request=<Request [b'POST']>\n",
      "2024-06-01 21:36:24,801 [ThreadPoolExecutor-6_0] DEBUG: receive_response_body.complete\n",
      "2024-06-01 21:36:24,806 [ThreadPoolExecutor-6_0] DEBUG: response_closed.started\n",
      "2024-06-01 21:36:24,806 [ThreadPoolExecutor-6_0] DEBUG: response_closed.complete\n",
      "2024-06-01 21:36:24,806 [ThreadPoolExecutor-6_0] DEBUG: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"200 OK\"\n",
      "2024-06-01 21:36:24,806 [ThreadPoolExecutor-6_0] DEBUG: AI response generated: You'd like me to write an essay about chat GPT to a file, which I've completed. Here is the content of the file:\n",
      "\n",
      "@Chat GPT is a revolutionary artificial intelligence model that has been designed to engage in natural-sounding conversations with humans. It uses a massive language model that is trained on a vast amount of text data, allowing it to understand and respond to a wide range of questions and topics. One of the key features of chat GPT is its ability to learn and adapt to the context of a conversation, allowing it to provide more accurate and relevant responses as the conversation progresses.\n",
      "\n",
      "I will use the write file tool.\n",
      "\n",
      "Executable successfully!\n",
      "2024-06-01 21:36:24,806 [ThreadPoolExecutor-6_0] DEBUG: Starting speech synthesis for text: You'd like me to write an essay about chat GPT to a file, which I've completed. Here is the content of the file:\n",
      "\n",
      "@Chat GPT is a revolutionary artificial intelligence model that has been designed to engage in natural-sounding conversations with humans. It uses a massive language model that is trained on a vast amount of text data, allowing it to understand and respond to a wide range of questions and topics. One of the key features of chat GPT is its ability to learn and adapt to the context of a conversation, allowing it to provide more accurate and relevant responses as the conversation progresses.\n",
      "\n",
      "I will use the write file tool.\n",
      "\n",
      "Executable successfully!\n",
      "2024-06-01 21:36:24,813 [ThreadPoolExecutor-6_0] DEBUG: Handling response with agents: You'd like me to write an essay about chat GPT to a file, which I've completed. Here is the content of the file:\n",
      "\n",
      "@Chat GPT is a revolutionary artificial intelligence model that has been designed to engage in natural-sounding conversations with humans. It uses a massive language model that is trained on a vast amount of text data, allowing it to understand and respond to a wide range of questions and topics. One of the key features of chat GPT is its ability to learn and adapt to the context of a conversation, allowing it to provide more accurate and relevant responses as the conversation progresses.\n",
      "\n",
      "I will use the write file tool.\n",
      "\n",
      "Executable successfully!\n",
      "2024-06-01 21:36:24,815 [ThreadPoolExecutor-3_0] DEBUG: Processing response with agents: You'd like me to write an essay about chat GPT to a file, which I've completed. Here is the content of the file:\n",
      "\n",
      "@Chat GPT is a revolutionary artificial intelligence model that has been designed to engage in natural-sounding conversations with humans. It uses a massive language model that is trained on a vast amount of text data, allowing it to understand and respond to a wide range of questions and topics. One of the key features of chat GPT is its ability to learn and adapt to the context of a conversation, allowing it to provide more accurate and relevant responses as the conversation progresses.\n",
      "\n",
      "I will use the write file tool.\n",
      "\n",
      "Executable successfully!\n",
      "2024-06-01 21:36:24,820 [ThreadPoolExecutor-3_0] DEBUG: Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a detailed and professional assistant. Your task is to generate comprehensive and detailed formatted text. \\n                Ensure everything is included without summarizing or truncating any content.\\n                Your response must be well-formed and include all details. \\n\\n                You must ALWAYS ALWAYS ALWAYS!!!!! output in a structured format as follows AND NO QUOTATION MARKS OR BACKSLASHES!:\\n                \\n                            \\n                {\\n                    \"title\": \"The Great Renovation\",\\n                    \"sections\": [\\n                        {\\n                            \"content\": \"<specific text content>\",\\n                            \"font_name\": \"<font family>\",\\n                            \"font_size\": <integer specifying font size>,\\n                            \"bold\": <true or false>,\\n                            \"italic\": <true or false>,\\n                            \"alignment\": \"<right, left, justify or center>\"\\n                            \"color\": [<integer for red>, <integer for green>, <integer for blue>]\\n                        },\\n                        {\\n                            \"content\": \"<another specific text content>\",\\n                            \"font_name\": \"<another font family>\",\\n                            \"font_size\": <another integer specifying font size>,\\n                            \"bold\": <true or false>,\\n                            \"italic\": <true or false>,\\n                            \"alignment\": \"<right, left, justify or center>\"\\n                            \"color\": [<integer for red>, <integer for green>, <integer for blue>]\\n                        }\\n                        // ... more sections as needed\\n                    ],\\n                    \"append\": <true or false> (this indicates appending to document or not)\\n                }\\n                PLEASE! Ensure the output is well-formed and valid.'}, {'role': 'user', 'content': 'Give whatever file title you want;NO COLONS!. Please Include a new title IN THE DOCUMENT, headings if you deem fit, and please format in a nice readable and coherent way.                      Specify the formatting for this text. Please make it a                         PROFESSIONALLY formatted text WITH black & blue colors and times new roman font PLEASE. NO NO NO bullet points of ANY KIND unless specified: Chat GPT is a revolutionary artificial intelligence model that has been designed to engage in natural-sounding conversations with humans. It uses a massive language model that is trained on a vast amount of text data, allowing it to understand and respond to a wide range of questions and topics. One of the key features of chat GPT is its ability to learn and adapt to the context of a conversation, allowing it to provide more accurate and relevant responses as the conversation progresses.\\n\\nI will use the write file tool.\\n\\nExecutable successfully!'}], 'model': 'llama3-70b-8192'}}\n",
      "2024-06-01 21:36:24,820 [ThreadPoolExecutor-3_0] DEBUG: send_request_headers.started request=<Request [b'POST']>\n",
      "2024-06-01 21:36:24,820 [ThreadPoolExecutor-3_0] DEBUG: send_request_headers.complete\n",
      "2024-06-01 21:36:24,820 [ThreadPoolExecutor-3_0] DEBUG: send_request_body.started request=<Request [b'POST']>\n",
      "2024-06-01 21:36:24,820 [ThreadPoolExecutor-3_0] DEBUG: send_request_body.complete\n",
      "2024-06-01 21:36:24,828 [ThreadPoolExecutor-3_0] DEBUG: receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "MODIFIED RESPONSE =  Chat GPT is a revolutionary artificial intelligence model that has been designed to engage in natural-sounding conversations with humans. It uses a massive language model that is trained on a vast amount of text data, allowing it to understand and respond to a wide range of questions and topics. One of the key features of chat GPT is its ability to learn and adapt to the context of a conversation, allowing it to provide more accurate and relevant responses as the conversation progresses.\n",
      "\n",
      "I will use the write file tool.\n",
      "\n",
      "Executable successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-01 21:36:25,648 [ThreadPoolExecutor-6_0] DEBUG: Speech synthesis completed and file saved.\n",
      "2024-06-01 21:36:25,648 [ThreadPoolExecutor-6_0] DEBUG: AI response generated: You'd like me to write an essay about chat GPT to a file, which I've completed. Here is the content of the file:\n",
      "\n",
      "@Chat GPT is a revolutionary artificial intelligence model that has been designed to engage in natural-sounding conversations with humans. It uses a massive language model that is trained on a vast amount of text data, allowing it to understand and respond to a wide range of questions and topics. One of the key features of chat GPT is its ability to learn and adapt to the context of a conversation, allowing it to provide more accurate and relevant responses as the conversation progresses.\n",
      "\n",
      "I will use the write file tool.\n",
      "\n",
      "Executable successfully!\n",
      "2024-06-01 21:36:25,648 [Thread-22 (process_request_thread)] INFO: 127.0.0.1 - - [01/Jun/2024 21:36:25] \"POST /talk HTTP/1.1\" 200 -\n",
      "2024-06-01 21:36:25,665 [Thread-26 (process_request_thread)] INFO: 127.0.0.1 - - [01/Jun/2024 21:36:25] \"\u001b[35m\u001b[1mGET /get_audio?1717292185663 HTTP/1.1\u001b[0m\" 206 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio content written to file \"synthesis.mp3\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-01 21:36:26,459 [ThreadPoolExecutor-3_0] DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 02 Jun 2024 01:36:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14398'), (b'x-ratelimit-remaining-tokens', b'5273'), (b'x-ratelimit-reset-requests', b'11.224999999s'), (b'x-ratelimit-reset-tokens', b'7.27s'), (b'x-request-id', b'req_01hzb9e3yhfkpact09pc7rv6qs'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=\":443\"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'88d3b61f5cc207fb-IAD'), (b'Content-Encoding', b'gzip')])\n",
      "2024-06-01 21:36:26,464 [ThreadPoolExecutor-3_0] INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-01 21:36:26,464 [ThreadPoolExecutor-3_0] DEBUG: receive_response_body.started request=<Request [b'POST']>\n",
      "2024-06-01 21:36:26,467 [ThreadPoolExecutor-3_0] DEBUG: receive_response_body.complete\n",
      "2024-06-01 21:36:26,467 [ThreadPoolExecutor-3_0] DEBUG: response_closed.started\n",
      "2024-06-01 21:36:26,470 [ThreadPoolExecutor-3_0] DEBUG: response_closed.complete\n",
      "2024-06-01 21:36:26,470 [ThreadPoolExecutor-3_0] DEBUG: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"200 OK\"\n",
      "2024-06-01 21:36:26,470 [ThreadPoolExecutor-3_0] DEBUG: Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\nwrite_file: Writes content into a .docx file with specified formatting and converts it to a .pdf file.        If you encounter errors, use this tool ONLY and input everything properly and try again.            IMPORTANT! - STOP AFTER ONE SUCCESSFUL EXECUTION! STOP AFTER ONE SUCCESSFUL EXECUTION! STOP AFTER ONE SUCCESSFUL EXECUTION! , args: {\\'title\\': {\\'title\\': \\'Title\\'}, \\'sections\\': {\\'title\\': \\'Sections\\'}, \\'append\\': {\\'title\\': \\'Append\\', \\'default\\': False}}\\nGoogleDriveUploadTool: Uploads a PDF to Google Drive and sets permissions for a specific user. Please set the \\'rename\\' parameter to None if the user does not want to rename the file before uploading to Google Drive. STOP AFTER ONE-TIME SUCCESSFUL EXECUTION, args: {\\'file_path\\': {\\'title\\': \\'File Path\\', \\'type\\': \\'string\\'}, \\'user_email\\': {\\'title\\': \\'User Email\\', \\'type\\': \\'string\\'}, \\'rename\\': {\\'title\\': \\'Rename\\', \\'type\\': \\'string\\'}}\\nGoogleSheetsUpdateTool: Appends three columns - name, phone number, and link to a PDF - to a preexisting logging google sheet. STOP AFTER ONE-TIME SUCCESSFUL EXECUTION, args: {\\'name\\': {\\'title\\': \\'Name\\', \\'type\\': \\'string\\'}, \\'phone_number\\': {\\'title\\': \\'Phone Number\\', \\'type\\': \\'string\\'}, \\'linkstr\\': {\\'title\\': \\'Linkstr\\', \\'type\\': \\'string\\'}}\\nGmailSendPdfTool: Sends an email with an optional PDF attachment using Gmail API., args: {\\'sender_email\\': {\\'title\\': \\'Sender Email\\', \\'type\\': \\'string\\'}, \\'recipient_email\\': {\\'title\\': \\'Recipient Email\\', \\'type\\': \\'string\\'}, \\'subject\\': {\\'title\\': \\'Subject\\', \\'type\\': \\'string\\'}, \\'body\\': {\\'title\\': \\'Body\\', \\'type\\': \\'string\\'}, \\'pdf_path\\': {\\'title\\': \\'Pdf Path\\', \\'type\\': \\'string\\'}}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \"action\" values: \"Final Answer\" or write_file, GoogleDriveUploadTool, GoogleSheetsUpdateTool, GmailSendPdfTool\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}\\n```\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\\nThought:'}, {'role': 'user', 'content': 'use ONLY write_file tool!!! INPUT EVERYTHING CORRECTLY!!!!!!!! INPUT ONLY WHAT YOURE GIVEN ! NO CREATIVITIES!!!! append-->true or false lowercase only!!! --> TITLE: AI Conversational Revolution, SECTIONS: [{\"content\": \"AI Conversational Revolution\", \"font_name\": \"Times New Roman\", \"font_size\": 24, \"bold\": true, \"italic\": false, \"alignment\": \"center\", \"color\": [0, 0, 0]}, {\"content\": \"Chat GPT: The Future of Conversational AI\", \"font_name\": \"Times New Roman\", \"font_size\": 18, \"bold\": true, \"italic\": false, \"alignment\": \"center\", \"color\": [0, 0, 255]}, {\"content\": \"Chat GPT is a revolutionary artificial intelligence model that has been designed to engage in natural-sounding conversations with humans.\", \"font_name\": \"Times New Roman\", \"font_size\": 12, \"bold\": false, \"italic\": false, \"alignment\": \"justify\", \"color\": [0, 0, 0]}, {\"content\": \"It uses a massive language model that is trained on a vast amount of text data, allowing it to understand and respond to a wide range of questions and topics.\", \"font_name\": \"Times New Roman\", \"font_size\": 12, \"bold\": false, \"italic\": false, \"alignment\": \"justify\", \"color\": [0, 0, 0]}, {\"content\": \"One of the key features of chat GPT is its ability to learn and adapt to the context of a conversation, allowing it to provide more accurate and relevant responses as the conversation progresses.\", \"font_name\": \"Times New Roman\", \"font_size\": 12, \"bold\": false, \"italic\": false, \"alignment\": \"justify\", \"color\": [0, 0, 0]}, {\"content\": \"Executable successfully!\", \"font_name\": \"Times New Roman\", \"font_size\": 12, \"bold\": true, \"italic\": false, \"alignment\": \"center\", \"color\": [0, 0, 0]}], APPEND: True\\n\\n'}], 'model': 'llama3-70b-8192', 'n': 1, 'stop': ['Observation:'], 'stream': False, 'temperature': 0.7}}\n",
      "2024-06-01 21:36:26,479 [ThreadPoolExecutor-3_0] DEBUG: close.started\n",
      "2024-06-01 21:36:26,481 [ThreadPoolExecutor-3_0] DEBUG: close.complete\n",
      "2024-06-01 21:36:26,481 [ThreadPoolExecutor-3_0] DEBUG: connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=None socket_options=None\n",
      "2024-06-01 21:36:26,489 [ThreadPoolExecutor-3_0] DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000022674476090>\n",
      "2024-06-01 21:36:26,489 [ThreadPoolExecutor-3_0] DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x000002266B3DF1D0> server_hostname='api.groq.com' timeout=None\n",
      "2024-06-01 21:36:26,509 [ThreadPoolExecutor-3_0] DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000022674476330>\n",
      "2024-06-01 21:36:26,514 [ThreadPoolExecutor-3_0] DEBUG: send_request_headers.started request=<Request [b'POST']>\n",
      "2024-06-01 21:36:26,514 [ThreadPoolExecutor-3_0] DEBUG: send_request_headers.complete\n",
      "2024-06-01 21:36:26,514 [ThreadPoolExecutor-3_0] DEBUG: send_request_body.started request=<Request [b'POST']>\n",
      "2024-06-01 21:36:26,514 [ThreadPoolExecutor-3_0] DEBUG: send_request_body.complete\n",
      "2024-06-01 21:36:26,519 [ThreadPoolExecutor-3_0] DEBUG: receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCOUT2\n",
      " Here is the formatted text:\n",
      "\n",
      "{\n",
      "\"title\": \"AI Conversational Revolution\",\n",
      "\"sections\": [\n",
      "{\n",
      "\"content\": \"AI Conversational Revolution\",\n",
      "\"font_name\": \"Times New Roman\",\n",
      "\"font_size\": 24,\n",
      "\"bold\": true,\n",
      "\"italic\": false,\n",
      "\"alignment\": \"center\",\n",
      "\"color\": [0, 0, 0]\n",
      "},\n",
      "{\n",
      "\"content\": \"Chat GPT: The Future of Conversational AI\",\n",
      "\"font_name\": \"Times New Roman\",\n",
      "\"font_size\": 18,\n",
      "\"bold\": true,\n",
      "\"italic\": false,\n",
      "\"alignment\": \"center\",\n",
      "\"color\": [0, 0, 255]\n",
      "},\n",
      "{\n",
      "\"content\": \"Chat GPT is a revolutionary artificial intelligence model that has been designed to engage in natural-sounding conversations with humans.\",\n",
      "\"font_name\": \"Times New Roman\",\n",
      "\"font_size\": 12,\n",
      "\"bold\": false,\n",
      "\"italic\": false,\n",
      "\"alignment\": \"justify\",\n",
      "\"color\": [0, 0, 0]\n",
      "},\n",
      "{\n",
      "\"content\": \"It uses a massive language model that is trained on a vast amount of text data, allowing it to understand and respond to a wide range of questions and topics.\",\n",
      "\"font_name\": \"Times New Roman\",\n",
      "\"font_size\": 12,\n",
      "\"bold\": false,\n",
      "\"italic\": false,\n",
      "\"alignment\": \"justify\",\n",
      "\"color\": [0, 0, 0]\n",
      "},\n",
      "{\n",
      "\"content\": \"One of the key features of chat GPT is its ability to learn and adapt to the context of a conversation, allowing it to provide more accurate and relevant responses as the conversation progresses.\",\n",
      "\"font_name\": \"Times New Roman\",\n",
      "\"font_size\": 12,\n",
      "\"bold\": false,\n",
      "\"italic\": false,\n",
      "\"alignment\": \"justify\",\n",
      "\"color\": [0, 0, 0]\n",
      "},\n",
      "{\n",
      "\"content\": \"Executable successfully!\",\n",
      "\"font_name\": \"Times New Roman\",\n",
      "\"font_size\": 12,\n",
      "\"bold\": true,\n",
      "\"italic\": false,\n",
      "\"alignment\": \"center\",\n",
      "\"color\": [0, 0, 0]\n",
      "}\n",
      "],\n",
      "\"append\": true\n",
      "}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-01 21:36:28,351 [ThreadPoolExecutor-3_0] DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 02 Jun 2024 01:36:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-ratelimit-limit-requests', b'14400'), (b'x-ratelimit-limit-tokens', b'6000'), (b'x-ratelimit-remaining-requests', b'14397'), (b'x-ratelimit-remaining-tokens', b'4939'), (b'x-ratelimit-reset-requests', b'16.385999999s'), (b'x-ratelimit-reset-tokens', b'10.61s'), (b'x-request-id', b'req_01hzb9e5k7f5avz84cyt9tycpn'), (b'via', b'1.1 google'), (b'alt-svc', b'h3=\":443\"; ma=86400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'88d3b629f9cb7ffd-IAD'), (b'Content-Encoding', b'gzip')])\n",
      "2024-06-01 21:36:28,351 [ThreadPoolExecutor-3_0] INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-01 21:36:28,351 [ThreadPoolExecutor-3_0] DEBUG: receive_response_body.started request=<Request [b'POST']>\n",
      "2024-06-01 21:36:28,351 [ThreadPoolExecutor-3_0] DEBUG: receive_response_body.complete\n",
      "2024-06-01 21:36:28,351 [ThreadPoolExecutor-3_0] DEBUG: response_closed.started\n",
      "2024-06-01 21:36:28,351 [ThreadPoolExecutor-3_0] DEBUG: response_closed.complete\n",
      "2024-06-01 21:36:28,351 [ThreadPoolExecutor-3_0] DEBUG: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"write_file\",\n",
      "  \"action_input\": {\n",
      "    \"title\": \"AI Conversational Revolution\",\n",
      "    \"sections\": [{\"content\": \"AI Conversational Revolution\", \"font_name\": \"Times New Roman\", \"font_size\": 24, \"bold\": true, \"italic\": false, \"alignment\": \"center\", \"color\": [0, 0, 0]}, {\"content\": \"Chat GPT: The Future of Conversational AI\", \"font_name\": \"Times New Roman\", \"font_size\": 18, \"bold\": true, \"italic\": false, \"alignment\": \"center\", \"color\": [0, 0, 255]}, {\"content\": \"Chat GPT is a revolutionary artificial intelligence model that has been designed to engage in natural-sounding conversations with humans.\", \"font_name\": \"Times New Roman\", \"font_size\": 12, \"bold\": false, \"italic\": false, \"alignment\": \"justify\", \"color\": [0, 0, 0]}, {\"content\": \"It uses a massive language model that is trained on a vast amount of text data, allowing it to understand and respond to a wide range of questions and topics.\", \"font_name\": \"Times New Roman\", \"font_size\": 12, \"bold\": false, \"italic\": false, \"alignment\": \"justify\", \"color\": [0, 0, 0]}, {\"content\": \"One of the key features of chat GPT is its ability to learn and adapt to the context of a conversation, allowing it to provide more accurate and relevant responses as the conversation progresses.\", \"font_name\": \"Times New Roman\", \"font_size\": 12, \"bold\": false, \"italic\": false, \"alignment\": \"justify\", \"color\": [0, 0, 0]}, {\"content\": \"Executable successfully!\", \"font_name\": \"Times New Roman\", \"font_size\": 12, \"bold\": true, \"italic\": false, \"alignment\": \"center\", \"color\": [0, 0, 0]}],\n",
      "    \"append\": true\n",
      "  }\n",
      "}\n",
      "```\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.33it/s]"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, send_file, render_template\n",
    "import whisper\n",
    "import pyaudio\n",
    "import wave\n",
    "import webrtcvad\n",
    "import collections\n",
    "import base64\n",
    "from google.cloud import texttospeech\n",
    "import json\n",
    "import random\n",
    "import asyncio\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import aiofiles\n",
    "from aiogoogle import Aiogoogle\n",
    "from flask_cors import CORS\n",
    "\n",
    "import json\n",
    "from langchain.agents import Tool\n",
    "my_tools = []\n",
    "\n",
    "\n",
    "\n",
    "my_tools.append(\n",
    "    \n",
    "    WriteFileTool()\n",
    "    \n",
    ")\n",
    "\n",
    "my_tools.append(\n",
    "    \n",
    "    GoogleDriveUploadTool()\n",
    "    \n",
    ")\n",
    "\n",
    "my_tools.append(\n",
    "    \n",
    "    GoogleSheetsUpdateTool()\n",
    "    \n",
    ")\n",
    "credentials_path = \"C:\\\\DEV\\\\WebdevFolder\\\\client_secret_291175256673-gr5p5vf3pi2h0m46h5qnd3ila4iitfqs.apps.googleusercontent.com.json\"\n",
    "my_tools.append(\n",
    "    GmailSendPdfTool(credentials_path)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "llm.groq_api_key = random.choice(api_keys)\n",
    "agent = initialize_agent(my_tools,llm,handle_parsing_errors=True,agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "from flask import Flask, request, jsonify, send_file, render_template\n",
    "import whisper\n",
    "import pyaudio\n",
    "import wave\n",
    "import webrtcvad\n",
    "import collections\n",
    "import base64\n",
    "from google.cloud import texttospeech\n",
    "import json\n",
    "import random\n",
    "import asyncio\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from flask_cors import CORS\n",
    "import uuid\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s [%(threadName)s] %(levelname)s: %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# Global variables\n",
    "chat_history = []\n",
    "model = whisper.load_model(\"base\")\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "CHUNK = 1024\n",
    "RECORD_SECONDS = 1000000\n",
    "vad = webrtcvad.Vad(3)\n",
    "audio = pyaudio.PyAudio()\n",
    "credentials = {\"name\": \"\", \"email\": \"\", \"recemail\": \"\", \"phone\": \"\"}\n",
    "\n",
    "# Initialize text-to-speech client\n",
    "tts_client = texttospeech.TextToSpeechClient.from_service_account_file(\"C:\\\\DEV\\\\WebdevFolder\\\\realestateai-doc-mgr-051849e19181.json\")\n",
    "\n",
    "executor = ThreadPoolExecutor(max_workers=5)\n",
    "\n",
    "def record_audio():\n",
    "    logger.debug('Starting audio recording...')\n",
    "    try:\n",
    "        stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                            rate=RATE, input=True,\n",
    "                            frames_per_buffer=CHUNK)\n",
    "        frames = []\n",
    "        ring_buffer = collections.deque(maxlen=100)\n",
    "        triggered = False\n",
    "        voiced_frames = []\n",
    "        silence_threshold = 10\n",
    "        silence_chunks = 0\n",
    "\n",
    "        for _ in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "            data = stream.read(CHUNK)\n",
    "            frames.append(data)\n",
    "\n",
    "            num_subframes = int(len(data) / 320)\n",
    "            for i in range(num_subframes):\n",
    "                subframe = data[i*320:(i+1)*320]\n",
    "                is_speech = vad.is_speech(subframe, RATE)\n",
    "                ring_buffer.append((subframe, is_speech))\n",
    "\n",
    "            num_voiced = len([f for f, speech in ring_buffer if speech])\n",
    "\n",
    "            if not triggered:\n",
    "                if num_voiced > 0.6 * ring_buffer.maxlen:\n",
    "                    triggered = True\n",
    "                    voiced_frames.extend([f for f, s in ring_buffer])\n",
    "                    ring_buffer.clear()\n",
    "            else:\n",
    "                voiced_frames.append(data)\n",
    "                if num_voiced < 0.2 * ring_buffer.maxlen:\n",
    "                    silence_chunks += 1\n",
    "                    if silence_chunks > silence_threshold:\n",
    "                        triggered = False\n",
    "                        break\n",
    "                else:\n",
    "                    silence_chunks = 0\n",
    "\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "\n",
    "        with wave.open(\"C:\\\\DEV\\\\webdevfolder\\\\output.wav\", 'wb') as wf:\n",
    "            wf.setnchannels(CHANNELS)\n",
    "            wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "            wf.setframerate(RATE)\n",
    "            wf.writeframes(b''.join(voiced_frames))\n",
    "        logger.debug('Audio recording completed and file saved.')\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred while recording audio: {e}\")\n",
    "\n",
    "def transcribe_audio():\n",
    "    result = model.transcribe(\"C:\\\\DEV\\\\webdevfolder\\\\output.wav\")\n",
    "    transcription = result['text']\n",
    "    \n",
    "    logger.debug(f'Audio transcription completed: {transcription}')\n",
    "    return transcription\n",
    "\n",
    "async def ai_response(transcription: str):\n",
    "    global chat_history\n",
    "    logger.debug(f'Generating AI response for transcription: {transcription}')\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"You are a nice, great assistant. User will tell you things. You just respond. \n",
    "                If user's query relates to the following: you delegate the tasks to certain tools - namely, writing to a file, sending an email, uploading to google drive, or updating a google sheet. \n",
    "                If what the user says is one of these three you must explicitly say AT THE END OF YOUR RESPONSE in this very format depending on which tool - \"I will use the [write file tool, gmail tool, sheets tool, OR drive upload tool]\". \n",
    "                so that user can confirm if you got it correctly. \n",
    "                When writing to a file, just start the content with '@' symbol when generating file content.\n",
    "                IMPORTANT: ONCE YOU HAVE EXECUTED THE TOOL YOU MUST SAY THAT IT EXECUTED SUCCESSFULLY. \n",
    "                IMPORTANT: IF YOU REMEMBER YOU HAVE USED A TOOL ALREADY (REFER TO CHAT HISTORY), AND YOU ARE IN THE PROCESS OF USING IT AGAIN, \\\n",
    "                YOU MUST ASK USER IF THEY ARE SURE TO USE THE TOOL AGAIN OR NOT.\n",
    "\n",
    "                If you have to use a google related tool, you MUST prompt the user or remind user to enter credentials in the doc manager extension. \n",
    "                If user tells you to do something that is not one of these, you kindly say that you don't have access to that functionality.\n",
    "                \"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": transcription + \"Here is the chat history for context (NEVER TALK ABOUT CHAT HISTORY IT IS ONLY FOR YOU NEVER TALK ABOUT IT IN YOUR RESPONSES!!!!): [\" + str(chat_history) + \"]\"\n",
    "            }\n",
    "        ],\n",
    "        model=\"llama3-70b-8192\",\n",
    "    )\n",
    "    response = chat_completion.choices[0].message.content\n",
    "    logger.debug(f'AI response generated: {response}')\n",
    "    chat_history.append(\"USER: \" + transcription + \"\\nTHE AI MODEL: \" + response + \"\\n\")\n",
    "    \n",
    "    \n",
    "    asyncio.create_task(handle_response_with_agents(response))\n",
    "   \n",
    "    await synthesize_speech(response)\n",
    "\n",
    "    return response\n",
    "\n",
    "async def handle_response_with_agents(response):\n",
    "    logger.debug(f'Handling response with agents: {response}')\n",
    "    await asyncio.get_event_loop().run_in_executor(executor, handle_agents, response)\n",
    "\n",
    "def handle_agents(response):\n",
    "    logger.debug(f'Processing response with agents: {response}')\n",
    "    name = credentials['name']\n",
    "    email = credentials['email']\n",
    "    recemail = credentials[\"recemail\"]\n",
    "    phone = credentials['phone']\n",
    "    print(email, recemail, name, phone)\n",
    "\n",
    "    title_of_file = ''\n",
    "    with open('most_recent_file_created.txt') as mostrec:\n",
    "        title_of_file = mostrec.read()\n",
    "    thepath = f\"./documents/{title_of_file}.pdf\"\n",
    "\n",
    "    if 'I will use' in response:\n",
    "        if 'write file' in response:\n",
    "            idx = response.find('@')\n",
    "            modified_response = response[idx + 1:].strip()\n",
    "            print('MODIFIED RESPONSE = ', modified_response)\n",
    "            cc_out2 = make_docmgr_write_to_file(modified_response)\n",
    "            title, sections, append = parse_formatted_response(cc_out2)\n",
    "            llm.groq_api_key = random.choice(api_keys)\n",
    "            agent.invoke({\"input\": f\"use ONLY write_file tool!!! INPUT EVERYTHING CORRECTLY!!!!!!!! INPUT ONLY WHAT YOURE GIVEN ! NO CREATIVITIES!!!! append-->true or false lowercase only!!! --> TITLE: {title}, SECTIONS: {json.dumps(sections)}, APPEND: {append}\"})\n",
    "        elif 'sheet' in response:\n",
    "            agent.invoke({\"input\": f\"please ONLY ONLY use google sheets update tool, input ONLY ONLY these into the tool PROPERLY! --> {credentials['name']}, {credentials['phone']}\"})\n",
    "        elif 'upload' in response:\n",
    "            agent.invoke({\"input\": f\"please use google drive upload tool, INPUTS --> FILE_PATH: {thepath} USER_EMAIL: {credentials['email']}\"})\n",
    "        elif 'mail' in response:\n",
    "            if 'pdf' in response or 'PDF' in response or 'file' in response:\n",
    "                agent.invoke({\"input\": f\"please use ONLY ONLY gmail send pdf tool. INPUT DIRECTLY THE FOLLOWING INPUTS --> SENDER EMAIL: {credentials['email']}, RECIPIENT EMAIL: {credentials['recemail']}, SUBJECT: you generate it yourself, BODY: you generate it yourself and it has to be an informative body, PDF PATH: {thepath}\"})\n",
    "            else:\n",
    "                agent.invoke({\"input\": f\"please use ONLY ONLY gmail send pdf tool. INPUT DIRECTLY THE FOLLOWING INPUTS --> SENDER EMAIL: {credentials['email']}, RECIPIENT EMAIL: {credentials['recemail']}, SUBJECT: you generate it yourself, BODY: you generate it yourself and it has to be an informative body, PDF PATH: nothing\"})\n",
    "\n",
    "async def synthesize_speech(text):\n",
    "    logger.debug(f'Starting speech synthesis for text: {text}')\n",
    "    synthesis_input = texttospeech.SynthesisInput(text=text)\n",
    "    voice = texttospeech.VoiceSelectionParams(\n",
    "        language_code=\"en-US\",\n",
    "        name=\"en-US-Casual-K\"\n",
    "    )\n",
    "    audio_config = texttospeech.AudioConfig(\n",
    "        audio_encoding=texttospeech.AudioEncoding.MP3\n",
    "    )\n",
    "    response = await asyncio.get_event_loop().run_in_executor(\n",
    "        executor, lambda: tts_client.synthesize_speech(\n",
    "            input=synthesis_input, voice=voice, audio_config=audio_config\n",
    "        )\n",
    "    )\n",
    "    async with aiofiles.open(\"C:\\\\DEV\\\\webdevfolder\\\\synthesis.mp3\", 'wb') as out:\n",
    "        await out.write(response.audio_content)\n",
    "    print('Audio content written to file \"synthesis.mp3\"')\n",
    "    logger.debug('Speech synthesis completed and file saved.')\n",
    "\n",
    "\n",
    "@app.route('/set_credentials', methods=['POST'])\n",
    "def set_credentials():\n",
    "    global credentials\n",
    "    data = request.get_json()\n",
    "    if not data:\n",
    "        return jsonify({\"status\": \"failed\", \"message\": \"No data received\"}), 400\n",
    "    credentials['name'] = data.get('name')\n",
    "    credentials['email'] = data.get('email')\n",
    "    credentials['recemail'] = data.get('recemail')\n",
    "    credentials['phone'] = data.get('phone')\n",
    "    print(\"THE CREDENTIALS ****** -------------> \", credentials)\n",
    "    return jsonify({\"status\": \"success\"})\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index2.html')\n",
    "\n",
    "@app.route('/talk', methods=['POST'])\n",
    "async def talk():\n",
    "    loop = asyncio.get_event_loop()\n",
    "    \n",
    "    logger.debug('Starting audio recording...')\n",
    "    await loop.run_in_executor(executor, record_audio)\n",
    "    logger.debug('Audio recording completed.')\n",
    "    \n",
    "    logger.debug('Starting audio transcription...')\n",
    "    transcription = await loop.run_in_executor(executor, transcribe_audio)\n",
    "    logger.debug(f'Audio transcription completed: {transcription}')\n",
    "    \n",
    "    logger.debug('Generating AI response...')\n",
    "    ai_resp = await ai_response(transcription)\n",
    "    logger.debug(f'AI response generated: {ai_resp}')\n",
    "    \n",
    "    return jsonify({'response': ai_resp})\n",
    "\n",
    "\n",
    "\n",
    "@app.route('/get_audio')\n",
    "def get_audio():\n",
    "    return send_file(\"C:\\\\DEV\\\\webdevfolder\\\\synthesis.mp3\", mimetype=\"audio/mp3\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
