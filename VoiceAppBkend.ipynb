{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install flask whisper\n",
    "#! pip install git+https://github.com/openai/whisper.git -q\n",
    "#!pip install ffmpeg\n",
    "#!pip install openai\n",
    "#!pip install transformers\n",
    "#!pip install librosa pyaudio\n",
    "#!pip install --force-reinstall scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 12:24:43,554 - INFO - \u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "2024-05-03 12:24:43,554 - INFO - \u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "2024-05-03 12:24:46,960 - INFO - 127.0.0.1 - - [03/May/2024 12:24:46] \"GET / HTTP/1.1\" 200 -\n",
      "2024-05-03 12:25:02,357 - INFO - 127.0.0.1 - - [03/May/2024 12:25:02] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:25:04,359 - INFO - 127.0.0.1 - - [03/May/2024 12:25:04] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:25:06,379 - INFO - 127.0.0.1 - - [03/May/2024 12:25:06] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:25:08,553 - INFO - 127.0.0.1 - - [03/May/2024 12:25:08] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:25:10,565 - INFO - 127.0.0.1 - - [03/May/2024 12:25:10] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:25:12,644 - INFO - 127.0.0.1 - - [03/May/2024 12:25:12] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:25:14,692 - INFO - 127.0.0.1 - - [03/May/2024 12:25:14] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:25:16,740 - INFO - 127.0.0.1 - - [03/May/2024 12:25:16] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:25:18,871 - INFO - 127.0.0.1 - - [03/May/2024 12:25:18] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:25:20,981 - INFO - 127.0.0.1 - - [03/May/2024 12:25:20] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:25:22,947 - INFO - 127.0.0.1 - - [03/May/2024 12:25:22] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:25:25,037 - INFO - 127.0.0.1 - - [03/May/2024 12:25:25] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:25:27,088 - INFO - 127.0.0.1 - - [03/May/2024 12:25:27] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:25:29,140 - INFO - 127.0.0.1 - - [03/May/2024 12:25:29] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:25:31,246 - INFO - 127.0.0.1 - - [03/May/2024 12:25:31] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:25:33,352 - INFO - 127.0.0.1 - - [03/May/2024 12:25:33] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:25:35,420 - INFO - 127.0.0.1 - - [03/May/2024 12:25:35] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:25:36,966 - ERROR - An error occurred during transcription\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\PC-User\\AppData\\Local\\Temp\\ipykernel_24952\\3109146553.py\", line 240, in transcribe_audio\n",
      "    result = model.transcribe(temp_audio_path)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\transcribe.py\", line 279, in transcribe\n",
      "    result: DecodingResult = decode_with_fallback(mel_segment)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\transcribe.py\", line 195, in decode_with_fallback\n",
      "    decode_result = model.decode(segment, options)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 824, in decode\n",
      "    result = DecodingTask(model, options).run(mel)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 737, in run\n",
      "    tokens, sum_logprobs, no_speech_probs = self._main_loop(audio_features, tokens)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 687, in _main_loop\n",
      "    logits = self.inference.logits(tokens, audio_features)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 163, in logits\n",
      "    return self.model.decoder(tokens, audio_features, kv_cache=self.kv_cache)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 211, in forward\n",
      "    x = block(x, xa, mask=self.mask, kv_cache=kv_cache)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 136, in forward\n",
      "    x = x + self.attn(self.attn_ln(x), mask=mask, kv_cache=kv_cache)[0]\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 90, in forward\n",
      "    wv, qk = self.qkv_attention(q, k, v, mask)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 104, in qkv_attention\n",
      "    qk = qk + mask[:n_ctx, :n_ctx]\n",
      "RuntimeError: The size of tensor a (6) must match the size of tensor b (3) at non-singleton dimension 3\n",
      "2024-05-03 12:25:37,429 - INFO - 127.0.0.1 - - [03/May/2024 12:25:37] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:25:39,481 - INFO - 127.0.0.1 - - [03/May/2024 12:25:39] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:25:40,251 - ERROR - An error occurred during transcription\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\PC-User\\AppData\\Local\\Temp\\ipykernel_24952\\3109146553.py\", line 240, in transcribe_audio\n",
      "    result = model.transcribe(temp_audio_path)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\transcribe.py\", line 279, in transcribe\n",
      "    result: DecodingResult = decode_with_fallback(mel_segment)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\transcribe.py\", line 195, in decode_with_fallback\n",
      "    decode_result = model.decode(segment, options)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 824, in decode\n",
      "    result = DecodingTask(model, options).run(mel)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 737, in run\n",
      "    tokens, sum_logprobs, no_speech_probs = self._main_loop(audio_features, tokens)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 687, in _main_loop\n",
      "    logits = self.inference.logits(tokens, audio_features)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 163, in logits\n",
      "    return self.model.decoder(tokens, audio_features, kv_cache=self.kv_cache)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 211, in forward\n",
      "    x = block(x, xa, mask=self.mask, kv_cache=kv_cache)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 136, in forward\n",
      "    x = x + self.attn(self.attn_ln(x), mask=mask, kv_cache=kv_cache)[0]\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 90, in forward\n",
      "    wv, qk = self.qkv_attention(q, k, v, mask)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 104, in qkv_attention\n",
      "    qk = qk + mask[:n_ctx, :n_ctx]\n",
      "RuntimeError: The size of tensor a (6) must match the size of tensor b (3) at non-singleton dimension 3\n",
      "2024-05-03 12:25:41,491 - INFO - 127.0.0.1 - - [03/May/2024 12:25:41] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:25:46,971 - INFO - 127.0.0.1 - - [03/May/2024 12:25:46] \"\u001b[35m\u001b[1mPOST /transcribe HTTP/1.1\u001b[0m\" 500 -\n",
      "2024-05-03 12:25:50,264 - INFO - 127.0.0.1 - - [03/May/2024 12:25:50] \"\u001b[35m\u001b[1mPOST /transcribe HTTP/1.1\u001b[0m\" 500 -\n",
      "2024-05-03 12:25:50,570 - INFO - 127.0.0.1 - - [03/May/2024 12:25:50] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:25:51,950 - INFO - 127.0.0.1 - - [03/May/2024 12:25:51] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:25:53,201 - INFO - 127.0.0.1 - - [03/May/2024 12:25:53] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:25:54,021 - ERROR - An error occurred during transcription\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\PC-User\\AppData\\Local\\Temp\\ipykernel_24952\\3109146553.py\", line 240, in transcribe_audio\n",
      "    result = model.transcribe(temp_audio_path)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\transcribe.py\", line 279, in transcribe\n",
      "    result: DecodingResult = decode_with_fallback(mel_segment)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\transcribe.py\", line 195, in decode_with_fallback\n",
      "    decode_result = model.decode(segment, options)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 824, in decode\n",
      "    result = DecodingTask(model, options).run(mel)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 737, in run\n",
      "    tokens, sum_logprobs, no_speech_probs = self._main_loop(audio_features, tokens)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 687, in _main_loop\n",
      "    logits = self.inference.logits(tokens, audio_features)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 163, in logits\n",
      "    return self.model.decoder(tokens, audio_features, kv_cache=self.kv_cache)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 211, in forward\n",
      "    x = block(x, xa, mask=self.mask, kv_cache=kv_cache)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 136, in forward\n",
      "    x = x + self.attn(self.attn_ln(x), mask=mask, kv_cache=kv_cache)[0]\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 90, in forward\n",
      "    wv, qk = self.qkv_attention(q, k, v, mask)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 104, in qkv_attention\n",
      "    qk = qk + mask[:n_ctx, :n_ctx]\n",
      "RuntimeError: The size of tensor a (6) must match the size of tensor b (3) at non-singleton dimension 3\n",
      "2024-05-03 12:25:54,261 - INFO - 127.0.0.1 - - [03/May/2024 12:25:54] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:25:56,373 - ERROR - An error occurred during transcription\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\PC-User\\AppData\\Local\\Temp\\ipykernel_24952\\3109146553.py\", line 240, in transcribe_audio\n",
      "    result = model.transcribe(temp_audio_path)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\transcribe.py\", line 279, in transcribe\n",
      "    result: DecodingResult = decode_with_fallback(mel_segment)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\transcribe.py\", line 195, in decode_with_fallback\n",
      "    decode_result = model.decode(segment, options)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 824, in decode\n",
      "    result = DecodingTask(model, options).run(mel)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 737, in run\n",
      "    tokens, sum_logprobs, no_speech_probs = self._main_loop(audio_features, tokens)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 687, in _main_loop\n",
      "    logits = self.inference.logits(tokens, audio_features)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 163, in logits\n",
      "    return self.model.decoder(tokens, audio_features, kv_cache=self.kv_cache)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 211, in forward\n",
      "    x = block(x, xa, mask=self.mask, kv_cache=kv_cache)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 136, in forward\n",
      "    x = x + self.attn(self.attn_ln(x), mask=mask, kv_cache=kv_cache)[0]\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 90, in forward\n",
      "    wv, qk = self.qkv_attention(q, k, v, mask)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 104, in qkv_attention\n",
      "    qk = qk + mask[:n_ctx, :n_ctx]\n",
      "RuntimeError: The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 3\n",
      "2024-05-03 12:25:59,196 - INFO - 127.0.0.1 - - [03/May/2024 12:25:59] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:26:04,034 - INFO - 127.0.0.1 - - [03/May/2024 12:26:04] \"\u001b[35m\u001b[1mPOST /transcribe HTTP/1.1\u001b[0m\" 500 -\n",
      "2024-05-03 12:26:05,485 - INFO - 127.0.0.1 - - [03/May/2024 12:26:05] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:26:06,383 - INFO - 127.0.0.1 - - [03/May/2024 12:26:06] \"\u001b[35m\u001b[1mPOST /transcribe HTTP/1.1\u001b[0m\" 500 -\n",
      "2024-05-03 12:26:08,103 - INFO - 127.0.0.1 - - [03/May/2024 12:26:08] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:26:08,390 - INFO - 127.0.0.1 - - [03/May/2024 12:26:08] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:26:11,394 - INFO - 127.0.0.1 - - [03/May/2024 12:26:11] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:26:12,346 - ERROR - An error occurred during transcription\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\PC-User\\AppData\\Local\\Temp\\ipykernel_24952\\3109146553.py\", line 240, in transcribe_audio\n",
      "    result = model.transcribe(temp_audio_path)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\transcribe.py\", line 279, in transcribe\n",
      "    result: DecodingResult = decode_with_fallback(mel_segment)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\transcribe.py\", line 195, in decode_with_fallback\n",
      "    decode_result = model.decode(segment, options)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 824, in decode\n",
      "    result = DecodingTask(model, options).run(mel)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 737, in run\n",
      "    tokens, sum_logprobs, no_speech_probs = self._main_loop(audio_features, tokens)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 687, in _main_loop\n",
      "    logits = self.inference.logits(tokens, audio_features)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 163, in logits\n",
      "    return self.model.decoder(tokens, audio_features, kv_cache=self.kv_cache)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 211, in forward\n",
      "    x = block(x, xa, mask=self.mask, kv_cache=kv_cache)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 136, in forward\n",
      "    x = x + self.attn(self.attn_ln(x), mask=mask, kv_cache=kv_cache)[0]\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 90, in forward\n",
      "    wv, qk = self.qkv_attention(q, k, v, mask)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 104, in qkv_attention\n",
      "    qk = qk + mask[:n_ctx, :n_ctx]\n",
      "RuntimeError: The size of tensor a (7) must match the size of tensor b (3) at non-singleton dimension 3\n",
      "2024-05-03 12:26:16,355 - INFO - 127.0.0.1 - - [03/May/2024 12:26:16] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:26:19,352 - INFO - 127.0.0.1 - - [03/May/2024 12:26:19] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:26:20,944 - INFO - 127.0.0.1 - - [03/May/2024 12:26:20] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:26:22,359 - INFO - 127.0.0.1 - - [03/May/2024 12:26:22] \"\u001b[35m\u001b[1mPOST /transcribe HTTP/1.1\u001b[0m\" 500 -\n",
      "2024-05-03 12:26:22,516 - INFO - 127.0.0.1 - - [03/May/2024 12:26:22] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:26:24,075 - INFO - 127.0.0.1 - - [03/May/2024 12:26:24] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:26:26,741 - ERROR - An error occurred during transcription\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\PC-User\\AppData\\Local\\Temp\\ipykernel_24952\\3109146553.py\", line 240, in transcribe_audio\n",
      "    result = model.transcribe(temp_audio_path)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\transcribe.py\", line 279, in transcribe\n",
      "    result: DecodingResult = decode_with_fallback(mel_segment)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\transcribe.py\", line 195, in decode_with_fallback\n",
      "    decode_result = model.decode(segment, options)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 824, in decode\n",
      "    result = DecodingTask(model, options).run(mel)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 737, in run\n",
      "    tokens, sum_logprobs, no_speech_probs = self._main_loop(audio_features, tokens)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 687, in _main_loop\n",
      "    logits = self.inference.logits(tokens, audio_features)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 163, in logits\n",
      "    return self.model.decoder(tokens, audio_features, kv_cache=self.kv_cache)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 211, in forward\n",
      "    x = block(x, xa, mask=self.mask, kv_cache=kv_cache)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 136, in forward\n",
      "    x = x + self.attn(self.attn_ln(x), mask=mask, kv_cache=kv_cache)[0]\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 90, in forward\n",
      "    wv, qk = self.qkv_attention(q, k, v, mask)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 104, in qkv_attention\n",
      "    qk = qk + mask[:n_ctx, :n_ctx]\n",
      "RuntimeError: The size of tensor a (6) must match the size of tensor b (3) at non-singleton dimension 3\n",
      "2024-05-03 12:26:28,537 - INFO - 127.0.0.1 - - [03/May/2024 12:26:28] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:26:31,611 - INFO - 127.0.0.1 - - [03/May/2024 12:26:31] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:26:34,292 - INFO - 127.0.0.1 - - [03/May/2024 12:26:34] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:26:36,751 - INFO - 127.0.0.1 - - [03/May/2024 12:26:36] \"\u001b[35m\u001b[1mPOST /transcribe HTTP/1.1\u001b[0m\" 500 -\n",
      "2024-05-03 12:26:37,000 - INFO - 127.0.0.1 - - [03/May/2024 12:26:37] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:26:37,768 - INFO - 127.0.0.1 - - [03/May/2024 12:26:37] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:26:40,777 - INFO - 127.0.0.1 - - [03/May/2024 12:26:40] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:26:40,847 - ERROR - An error occurred during transcription\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\PC-User\\AppData\\Local\\Temp\\ipykernel_24952\\3109146553.py\", line 240, in transcribe_audio\n",
      "    result = model.transcribe(temp_audio_path)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\transcribe.py\", line 279, in transcribe\n",
      "    result: DecodingResult = decode_with_fallback(mel_segment)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\transcribe.py\", line 195, in decode_with_fallback\n",
      "    decode_result = model.decode(segment, options)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 824, in decode\n",
      "    result = DecodingTask(model, options).run(mel)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 737, in run\n",
      "    tokens, sum_logprobs, no_speech_probs = self._main_loop(audio_features, tokens)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 687, in _main_loop\n",
      "    logits = self.inference.logits(tokens, audio_features)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 163, in logits\n",
      "    return self.model.decoder(tokens, audio_features, kv_cache=self.kv_cache)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 211, in forward\n",
      "    x = block(x, xa, mask=self.mask, kv_cache=kv_cache)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 136, in forward\n",
      "    x = x + self.attn(self.attn_ln(x), mask=mask, kv_cache=kv_cache)[0]\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 90, in forward\n",
      "    wv, qk = self.qkv_attention(q, k, v, mask)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 104, in qkv_attention\n",
      "    qk = qk + mask[:n_ctx, :n_ctx]\n",
      "RuntimeError: The size of tensor a (8) must match the size of tensor b (3) at non-singleton dimension 3\n",
      "2024-05-03 12:26:43,845 - INFO - 127.0.0.1 - - [03/May/2024 12:26:43] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:26:46,481 - INFO - 127.0.0.1 - - [03/May/2024 12:26:46] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:26:50,860 - INFO - 127.0.0.1 - - [03/May/2024 12:26:50] \"\u001b[35m\u001b[1mPOST /transcribe HTTP/1.1\u001b[0m\" 500 -\n",
      "2024-05-03 12:26:51,220 - INFO - 127.0.0.1 - - [03/May/2024 12:26:51] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:26:51,768 - INFO - 127.0.0.1 - - [03/May/2024 12:26:51] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:26:53,366 - INFO - 127.0.0.1 - - [03/May/2024 12:26:53] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:26:56,014 - ERROR - An error occurred during transcription\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\PC-User\\AppData\\Local\\Temp\\ipykernel_24952\\3109146553.py\", line 240, in transcribe_audio\n",
      "    result = model.transcribe(temp_audio_path)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\transcribe.py\", line 279, in transcribe\n",
      "    result: DecodingResult = decode_with_fallback(mel_segment)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\transcribe.py\", line 195, in decode_with_fallback\n",
      "    decode_result = model.decode(segment, options)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 824, in decode\n",
      "    result = DecodingTask(model, options).run(mel)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 737, in run\n",
      "    tokens, sum_logprobs, no_speech_probs = self._main_loop(audio_features, tokens)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 687, in _main_loop\n",
      "    logits = self.inference.logits(tokens, audio_features)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 163, in logits\n",
      "    return self.model.decoder(tokens, audio_features, kv_cache=self.kv_cache)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 211, in forward\n",
      "    x = block(x, xa, mask=self.mask, kv_cache=kv_cache)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 136, in forward\n",
      "    x = x + self.attn(self.attn_ln(x), mask=mask, kv_cache=kv_cache)[0]\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 90, in forward\n",
      "    wv, qk = self.qkv_attention(q, k, v, mask)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 104, in qkv_attention\n",
      "    qk = qk + mask[:n_ctx, :n_ctx]\n",
      "RuntimeError: The size of tensor a (10) must match the size of tensor b (3) at non-singleton dimension 3\n",
      "2024-05-03 12:26:56,078 - INFO - 127.0.0.1 - - [03/May/2024 12:26:56] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:26:57,170 - ERROR - An error occurred during transcription\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\PC-User\\AppData\\Local\\Temp\\ipykernel_24952\\3109146553.py\", line 240, in transcribe_audio\n",
      "    result = model.transcribe(temp_audio_path)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\transcribe.py\", line 279, in transcribe\n",
      "    result: DecodingResult = decode_with_fallback(mel_segment)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\transcribe.py\", line 195, in decode_with_fallback\n",
      "    decode_result = model.decode(segment, options)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 824, in decode\n",
      "    result = DecodingTask(model, options).run(mel)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 737, in run\n",
      "    tokens, sum_logprobs, no_speech_probs = self._main_loop(audio_features, tokens)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 687, in _main_loop\n",
      "    logits = self.inference.logits(tokens, audio_features)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 163, in logits\n",
      "    return self.model.decoder(tokens, audio_features, kv_cache=self.kv_cache)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 211, in forward\n",
      "    x = block(x, xa, mask=self.mask, kv_cache=kv_cache)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 136, in forward\n",
      "    x = x + self.attn(self.attn_ln(x), mask=mask, kv_cache=kv_cache)[0]\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 90, in forward\n",
      "    wv, qk = self.qkv_attention(q, k, v, mask)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 104, in qkv_attention\n",
      "    qk = qk + mask[:n_ctx, :n_ctx]\n",
      "RuntimeError: The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 3\n",
      "2024-05-03 12:26:58,483 - ERROR - An error occurred during transcription\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\PC-User\\AppData\\Local\\Temp\\ipykernel_24952\\3109146553.py\", line 240, in transcribe_audio\n",
      "    result = model.transcribe(temp_audio_path)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\transcribe.py\", line 279, in transcribe\n",
      "    result: DecodingResult = decode_with_fallback(mel_segment)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\transcribe.py\", line 195, in decode_with_fallback\n",
      "    decode_result = model.decode(segment, options)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 824, in decode\n",
      "    result = DecodingTask(model, options).run(mel)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 737, in run\n",
      "    tokens, sum_logprobs, no_speech_probs = self._main_loop(audio_features, tokens)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 687, in _main_loop\n",
      "    logits = self.inference.logits(tokens, audio_features)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 163, in logits\n",
      "    return self.model.decoder(tokens, audio_features, kv_cache=self.kv_cache)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 211, in forward\n",
      "    x = block(x, xa, mask=self.mask, kv_cache=kv_cache)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 136, in forward\n",
      "    x = x + self.attn(self.attn_ln(x), mask=mask, kv_cache=kv_cache)[0]\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 90, in forward\n",
      "    wv, qk = self.qkv_attention(q, k, v, mask)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 104, in qkv_attention\n",
      "    qk = qk + mask[:n_ctx, :n_ctx]\n",
      "RuntimeError: The size of tensor a (6) must match the size of tensor b (3) at non-singleton dimension 3\n",
      "2024-05-03 12:26:58,710 - INFO - 127.0.0.1 - - [03/May/2024 12:26:58] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:27:00,168 - ERROR - An error occurred during transcription\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\PC-User\\AppData\\Local\\Temp\\ipykernel_24952\\3109146553.py\", line 240, in transcribe_audio\n",
      "    result = model.transcribe(temp_audio_path)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\transcribe.py\", line 279, in transcribe\n",
      "    result: DecodingResult = decode_with_fallback(mel_segment)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\transcribe.py\", line 195, in decode_with_fallback\n",
      "    decode_result = model.decode(segment, options)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 824, in decode\n",
      "    result = DecodingTask(model, options).run(mel)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 737, in run\n",
      "    tokens, sum_logprobs, no_speech_probs = self._main_loop(audio_features, tokens)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 687, in _main_loop\n",
      "    logits = self.inference.logits(tokens, audio_features)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 163, in logits\n",
      "    return self.model.decoder(tokens, audio_features, kv_cache=self.kv_cache)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 211, in forward\n",
      "    x = block(x, xa, mask=self.mask, kv_cache=kv_cache)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 136, in forward\n",
      "    x = x + self.attn(self.attn_ln(x), mask=mask, kv_cache=kv_cache)[0]\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 90, in forward\n",
      "    wv, qk = self.qkv_attention(q, k, v, mask)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 104, in qkv_attention\n",
      "    qk = qk + mask[:n_ctx, :n_ctx]\n",
      "RuntimeError: The size of tensor a (6) must match the size of tensor b (3) at non-singleton dimension 3\n",
      "2024-05-03 12:27:02,107 - ERROR - An error occurred during transcription\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\PC-User\\AppData\\Local\\Temp\\ipykernel_24952\\3109146553.py\", line 240, in transcribe_audio\n",
      "    result = model.transcribe(temp_audio_path)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\transcribe.py\", line 279, in transcribe\n",
      "    result: DecodingResult = decode_with_fallback(mel_segment)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\transcribe.py\", line 195, in decode_with_fallback\n",
      "    decode_result = model.decode(segment, options)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 824, in decode\n",
      "    result = DecodingTask(model, options).run(mel)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 737, in run\n",
      "    tokens, sum_logprobs, no_speech_probs = self._main_loop(audio_features, tokens)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 687, in _main_loop\n",
      "    logits = self.inference.logits(tokens, audio_features)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\decoding.py\", line 163, in logits\n",
      "    return self.model.decoder(tokens, audio_features, kv_cache=self.kv_cache)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 211, in forward\n",
      "    x = block(x, xa, mask=self.mask, kv_cache=kv_cache)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 136, in forward\n",
      "    x = x + self.attn(self.attn_ln(x), mask=mask, kv_cache=kv_cache)[0]\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 90, in forward\n",
      "    wv, qk = self.qkv_attention(q, k, v, mask)\n",
      "  File \"d:\\DEV\\WebdevFolder\\RealEstateAI\\.venv\\lib\\site-packages\\whisper\\model.py\", line 104, in qkv_attention\n",
      "    qk = qk + mask[:n_ctx, :n_ctx]\n",
      "RuntimeError: The size of tensor a (10) must match the size of tensor b (3) at non-singleton dimension 3\n",
      "2024-05-03 12:27:06,028 - INFO - 127.0.0.1 - - [03/May/2024 12:27:06] \"\u001b[35m\u001b[1mPOST /transcribe HTTP/1.1\u001b[0m\" 500 -\n",
      "2024-05-03 12:27:07,179 - INFO - 127.0.0.1 - - [03/May/2024 12:27:07] \"\u001b[35m\u001b[1mPOST /transcribe HTTP/1.1\u001b[0m\" 500 -\n",
      "2024-05-03 12:27:08,493 - INFO - 127.0.0.1 - - [03/May/2024 12:27:08] \"\u001b[35m\u001b[1mPOST /transcribe HTTP/1.1\u001b[0m\" 500 -\n",
      "2024-05-03 12:27:10,179 - INFO - 127.0.0.1 - - [03/May/2024 12:27:10] \"\u001b[35m\u001b[1mPOST /transcribe HTTP/1.1\u001b[0m\" 500 -\n",
      "2024-05-03 12:27:12,118 - INFO - 127.0.0.1 - - [03/May/2024 12:27:12] \"\u001b[35m\u001b[1mPOST /transcribe HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 12:27:13,736 - INFO - 127.0.0.1 - - [03/May/2024 12:27:13] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:27:18,343 - INFO - 127.0.0.1 - - [03/May/2024 12:27:18] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:27:20,402 - INFO - 127.0.0.1 - - [03/May/2024 12:27:20] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:27:21,720 - INFO - 127.0.0.1 - - [03/May/2024 12:27:21] \"POST /transcribe HTTP/1.1\" 200 -\n",
      "2024-05-03 12:27:23,085 - INFO - 127.0.0.1 - - [03/May/2024 12:27:23] \"POST /transcribe HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "from flask import Flask, request, jsonify\n",
    "import tempfile\n",
    "import whisper\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa \n",
    "import pyaudio\n",
    "# Setup Flask app\n",
    "app = Flask(__name__)\n",
    " # Allow cross-origin requests\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Load the Whisper model once to save resources\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return \"\"\"<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Real-Time Speech to Text</title>\n",
    "    <style>\n",
    "        /* Add Skype-like styling */\n",
    "        body {\n",
    "            font-family: Arial, sans-serif;\n",
    "            background-color: #fff;\n",
    "        }\n",
    "        .container {\n",
    "            max-width: 400px;\n",
    "            margin: 40px auto;\n",
    "            background-color: #f7f7f7;\n",
    "            padding: 20px;\n",
    "            border-radius: 10px;\n",
    "            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);\n",
    "        }\n",
    "        .header {\n",
    "            background-color: #333;\n",
    "            color: #fff;\n",
    "            padding: 10px;\n",
    "            border-bottom: 1px solid #333;\n",
    "            border-radius: 10px 10px 0 0;\n",
    "        }\n",
    "        .header span {\n",
    "            font-weight: bold;\n",
    "            font-size: 18px;\n",
    "        }\n",
    "        .call-info {\n",
    "            margin-top: 20px;\n",
    "            display: flex;\n",
    "            flex-wrap: wrap;\n",
    "            justify-content: space-between;\n",
    "        }\n",
    "        .call-info span {\n",
    "            font-weight: bold;\n",
    "            margin-right: 10px;\n",
    "            font-size: 16px;\n",
    "        }\n",
    "        .transcription {\n",
    "            margin-top: 20px;\n",
    "            padding: 20px;\n",
    "            border: 1px solid #ddd;\n",
    "            border-radius: 10px;\n",
    "            background-color: #f9f9f9;\n",
    "        }\n",
    "        .button-container {\n",
    "            margin-top: 20px;\n",
    "            text-align: center;\n",
    "        }\n",
    "        .button-container button {\n",
    "            padding: 10px 20px;\n",
    "            border: none;\n",
    "            border-radius: 10px;\n",
    "            background-color: #333;\n",
    "            color: #fff;\n",
    "            cursor: pointer;\n",
    "        }\n",
    "        .button-container button:hover {\n",
    "            background-color: #444;\n",
    "        }\n",
    "        /* Add Skype-like video call elements */\n",
    "        .video-call {\n",
    "            display: flex;\n",
    "            flex-wrap: wrap;\n",
    "            justify-content: center;\n",
    "            margin-top: 20px;\n",
    "        }\n",
    "        .video-call div {\n",
    "            width: 50%;\n",
    "            height: 200px;\n",
    "            background-color: #333;\n",
    "            border-radius: 10px;\n",
    "            margin: 10px;\n",
    "        }\n",
    "        .video-call div:first-child {\n",
    "            background-image: url('https://images.unsplash.com/photo-1500648767791-00dcc994a43e?q=80&w=1000&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxzZWFyY2h8Mnx8cmFuZG9tJTIwcGVvcGxlfGVufDB8fDB8fHww');\n",
    "            background-size: cover;\n",
    "            background-position: center;\n",
    "        }\n",
    "        .video-call div:last-child {\n",
    "            background-image: url('https://preview.redd.it/created-random-people-using-chatgpt-midjourney-do-you-know-v0-q1aa450i5dqb1.png?width=1024&format=png&auto=webp&s=c4e9abc47d193474a2fa1a7e337d9d9340dce947');\n",
    "            background-size: cover;\n",
    "            background-position: center;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"container\">\n",
    "        <div class=\"header\">\n",
    "            <span>Skype Call</span>\n",
    "        </div>\n",
    "        <div class=\"call-info\">\n",
    "            <span>Call ID:</span> <span>1234567890</span>\n",
    "            <span>Caller:</span> <span>John Doe</span>\n",
    "            <span>Duration:</span> <span>00:00:00</span>\n",
    "        </div>\n",
    "        <div class=\"video-call\">\n",
    "            <div></div>\n",
    "            <div></div>\n",
    "        </div>\n",
    "        <div class=\"transcription\">\n",
    "            <p id=\"transcription\"></p>\n",
    "        </div>\n",
    "        <div class=\"button-container\">\n",
    "            <button id=\"endCall\">End Call</button>\n",
    "        </div>\n",
    "    </div>\n",
    "\n",
    "    <script>\n",
    "    let audioContext, microphone, mediaRecorder, audioChunks = [], silenceDetector;\n",
    "    let lastSoundTimestamp = Date.now();\n",
    "    const silenceThreshold = 2000; // Increased silence threshold to 2 seconds\n",
    "\n",
    "    navigator.mediaDevices.getUserMedia({ audio: true })\n",
    "        .then(stream => {\n",
    "            audioContext = new AudioContext();\n",
    "            microphone = audioContext.createMediaStreamSource(stream);\n",
    "            mediaRecorder = new MediaRecorder(stream);\n",
    "            setupMediaRecorder();\n",
    "        })\n",
    "        .catch(error => console.error('Error accessing media devices.', error));\n",
    "\n",
    "    function setupMediaRecorder() {\n",
    "        mediaRecorder.ondataavailable = event => {\n",
    "            if (event.data.size > 0) {\n",
    "                audioChunks.push(event.data);\n",
    "            }\n",
    "        };\n",
    "\n",
    "        mediaRecorder.start(1000); // Collect data in chunks of 1 second\n",
    "\n",
    "        silenceDetector = setInterval(() => {\n",
    "            if ((Date.now() - lastSoundTimestamp) > silenceThreshold && audioChunks.length) {\n",
    "                mediaRecorder.stop();\n",
    "            }\n",
    "        }, 1000); // Check every 1 second for extended silence\n",
    "\n",
    "        microphone.connect(audioContext.createScriptProcessor(4096, 1, 1)).onaudioprocess = function(event) {\n",
    "            var input = event.inputBuffer.getChannelData(0);\n",
    "            var sum = 0, i = 0;\n",
    "            for (; i < input.length; ++i) sum += input[i] * input[i];\n",
    "            if (Math.sqrt(sum / input.length) > 0.001) { // Detect sound\n",
    "                lastSoundTimestamp = Date.now();\n",
    "            }\n",
    "        };\n",
    "\n",
    "        mediaRecorder.onstop = () => {\n",
    "            sendAudioToServer();\n",
    "            audioChunks = []; // Clear the buffer after sending\n",
    "            mediaRecorder.start(1000); // Restart recording after sending data\n",
    "        };\n",
    "    }\n",
    "\n",
    "    function sendAudioToServer() {\n",
    "        if (audioChunks.length > 0) {\n",
    "            const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });\n",
    "            const formData = new FormData();\n",
    "            formData.append('audio', audioBlob, 'file.wav');\n",
    "\n",
    "            fetch('/transcribe', {\n",
    "                method: 'POST',\n",
    "                body: formData\n",
    "            })\n",
    "            .then(response => response.json())\n",
    "            .then(data => {\n",
    "                document.getElementById('transcription').textContent = data.transcription;\n",
    "            })\n",
    "            .catch(console.error);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    document.getElementById('endCall').addEventListener('click', () => {\n",
    "        clearInterval(silenceDetector);\n",
    "        mediaRecorder.stop(); // This will also trigger the last data send if there are any chunks left\n",
    "    });\n",
    "</script>\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def format_list(lst:list):\n",
    "    string = ''\n",
    "    ctr = 0\n",
    "    for c in lst:\n",
    "        string += (c + \" \")\n",
    "        if(ctr > 4):\n",
    "            string += (\"\\n\")\n",
    "            ctr = 0\n",
    "        ctr += 1\n",
    "    return string\n",
    "\n",
    "conversation_history = []\n",
    "@app.route('/transcribe', methods=['POST'])\n",
    "def transcribe_audio():\n",
    "    global conversation_history\n",
    "    if 'audio' not in request.files:\n",
    "        return jsonify({\"error\": \"No audio file provided\"}), 400\n",
    "\n",
    "    audio_file = request.files['audio']\n",
    "    \n",
    "    temp_dir = tempfile.mkdtemp(dir=\"D:\\\\DEV\\\\WebdevFolder\\\\RealEstateAI\")\n",
    "    try:\n",
    "        # Save the audio file to a temporary file\n",
    "        temp_audio_path = os.path.join(temp_dir, audio_file.filename)\n",
    "        audio_file.save(temp_audio_path)\n",
    "\n",
    "        \n",
    "        result = model.transcribe(temp_audio_path)\n",
    "        conversation_history.append( result['text'])\n",
    "        conversation_history_str = format_list(conversation_history)\n",
    "        return jsonify({\"transcription\": conversation_history_str})\n",
    "    except Exception as e:\n",
    "        logging.exception(\"An error occurred during transcription\")\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "    finally:\n",
    "        time.sleep(10)\n",
    "        # Cleanup: Remove temporary files\n",
    "        os.remove(temp_audio_path)\n",
    "        os.rmdir(temp_dir)\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=False, port=5000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
